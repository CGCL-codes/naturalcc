{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(sys.path[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'True'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image,ImageDraw\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scripts.train.utils import smart_tokenizer_and_embedding_resize,Html2BboxTree,move_to_device,BboxTree2Html,add_special_tokens\n",
    "from vars import *\n",
    "from my_dataset import UICoderDataset,UICoderCollater\n",
    "from transformers import AutoProcessor, Pix2StructForConditionalGeneration,AddedToken\n",
    "from utils import Html2BboxTree, BboxTree2StyleList, BboxTree2Html\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = 'cuda:0'\n",
    "# bbox_model_path = \"/data02/users/lz/code/UICoder/checkpoints/stage1/l2048_p1024_vu_3m*1/checkpoint-200000\"\n",
    "bbox_model_path = \"/data02/users/lz/code/UICoder/checkpoints/stage1/l2048_p1024_vu2048_3m*1/checkpoint-50000\"\n",
    "style_model_path = \"/data02/users/lz/code/UICoder/checkpoints/stage2/l256_p512_vu_100k*1/checkpoint-50000\"\n",
    "\n",
    "data_path = '/data02/bbox_v2/data/00002.parquet'\n",
    "# data_path = '/data02/users/lz/code/UICoder/datasets/WebSight-format-parquet/arrow'\n",
    "output_dir = '/data02/users/lz/code/UICoder/test_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(processor_name_or_path)\n",
    "model_bbox = Pix2StructForConditionalGeneration.from_pretrained(bbox_model_path,is_encoder_decoder=True,device_map=device,torch_dtype=torch.float16)\n",
    "model_style = Pix2StructForConditionalGeneration.from_pretrained(style_model_path,is_encoder_decoder=True,device_map=device,torch_dtype=torch.float16)\n",
    "add_special_tokens(model_bbox,processor.tokenizer)\n",
    "add_special_tokens(model_style,processor.tokenizer)\n",
    "\n",
    "ds = load_dataset('parquet', data_files={'train':data_path})['train']\n",
    "# ds = UICoderDataset(path=data_path,processor=processor,max_length=1024,max_patches=1024,max_num=100,drop_longer=True,stage=1,preprocess=True, make_patches_while_training=True, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drawBboxOnImage(draw: ImageDraw,bbox_node):\n",
    "    bbox = bbox_node['bbox']\n",
    "    if bbox[2] > 0 and bbox[3] > 0:\n",
    "        draw.rectangle((bbox[0],bbox[1],bbox[0]+bbox[2],bbox[1]+bbox[3]),outline=\"red\",width=2)\n",
    "    for node in bbox_node['children']:\n",
    "        drawBboxOnImage(draw, node)\n",
    "        \n",
    "def stickImages(images):\n",
    "    sizes = list(map(lambda x: x.size,images))\n",
    "\n",
    "    max_width = max(list(map(lambda x: x[0],sizes)))\n",
    "    max_height = max(list(map(lambda x: x[1],sizes)))\n",
    "\n",
    "    new_image = Image.new('RGB', ((max_width+10)*len(images), max_height))\n",
    "    \n",
    "    for idx,image in enumerate(images):\n",
    "        new_image.paste(image, ((max_width+10)*idx, 0))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def remove_bbox(html_content):\n",
    "    bbox_pattern = r' bbox=\\[[^\\]]*\\]'\n",
    "    cleaned_html = re.sub(bbox_pattern, '', html_content)\n",
    "    return cleaned_html\n",
    "\n",
    "def infer_bbox(image):\n",
    "    model_bbox.eval()\n",
    "    with torch.no_grad():\n",
    "        input = f'<body bbox=['\n",
    "        decoder_input_ids = processor.tokenizer.encode(input,return_tensors='pt',add_special_tokens=True)[...,:-1]\n",
    "        encoding = processor(images=[image],text=[\"\"],max_patches=1024,return_tensors='pt')\n",
    "        item = {\n",
    "            'decoder_input_ids': decoder_input_ids,\n",
    "            'flattened_patches': encoding['flattened_patches'].half(),\n",
    "            'attention_mask': encoding['attention_mask']\n",
    "        }\n",
    "        item = move_to_device(item,device)\n",
    "    \n",
    "        outputs = model_bbox.generate(**item,max_new_tokens=2560,eos_token_id=processor.tokenizer.eos_token_id,do_sample=True)\n",
    "                \n",
    "        prediction_html = processor.tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "    return prediction_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "# image\n",
    "image = ds[idx]['image']\n",
    "\n",
    "# infer\n",
    "prediction_html = infer_bbox(image)\n",
    "\n",
    "# predicted html\n",
    "print(len(processor.tokenizer.encode(prediction_html)))\n",
    "prediction_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aBbox = Html2BboxTree(answer_html)\n",
    "pBbox = Html2BboxTree(prediction_html, size=image.size)\n",
    "aImage = image.copy()\n",
    "pImage = image.copy()\n",
    "\n",
    "drawBboxOnImage(ImageDraw.Draw(aImage),json.loads(ds[idx]['bbox']))\n",
    "drawBboxOnImage(ImageDraw.Draw(pImage),pBbox)\n",
    "\n",
    "pair = stickImages([aImage,pImage])\n",
    "pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Style Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictStyle(image,styleItem):\n",
    "    cnode_type_bbox_list = list(map(lambda x: f'{x[\"type\"]}({x[\"bbox\"][0]-styleItem[\"bbox\"][0]},{x[\"bbox\"][1]-styleItem[\"bbox\"][1]},{x[\"bbox\"][2]},{x[\"bbox\"]})', styleItem['children']))\n",
    "    input = f\"{styleItem['type']}<{','.join(cnode_type_bbox_list)}> %{styleItem['style']}%<%\"\n",
    "    decoder_input_ids = processor.tokenizer.encode(input,return_tensors='pt')[...,:-1]\n",
    "    encoding = processor(images=[image],text=[\"\"],max_patches=512,return_tensors='pt')\n",
    "    item = {\n",
    "        'decoder_input_ids': decoder_input_ids,\n",
    "        'flattened_patches': encoding['flattened_patches'].half(),\n",
    "        'attention_mask': encoding['attention_mask']\n",
    "    }\n",
    "    item = move_to_device(item,device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_style.generate(**item,max_new_tokens=256,eos_token_id=processor.tokenizer.eos_token_id)\n",
    "        predictions = processor.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    css = '<'.join(predictions[0].split('<')[2:]).strip()\n",
    "    if css and css[0] == '%':\n",
    "        css = css[1:]\n",
    "    if css and css[-1] == '>':\n",
    "        css = css[:-1]\n",
    "    if css and css[-1] == '%':\n",
    "        css = css[:-1]\n",
    "    css = css.split('%,%')\n",
    "    return css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxTree = Html2BboxTree(prediction_html, size=image.size)\n",
    "indexList = BboxTree2StyleList(bboxTree, skip_leaf=False)\n",
    "\n",
    "def locateByIndex(bboxTree,index):\n",
    "    target = bboxTree\n",
    "    for i in list(filter(lambda x: x,index.split('-'))):\n",
    "        target = target['children'][int(i)]\n",
    "    return target\n",
    "\n",
    "for item in tqdm(indexList):\n",
    "    bbox = item['bbox']\n",
    "    index = item['index']\n",
    "\n",
    "    if not item['children'] or bbox[2] <= bbox_padding*2 or bbox[3] <= bbox_padding*2:\n",
    "        continue\n",
    "    image_crop = image.crop((bbox[0],bbox[1],bbox[0]+bbox[2],bbox[1]+bbox[3]))\n",
    "    predicted_css = predictStyle(image_crop,item)\n",
    "\n",
    "    for idx, css_item in enumerate(predicted_css):\n",
    "        index_tmp = f\"{index}{'-' if index else ''}{idx}\"\n",
    "        target = locateByIndex(bboxTree, index_tmp)\n",
    "        target['style'] = css_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Text and Image Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['ch_sim','en'])\n",
    "\n",
    "img_idx = 0\n",
    "for item in tqdm(indexList):\n",
    "    if not len(item['children']):\n",
    "        bbox = item['bbox']\n",
    "        index = item['index']\n",
    "        if bbox[2] <= 0 or bbox[3] <= 0:\n",
    "            continue\n",
    "        image_crop = image.crop((bbox[0],bbox[1],bbox[0]+bbox[2],bbox[1]+bbox[3]))\n",
    "        image_crop_text = image.crop((bbox[0]-bbox_padding*5,bbox[1]-bbox_padding*5,bbox[0]+bbox[2]+bbox_padding*10,bbox[1]+bbox[3]+bbox_padding*10)).convert('L')\n",
    "        target = locateByIndex(bboxTree, index)\n",
    "        if item['type'] == 'img':\n",
    "            image_crop.save(os.path.join(output_dir,f'{img_idx}.png'))\n",
    "            target['children'] = [f'{img_idx}.png']\n",
    "            img_idx += 1\n",
    "        else:\n",
    "            result = reader.readtext(np.array(image_crop_text))\n",
    "            text = '\\n'.join(list(map(lambda x: x[1], result)))\n",
    "            target['children'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_html_with_style = BboxTree2Html(bboxTree,style=True)\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir,'index.html'),'w') as f:\n",
    "    f.write(predicted_html_with_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
