from collections import Counter
from utils.eval import eval_ex_match, extract_answer
import random
import json
import numpy as np
from tqdm import tqdm
from fire import Fire
from typing import Union, List, Tuple
import re

def flatten(lst):
    flat_list = []
    for i in lst:
        if isinstance(i, list):
            flat_list.extend(flatten(i))
        else:
            flat_list.append(i)
    return flat_list

def load_results(checkpoints, elements_per_checkpoint):

    print(f"Loading {checkpoints}...")
    # not a list or a tuple, make it a list
    if not isinstance(checkpoints, list) and not isinstance(checkpoints, tuple):
        # try to split by comma
        if "," in checkpoints:
            checkpoints = checkpoints.split(",")
            # remove the spaces
            checkpoints = [checkpoint.strip() for checkpoint in checkpoints]
        else:
            checkpoints = [checkpoints]

    all_results = []

    # read all checkpoints
    for checkpoint in checkpoints:
        print(f"Loading {checkpoint}...")

        if checkpoint.endswith(".jsonl"):
            with open(checkpoint, "r") as f:
                results = [json.loads(line) for line in f.readlines()]
        else:
            with open(f"output/{checkpoint}/result.jsonl", "r") as f:
                results = [json.loads(line) for line in f.readlines()]

        print(f"Loaded {len(results)} results.")


        # deduplicate the results by id
        results = {result["question_id"]: result for result in results}
        results = list(results.values())

        all_results.append(results)

    # make sure the checkpoints are same length, if not, cut the longer one
    min_len = min([len(results) for results in all_results])
    all_results = [results[:min_len] for results in all_results]

    # the results are now in the form of [[dict, dict, ...], [dict, dict, ...], ...]
    # we want to combine them into one list of dicts by aggregating the dict["text"] field
    combined_results = []
    for i, results in enumerate(all_results):
        if i == 0:
            # if this is the first checkpoint, just add the results
            combined_results = results
            # make the text field a list of list
            for result in combined_results:
                # random sample the text field if specified
                if isinstance(result["text"], str):
                    result["text"] = [result["text"]]
                result["text"] = random.sample(result["text"], elements_per_checkpoint[i]) if elements_per_checkpoint else [result["text"]]

        else:
            # if this is not the first checkpoint, add the text field to the existing list
            for j, result in enumerate(results):
                # remember to random sample the text field if specified
                if isinstance(result["text"], str):
                    result["text"] = [result["text"]]
                temp = random.sample(result["text"], elements_per_checkpoint[i]) if elements_per_checkpoint else result["text"]

                # add by question id instead of index
                for k, combined_result in enumerate(combined_results):
                    if combined_result["question_id"] == result["question_id"]:
                        combined_results[k]["text"].append(temp)
                        break

    # now we have a list of dicts with the text field being a list of list
    return combined_results


from typing import List, Dict
import re

def classify_question(question_text: str, table_columns: List[str] = None) -> List[str]:
    """è¿”å›é—®é¢˜æ‰€å±çš„æ‰€æœ‰SQLæ“ä½œç±»åˆ«"""
    question = question_text.lower()
    categories = set()

    # æ£€æµ‹èšåˆå‡½æ•°ï¼ˆCOUNT/SUM/AVGç­‰ï¼‰
    # æ”¹è¿›åçš„èšåˆæ£€æµ‹ï¼ˆè¦†ç›–æ›´å¤šå…³é”®è¯ï¼‰
    aggregation_keywords = [
        r"\b(count\(|sum\(|avg\(|average\(|max\(|min\()",  # å‡½æ•°å½¢å¼
        r"\b(total\b|how many|number of|average of|sum of)",  # è‡ªç„¶è¯­è¨€
        r"\b(most|least)\b.*\b(amount|quantity)\b"  # éšå«èšåˆ
    ]
    if any(re.search(pattern, question) for pattern in aggregation_keywords):
        categories.add("AGGREGATION")

    # æ£€æµ‹æ’åºï¼ˆORDER BYï¼‰
    if re.search(r"\b(order by|sort by|highest|lowest|top|bottom|ascending|descending)", question):
        categories.add("ORDER_BY")

    # æ£€æµ‹åˆ†ç»„ï¼ˆGROUP BYï¼‰
    if re.search(r"\b(group by|per|by each|for each)", question):
        categories.add("GROUP_BY")

    # æ£€æµ‹æ¡ä»¶è¿‡æ»¤ï¼ˆWHEREï¼‰
    condition_keywords = r"(>|<|=|!=|>=|<=|where|and|or|not in|excluding)"
    if re.search(condition_keywords, question):
        if table_columns:  # å¦‚æœæœ‰åˆ—åï¼Œè¿›ä¸€æ­¥éªŒè¯åˆ—å+æ¡ä»¶ç»„åˆ
            for col in table_columns:
                col = col.lower()
                if (col in question) and re.search(condition_keywords, question):
                    categories.add("WHERE")
                    break
        else:  # æ— åˆ—åæ—¶ç›´æ¥åŒ¹é…æ¡ä»¶å…³é”®è¯
            categories.add("WHERE")

    # é»˜è®¤ç±»åˆ«ï¼ˆç®€å•æŸ¥è¯¢ï¼‰
    if not categories:
        categories.add("SELECT")



    return sorted(categories)  # è¿”å›æ’åºåçš„ç±»åˆ«åˆ—è¡¨

# ç¤ºä¾‹è°ƒç”¨
from collections import defaultdict
import numpy as np
from tqdm import tqdm


def eval_wtq_with_multilabel(checkpoints: Union[List, Tuple, str],
                             elements_per_checkpoint: Union[None, int, List] = None,
                             n_times: int = 100,
                             sub_sample_question_ids: list = None):
    # åŠ è½½æ•°æ®
    results = load_results(checkpoints, elements_per_checkpoint)

    # åˆå§‹åŒ–ç»Ÿè®¡å­—å…¸
    sql_categories = ["SELECT", "WHERE", "GROUP_BY", "ORDER_BY", "AGGREGATION", "MULTI_OP"]
    category_stats = {cat: {"correct": 0, "total": 0} for cat in sql_categories}
    acc_list = []  # å­˜å‚¨æ¯è½®çš„æ€»ä½“å‡†ç¡®ç‡

    for _ in tqdm(range(n_times), desc="Evaluating"):
        batch_correct, batch_total = 0, 0

        for result in results:
            if sub_sample_question_ids and result["question_id"] not in sub_sample_question_ids:
                continue

            # å¤šæ ‡ç­¾åˆ†ç±»
            table_columns = result.get("table_columns", [])
            categories = classify_question(result["question"], table_columns)

            # è®¡ç®—å½“å‰é—®é¢˜æ˜¯å¦æ­£ç¡®
            answer = ", ".join(result["answer"])
            preds = flatten([result["text"]]) if isinstance(result["text"], str) else flatten(result["text"])
            preds = [extract_answer(pred) for pred in preds if pred]

            is_correct = False

            if preds:
                final_pred, _ = Counter(preds).most_common(1)[0]
                is_correct = eval_ex_match(answer, final_pred)
                batch_correct += int(is_correct)
            batch_total += 1
            """
            is_correct = False

            if preds:  # æœ‰é¢„æµ‹ç»“æœ
                final_pred, _ = Counter(preds).most_common(1)[0]
                is_correct = eval_ex_match(answer, final_pred)
            else:  # æ²¡æœ‰é¢„æµ‹ç»“æœï¼Œç®—é”™
                is_correct = False
            batch_correct += int(is_correct)
            batch_total += 1
            """
            # æ›´æ–°å¤šæ ‡ç­¾ç»Ÿè®¡
            for cat in categories:
                category_stats[cat]["total"] += 1
                if is_correct:
                    category_stats[cat]["correct"] += 1
            if len(categories) > 1:
                category_stats["MULTI_OP"]["total"] += 1
                if is_correct:
                    category_stats["MULTI_OP"]["correct"] += 1

        acc_list.append(batch_correct / batch_total * 100 if batch_total > 0 else 0)


    # æ‰“å°å…¨å±€ç»Ÿè®¡ï¼ˆä¿ç•™åŸæœ‰è¾“å‡ºï¼‰
    print("\nğŸ“Š ========== å…¨å±€ç»Ÿè®¡ ==========")
    print(f"æ€»æ ·æœ¬æ•°: {len(results)}")
    print(f"æœ€å°å‡†ç¡®ç‡: {min(acc_list):.2f}%")
    print(f"æœ€å¤§å‡†ç¡®ç‡: {max(acc_list):.2f}%")
    print(f"å¹³å‡å‡†ç¡®ç‡: {np.mean(acc_list):.2f}% Â± {np.std(acc_list):.2f}%")


    # æ‰“å°å¤šæ ‡ç­¾åˆ†ç±»ç»“æœ
    print("\nğŸ” ========== å¤šæ ‡ç­¾åˆ†ç±»ç»Ÿè®¡ ==========")
    for category in sql_categories:
        stats = category_stats[category]
        if stats["total"] > 0:
            accuracy = stats["correct"] / stats["total"] * 100
            print(f"{category.ljust(10)}: {accuracy:.2f}% ({stats['correct']}/{stats['total']})")
        else:
            print(f"{category.ljust(10)}: æ— æ ·æœ¬")

    # å¤šæ“ä½œé—®é¢˜å æ¯”
    multi_op_ratio = category_stats["MULTI_OP"]["total"] / len(results) * 100
    print(f"\nğŸ”¹ å¤šæ“ä½œé—®é¢˜å æ¯”: {multi_op_ratio:.1f}%")

if __name__ == "__main__":
    #Fire(eval_wtq)
    #eval_wtq(checkpoints ="./assets/results/wtq-cot-all/result_5.jsonl",n_times=100)
    eval_wtq_with_multilabel(checkpoints="./output/wtq_agent/result.jsonl", n_times=1
             )