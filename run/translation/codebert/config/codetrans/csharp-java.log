nohup: ignoring input
Using backend: pytorch
[2021-11-05 07:54:21]    INFO >> No /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt to initialize model (train.py:86, <module>())
[2021-11-05 07:54:21]    INFO >> Start training epoch   1/100, best bleu4: 0.00 (train.py:88, <module>())
/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[2021-11-05 07:56:18]    INFO >> Epoch   1/100, Batch 500/2575, train loss: 500.3873 (train.py:125, train())
[2021-11-05 07:58:00]    INFO >> Epoch   1/100, Batch 1000/2575, train loss: 424.2110 (train.py:125, train())
[2021-11-05 07:59:42]    INFO >> Epoch   1/100, Batch 1500/2575, train loss: 389.6131 (train.py:125, train())
[2021-11-05 08:01:21]    INFO >> Epoch   1/100, Batch 2000/2575, train loss: 362.0164 (train.py:125, train())
[2021-11-05 08:03:06]    INFO >> Epoch   1/100, Batch 2500/2575, train loss: 337.0149 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:03:19]    INFO >> Epoch   1/100, train loss: 334.5951 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:07:19]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 08:07:19]    INFO >> Epoch   1/100, valid loss: 0.0000, valid bleu4: 5.98, best bleu4: 5.98 (train.py:210, <module>())
[2021-11-05 08:07:23]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:09:13]    INFO >> Epoch   2/100, Batch 500/2575, train loss: 229.7788 (train.py:125, train())
[2021-11-05 08:10:54]    INFO >> Epoch   2/100, Batch 1000/2575, train loss: 216.5782 (train.py:125, train())
[2021-11-05 08:12:38]    INFO >> Epoch   2/100, Batch 1500/2575, train loss: 208.2203 (train.py:125, train())
[2021-11-05 08:14:19]    INFO >> Epoch   2/100, Batch 2000/2575, train loss: 200.0712 (train.py:125, train())
[2021-11-05 08:15:59]    INFO >> Epoch   2/100, Batch 2500/2575, train loss: 192.2715 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:16:16]    INFO >> Epoch   2/100, train loss: 191.4174 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:20:18]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 08:20:18]    INFO >> Epoch   2/100, valid loss: 0.0000, valid bleu4: 6.36, best bleu4: 6.36 (train.py:210, <module>())
[2021-11-05 08:20:27]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:22:15]    INFO >> Epoch   3/100, Batch 500/2575, train loss: 149.4240 (train.py:125, train())
[2021-11-05 08:24:00]    INFO >> Epoch   3/100, Batch 1000/2575, train loss: 147.5121 (train.py:125, train())
[2021-11-05 08:25:33]    INFO >> Epoch   3/100, Batch 1500/2575, train loss: 141.2543 (train.py:125, train())
[2021-11-05 08:27:08]    INFO >> Epoch   3/100, Batch 2000/2575, train loss: 137.8123 (train.py:125, train())
[2021-11-05 08:28:53]    INFO >> Epoch   3/100, Batch 2500/2575, train loss: 136.4072 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:29:07]    INFO >> Epoch   3/100, train loss: 136.1976 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:33:13]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 08:33:13]    INFO >> Epoch   3/100, valid loss: 0.0000, valid bleu4: 13.24, best bleu4: 13.24 (train.py:210, <module>())
[2021-11-05 08:33:21]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:35:09]    INFO >> Epoch   4/100, Batch 500/2575, train loss: 117.2841 (train.py:125, train())
[2021-11-05 08:36:46]    INFO >> Epoch   4/100, Batch 1000/2575, train loss: 109.8214 (train.py:125, train())
[2021-11-05 08:38:29]    INFO >> Epoch   4/100, Batch 1500/2575, train loss: 107.5827 (train.py:125, train())
[2021-11-05 08:40:14]    INFO >> Epoch   4/100, Batch 2000/2575, train loss: 104.0523 (train.py:125, train())
[2021-11-05 08:41:55]    INFO >> Epoch   4/100, Batch 2500/2575, train loss: 103.7223 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:42:12]    INFO >> Epoch   4/100, train loss: 103.3178 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:46:09]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 08:46:09]    INFO >> Epoch   4/100, valid loss: 0.0000, valid bleu4: 20.79, best bleu4: 20.79 (train.py:210, <module>())
[2021-11-05 08:46:18]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:48:06]    INFO >> Epoch   5/100, Batch 500/2575, train loss: 83.5541 (train.py:125, train())
[2021-11-05 08:49:49]    INFO >> Epoch   5/100, Batch 1000/2575, train loss: 82.6317 (train.py:125, train())
[2021-11-05 08:51:27]    INFO >> Epoch   5/100, Batch 1500/2575, train loss: 81.8083 (train.py:125, train())
[2021-11-05 08:53:09]    INFO >> Epoch   5/100, Batch 2000/2575, train loss: 80.1967 (train.py:125, train())
[2021-11-05 08:54:51]    INFO >> Epoch   5/100, Batch 2500/2575, train loss: 77.2531 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:55:08]    INFO >> Epoch   5/100, train loss: 76.9382 (train.py:134, <module>())
[2021-11-05 08:55:12]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/5.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:59:22]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 08:59:22]    INFO >> Epoch   5/100, valid loss: 0.0000, valid bleu4: 24.97, best bleu4: 24.97 (train.py:210, <module>())
[2021-11-05 08:59:30]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:01:25]    INFO >> Epoch   6/100, Batch 500/2575, train loss: 58.9900 (train.py:125, train())
[2021-11-05 09:03:08]    INFO >> Epoch   6/100, Batch 1000/2575, train loss: 58.8847 (train.py:125, train())
[2021-11-05 09:04:51]    INFO >> Epoch   6/100, Batch 1500/2575, train loss: 57.0251 (train.py:125, train())
[2021-11-05 09:06:32]    INFO >> Epoch   6/100, Batch 2000/2575, train loss: 55.6534 (train.py:125, train())
[2021-11-05 09:08:16]    INFO >> Epoch   6/100, Batch 2500/2575, train loss: 55.4592 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:08:32]    INFO >> Epoch   6/100, train loss: 55.3909 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:12:42]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 09:12:42]    INFO >> Epoch   6/100, valid loss: 0.0000, valid bleu4: 39.03, best bleu4: 39.03 (train.py:210, <module>())
[2021-11-05 09:12:52]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:14:46]    INFO >> Epoch   7/100, Batch 500/2575, train loss: 40.4476 (train.py:125, train())
[2021-11-05 09:16:29]    INFO >> Epoch   7/100, Batch 1000/2575, train loss: 40.0189 (train.py:125, train())
[2021-11-05 09:18:11]    INFO >> Epoch   7/100, Batch 1500/2575, train loss: 40.3981 (train.py:125, train())
[2021-11-05 09:19:53]    INFO >> Epoch   7/100, Batch 2000/2575, train loss: 40.6100 (train.py:125, train())
[2021-11-05 09:21:39]    INFO >> Epoch   7/100, Batch 2500/2575, train loss: 39.8360 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:21:53]    INFO >> Epoch   7/100, train loss: 39.7238 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:26:03]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 09:26:03]    INFO >> Epoch   7/100, valid loss: 0.0000, valid bleu4: 47.01, best bleu4: 47.01 (train.py:210, <module>())
[2021-11-05 09:26:11]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:27:59]    INFO >> Epoch   8/100, Batch 500/2575, train loss: 28.8837 (train.py:125, train())
[2021-11-05 09:29:38]    INFO >> Epoch   8/100, Batch 1000/2575, train loss: 30.5016 (train.py:125, train())
[2021-11-05 09:31:20]    INFO >> Epoch   8/100, Batch 1500/2575, train loss: 30.1778 (train.py:125, train())
[2021-11-05 09:33:06]    INFO >> Epoch   8/100, Batch 2000/2575, train loss: 30.0966 (train.py:125, train())
[2021-11-05 09:34:51]    INFO >> Epoch   8/100, Batch 2500/2575, train loss: 30.1020 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:35:07]    INFO >> Epoch   8/100, train loss: 30.0407 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:39:12]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 09:39:12]    INFO >> Epoch   8/100, valid loss: 0.0000, valid bleu4: 49.92, best bleu4: 49.92 (train.py:210, <module>())
[2021-11-05 09:39:20]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:41:14]    INFO >> Epoch   9/100, Batch 500/2575, train loss: 22.3635 (train.py:125, train())
[2021-11-05 09:44:03]    INFO >> Epoch   9/100, Batch 1000/2575, train loss: 24.0142 (train.py:125, train())
[2021-11-05 09:46:19]    INFO >> Epoch   9/100, Batch 1500/2575, train loss: 24.1642 (train.py:125, train())
[2021-11-05 09:48:35]    INFO >> Epoch   9/100, Batch 2000/2575, train loss: 23.7872 (train.py:125, train())
[2021-11-05 09:50:50]    INFO >> Epoch   9/100, Batch 2500/2575, train loss: 24.1094 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:51:07]    INFO >> Epoch   9/100, train loss: 24.2457 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:57:06]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 09:57:06]    INFO >> Epoch   9/100, valid loss: 0.0000, valid bleu4: 55.12, best bleu4: 55.12 (train.py:210, <module>())
[2021-11-05 09:57:15]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:58:54]    INFO >> Epoch  10/100, Batch 500/2575, train loss: 19.5431 (train.py:125, train())
[2021-11-05 10:01:11]    INFO >> Epoch  10/100, Batch 1000/2575, train loss: 19.6402 (train.py:125, train())
[2021-11-05 10:03:27]    INFO >> Epoch  10/100, Batch 1500/2575, train loss: 19.9727 (train.py:125, train())
[2021-11-05 10:05:44]    INFO >> Epoch  10/100, Batch 2000/2575, train loss: 20.2930 (train.py:125, train())
[2021-11-05 10:08:01]    INFO >> Epoch  10/100, Batch 2500/2575, train loss: 20.3326 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:08:26]    INFO >> Epoch  10/100, train loss: 20.2396 (train.py:134, <module>())
[2021-11-05 10:08:30]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/10.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:14:37]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 10:14:37]    INFO >> Epoch  10/100, valid loss: 0.0000, valid bleu4: 59.03, best bleu4: 59.03 (train.py:210, <module>())
[2021-11-05 10:14:45]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 10:17:35]    INFO >> Epoch  11/100, Batch 500/2575, train loss: 17.4217 (train.py:125, train())
[2021-11-05 10:19:38]    INFO >> Epoch  11/100, Batch 1000/2575, train loss: 17.0816 (train.py:125, train())
[2021-11-05 10:21:55]    INFO >> Epoch  11/100, Batch 1500/2575, train loss: 16.7801 (train.py:125, train())
[2021-11-05 10:24:09]    INFO >> Epoch  11/100, Batch 2000/2575, train loss: 16.6933 (train.py:125, train())
[2021-11-05 10:26:25]    INFO >> Epoch  11/100, Batch 2500/2575, train loss: 16.6524 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:26:46]    INFO >> Epoch  11/100, train loss: 16.9216 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:32:39]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 10:32:39]    INFO >> Epoch  11/100, valid loss: 0.0000, valid bleu4: 60.25, best bleu4: 60.25 (train.py:210, <module>())
[2021-11-05 10:32:47]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 10:35:37]    INFO >> Epoch  12/100, Batch 500/2575, train loss: 13.0860 (train.py:125, train())
[2021-11-05 10:38:07]    INFO >> Epoch  12/100, Batch 1000/2575, train loss: 13.6528 (train.py:125, train())
[2021-11-05 10:40:15]    INFO >> Epoch  12/100, Batch 1500/2575, train loss: 13.4148 (train.py:125, train())
[2021-11-05 10:42:43]    INFO >> Epoch  12/100, Batch 2000/2575, train loss: 13.6459 (train.py:125, train())
[2021-11-05 10:45:05]    INFO >> Epoch  12/100, Batch 2500/2575, train loss: 13.7783 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:45:26]    INFO >> Epoch  12/100, train loss: 13.8348 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:50:57]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 10:50:57]    INFO >> Epoch  12/100, valid loss: 0.0000, valid bleu4: 60.46, best bleu4: 60.46 (train.py:210, <module>())
[2021-11-05 10:51:05]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 10:53:54]    INFO >> Epoch  13/100, Batch 500/2575, train loss: 10.5319 (train.py:125, train())
[2021-11-05 10:56:35]    INFO >> Epoch  13/100, Batch 1000/2575, train loss: 10.5728 (train.py:125, train())
[2021-11-05 10:58:44]    INFO >> Epoch  13/100, Batch 1500/2575, train loss: 11.1127 (train.py:125, train())
[2021-11-05 11:01:01]    INFO >> Epoch  13/100, Batch 2000/2575, train loss: 11.1929 (train.py:125, train())
[2021-11-05 11:03:16]    INFO >> Epoch  13/100, Batch 2500/2575, train loss: 11.3286 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:03:36]    INFO >> Epoch  13/100, train loss: 11.2771 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:08:47]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 11:08:47]    INFO >> Epoch  13/100, valid loss: 0.0000, valid bleu4: 62.39, best bleu4: 62.39 (train.py:210, <module>())
[2021-11-05 11:08:55]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 11:11:44]    INFO >> Epoch  14/100, Batch 500/2575, train loss: 9.6843 (train.py:125, train())
[2021-11-05 11:14:26]    INFO >> Epoch  14/100, Batch 1000/2575, train loss: 9.6331 (train.py:125, train())
[2021-11-05 11:17:08]    INFO >> Epoch  14/100, Batch 1500/2575, train loss: 9.5433 (train.py:125, train())
[2021-11-05 11:19:15]    INFO >> Epoch  14/100, Batch 2000/2575, train loss: 9.3777 (train.py:125, train())
[2021-11-05 11:21:31]    INFO >> Epoch  14/100, Batch 2500/2575, train loss: 9.4925 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:21:51]    INFO >> Epoch  14/100, train loss: 9.5243 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:27:01]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 11:27:01]    INFO >> Epoch  14/100, valid loss: 0.0000, valid bleu4: 63.20, best bleu4: 63.20 (train.py:210, <module>())
[2021-11-05 11:27:09]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 11:29:27]    INFO >> Epoch  15/100, Batch 500/2575, train loss: 8.1669 (train.py:125, train())
[2021-11-05 11:32:09]    INFO >> Epoch  15/100, Batch 1000/2575, train loss: 8.0214 (train.py:125, train())
[2021-11-05 11:34:50]    INFO >> Epoch  15/100, Batch 1500/2575, train loss: 7.7056 (train.py:125, train())
[2021-11-05 11:37:31]    INFO >> Epoch  15/100, Batch 2000/2575, train loss: 7.8687 (train.py:125, train())
[2021-11-05 11:39:37]    INFO >> Epoch  15/100, Batch 2500/2575, train loss: 8.0634 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:39:58]    INFO >> Epoch  15/100, train loss: 8.0460 (train.py:134, <module>())
[2021-11-05 11:40:02]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/15.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:45:12]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 11:45:12]    INFO >> Epoch  15/100, valid loss: 0.0000, valid bleu4: 63.67, best bleu4: 63.67 (train.py:210, <module>())
[2021-11-05 11:45:20]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 11:47:44]    INFO >> Epoch  16/100, Batch 500/2575, train loss: 6.5586 (train.py:125, train())
[2021-11-05 11:50:01]    INFO >> Epoch  16/100, Batch 1000/2575, train loss: 6.9216 (train.py:125, train())
[2021-11-05 11:52:42]    INFO >> Epoch  16/100, Batch 1500/2575, train loss: 6.8362 (train.py:125, train())
[2021-11-05 11:55:24]    INFO >> Epoch  16/100, Batch 2000/2575, train loss: 6.9434 (train.py:125, train())
[2021-11-05 11:58:05]    INFO >> Epoch  16/100, Batch 2500/2575, train loss: 6.9327 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:58:30]    INFO >> Epoch  16/100, train loss: 6.9747 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:03:14]    INFO >> Epoch  16/100, valid loss: 0.0000, valid bleu4: 63.18, best bleu4: 63.67 (train.py:210, <module>())
[2021-11-05 12:03:22]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 12:05:46]    INFO >> Epoch  17/100, Batch 500/2575, train loss: 7.0430 (train.py:125, train())
[2021-11-05 12:08:02]    INFO >> Epoch  17/100, Batch 1000/2575, train loss: 6.4235 (train.py:125, train())
[2021-11-05 12:10:15]    INFO >> Epoch  17/100, Batch 1500/2575, train loss: 6.1268 (train.py:125, train())
[2021-11-05 12:12:56]    INFO >> Epoch  17/100, Batch 2000/2575, train loss: 6.1021 (train.py:125, train())
[2021-11-05 12:15:38]    INFO >> Epoch  17/100, Batch 2500/2575, train loss: 6.0224 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:16:03]    INFO >> Epoch  17/100, train loss: 6.0339 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:21:26]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 12:21:26]    INFO >> Epoch  17/100, valid loss: 0.0000, valid bleu4: 67.41, best bleu4: 67.41 (train.py:210, <module>())
[2021-11-05 12:21:35]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 12:23:56]    INFO >> Epoch  18/100, Batch 500/2575, train loss: 5.2834 (train.py:125, train())
[2021-11-05 12:26:13]    INFO >> Epoch  18/100, Batch 1000/2575, train loss: 5.0354 (train.py:125, train())
[2021-11-05 12:28:28]    INFO >> Epoch  18/100, Batch 1500/2575, train loss: 5.0860 (train.py:125, train())
[2021-11-05 12:30:50]    INFO >> Epoch  18/100, Batch 2000/2575, train loss: 5.2274 (train.py:125, train())
[2021-11-05 12:33:32]    INFO >> Epoch  18/100, Batch 2500/2575, train loss: 5.3074 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:33:57]    INFO >> Epoch  18/100, train loss: 5.3060 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:40:06]    INFO >> Epoch  18/100, valid loss: 0.0000, valid bleu4: 65.55, best bleu4: 67.41 (train.py:210, <module>())
[2021-11-05 12:40:14]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 12:42:45]    INFO >> Epoch  19/100, Batch 500/2575, train loss: 4.7585 (train.py:125, train())
[2021-11-05 12:45:24]    INFO >> Epoch  19/100, Batch 1000/2575, train loss: 4.8371 (train.py:125, train())
[2021-11-05 12:48:02]    INFO >> Epoch  19/100, Batch 1500/2575, train loss: 4.6922 (train.py:125, train())
[2021-11-05 12:50:40]    INFO >> Epoch  19/100, Batch 2000/2575, train loss: 4.8080 (train.py:125, train())
[2021-11-05 12:53:26]    INFO >> Epoch  19/100, Batch 2500/2575, train loss: 4.8188 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:53:54]    INFO >> Epoch  19/100, train loss: 4.8207 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:00:41]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 13:00:41]    INFO >> Epoch  19/100, valid loss: 0.0000, valid bleu4: 67.70, best bleu4: 67.70 (train.py:210, <module>())
[2021-11-05 13:00:49]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 13:04:03]    INFO >> Epoch  20/100, Batch 500/2575, train loss: 3.7173 (train.py:125, train())
[2021-11-05 13:06:26]    INFO >> Epoch  20/100, Batch 1000/2575, train loss: 3.8062 (train.py:125, train())
[2021-11-05 13:09:05]    INFO >> Epoch  20/100, Batch 1500/2575, train loss: 3.9376 (train.py:125, train())
[2021-11-05 13:11:45]    INFO >> Epoch  20/100, Batch 2000/2575, train loss: 4.1114 (train.py:125, train())
[2021-11-05 13:14:22]    INFO >> Epoch  20/100, Batch 2500/2575, train loss: 4.1343 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:14:47]    INFO >> Epoch  20/100, train loss: 4.1528 (train.py:134, <module>())
[2021-11-05 13:14:51]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/20.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:21:14]    INFO >> Epoch  20/100, valid loss: 0.0000, valid bleu4: 67.26, best bleu4: 67.70 (train.py:210, <module>())
[2021-11-05 13:21:21]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 13:24:37]    INFO >> Epoch  21/100, Batch 500/2575, train loss: 4.0073 (train.py:125, train())
[2021-11-05 13:27:44]    INFO >> Epoch  21/100, Batch 1000/2575, train loss: 3.8474 (train.py:125, train())
[2021-11-05 13:30:10]    INFO >> Epoch  21/100, Batch 1500/2575, train loss: 3.7578 (train.py:125, train())
[2021-11-05 13:32:52]    INFO >> Epoch  21/100, Batch 2000/2575, train loss: 3.8734 (train.py:125, train())
[2021-11-05 13:35:32]    INFO >> Epoch  21/100, Batch 2500/2575, train loss: 3.8727 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:35:58]    INFO >> Epoch  21/100, train loss: 3.8459 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:41:53]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 13:41:53]    INFO >> Epoch  21/100, valid loss: 0.0000, valid bleu4: 69.05, best bleu4: 69.05 (train.py:210, <module>())
[2021-11-05 13:42:02]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 13:45:22]    INFO >> Epoch  22/100, Batch 500/2575, train loss: 3.2242 (train.py:125, train())
[2021-11-05 13:48:31]    INFO >> Epoch  22/100, Batch 1000/2575, train loss: 3.2896 (train.py:125, train())
[2021-11-05 13:51:39]    INFO >> Epoch  22/100, Batch 1500/2575, train loss: 3.3418 (train.py:125, train())
[2021-11-05 13:54:03]    INFO >> Epoch  22/100, Batch 2000/2575, train loss: 3.3635 (train.py:125, train())
[2021-11-05 13:56:21]    INFO >> Epoch  22/100, Batch 2500/2575, train loss: 3.3398 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:56:42]    INFO >> Epoch  22/100, train loss: 3.3432 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:01:45]    INFO >> Epoch  22/100, valid loss: 0.0000, valid bleu4: 67.87, best bleu4: 69.05 (train.py:210, <module>())
[2021-11-05 14:01:53]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 14:04:25]    INFO >> Epoch  23/100, Batch 500/2575, train loss: 3.0477 (train.py:125, train())
[2021-11-05 14:07:06]    INFO >> Epoch  23/100, Batch 1000/2575, train loss: 2.8998 (train.py:125, train())
[2021-11-05 14:09:48]    INFO >> Epoch  23/100, Batch 1500/2575, train loss: 3.0189 (train.py:125, train())
[2021-11-05 14:12:29]    INFO >> Epoch  23/100, Batch 2000/2575, train loss: 3.0603 (train.py:125, train())
[2021-11-05 14:14:23]    INFO >> Epoch  23/100, Batch 2500/2575, train loss: 3.1583 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:14:44]    INFO >> Epoch  23/100, train loss: 3.1504 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:19:46]    INFO >> Epoch  23/100, valid loss: 0.0000, valid bleu4: 67.99, best bleu4: 69.05 (train.py:210, <module>())
[2021-11-05 14:19:54]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 14:22:17]    INFO >> Epoch  24/100, Batch 500/2575, train loss: 2.8650 (train.py:125, train())
[2021-11-05 14:24:40]    INFO >> Epoch  24/100, Batch 1000/2575, train loss: 2.7563 (train.py:125, train())
[2021-11-05 14:27:21]    INFO >> Epoch  24/100, Batch 1500/2575, train loss: 2.7521 (train.py:125, train())
[2021-11-05 14:30:03]    INFO >> Epoch  24/100, Batch 2000/2575, train loss: 2.8826 (train.py:125, train())
[2021-11-05 14:32:44]    INFO >> Epoch  24/100, Batch 2500/2575, train loss: 2.9393 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:33:08]    INFO >> Epoch  24/100, train loss: 2.9382 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:38:00]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 14:38:00]    INFO >> Epoch  24/100, valid loss: 0.0000, valid bleu4: 69.47, best bleu4: 69.47 (train.py:210, <module>())
[2021-11-05 14:38:09]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 14:40:32]    INFO >> Epoch  25/100, Batch 500/2575, train loss: 3.5846 (train.py:125, train())
[2021-11-05 14:42:47]    INFO >> Epoch  25/100, Batch 1000/2575, train loss: 3.0790 (train.py:125, train())
[2021-11-05 14:45:11]    INFO >> Epoch  25/100, Batch 1500/2575, train loss: 2.8733 (train.py:125, train())
[2021-11-05 14:47:53]    INFO >> Epoch  25/100, Batch 2000/2575, train loss: 2.8244 (train.py:125, train())
[2021-11-05 14:50:34]    INFO >> Epoch  25/100, Batch 2500/2575, train loss: 2.7281 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:50:59]    INFO >> Epoch  25/100, train loss: 2.7305 (train.py:134, <module>())
[2021-11-05 14:51:03]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/25.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:56:14]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 14:56:14]    INFO >> Epoch  25/100, valid loss: 0.0000, valid bleu4: 69.56, best bleu4: 69.56 (train.py:210, <module>())
[2021-11-05 14:56:22]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 14:58:47]    INFO >> Epoch  26/100, Batch 500/2575, train loss: 2.1800 (train.py:125, train())
[2021-11-05 15:01:02]    INFO >> Epoch  26/100, Batch 1000/2575, train loss: 2.3143 (train.py:125, train())
[2021-11-05 15:03:18]    INFO >> Epoch  26/100, Batch 1500/2575, train loss: 2.4065 (train.py:125, train())
[2021-11-05 15:05:45]    INFO >> Epoch  26/100, Batch 2000/2575, train loss: 2.4337 (train.py:125, train())
[2021-11-05 15:08:27]    INFO >> Epoch  26/100, Batch 2500/2575, train loss: 2.5192 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:08:52]    INFO >> Epoch  26/100, train loss: 2.5172 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:14:44]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 15:14:44]    INFO >> Epoch  26/100, valid loss: 0.0000, valid bleu4: 70.20, best bleu4: 70.20 (train.py:210, <module>())
[2021-11-05 15:14:52]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 15:17:16]    INFO >> Epoch  27/100, Batch 500/2575, train loss: 2.1889 (train.py:125, train())
[2021-11-05 15:19:32]    INFO >> Epoch  27/100, Batch 1000/2575, train loss: 2.2215 (train.py:125, train())
[2021-11-05 15:21:45]    INFO >> Epoch  27/100, Batch 1500/2575, train loss: 2.2361 (train.py:125, train())
[2021-11-05 15:23:58]    INFO >> Epoch  27/100, Batch 2000/2575, train loss: 2.2591 (train.py:125, train())
[2021-11-05 15:26:39]    INFO >> Epoch  27/100, Batch 2500/2575, train loss: 2.2780 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:27:04]    INFO >> Epoch  27/100, train loss: 2.2843 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:33:02]    INFO >> Epoch  27/100, valid loss: 0.0000, valid bleu4: 70.09, best bleu4: 70.20 (train.py:210, <module>())
[2021-11-05 15:33:10]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 15:35:19]    INFO >> Epoch  28/100, Batch 500/2575, train loss: 2.1058 (train.py:125, train())
[2021-11-05 15:37:33]    INFO >> Epoch  28/100, Batch 1000/2575, train loss: 2.1658 (train.py:125, train())
[2021-11-05 15:39:47]    INFO >> Epoch  28/100, Batch 1500/2575, train loss: 2.1638 (train.py:125, train())
[2021-11-05 15:42:01]    INFO >> Epoch  28/100, Batch 2000/2575, train loss: 2.1426 (train.py:125, train())
[2021-11-05 15:44:11]    INFO >> Epoch  28/100, Batch 2500/2575, train loss: 2.1400 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:44:36]    INFO >> Epoch  28/100, train loss: 2.1437 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:50:34]    INFO >> Epoch  28/100, valid loss: 0.0000, valid bleu4: 69.21, best bleu4: 70.20 (train.py:210, <module>())
[2021-11-05 15:50:42]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 15:53:31]    INFO >> Epoch  29/100, Batch 500/2575, train loss: 2.0812 (train.py:125, train())
[2021-11-05 15:55:36]    INFO >> Epoch  29/100, Batch 1000/2575, train loss: 1.9774 (train.py:125, train())
[2021-11-05 15:57:51]    INFO >> Epoch  29/100, Batch 1500/2575, train loss: 1.9972 (train.py:125, train())
[2021-11-05 16:00:07]    INFO >> Epoch  29/100, Batch 2000/2575, train loss: 2.0373 (train.py:125, train())
[2021-11-05 16:02:45]    INFO >> Epoch  29/100, Batch 2500/2575, train loss: 2.0439 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:03:10]    INFO >> Epoch  29/100, train loss: 2.0452 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:09:17]    INFO >> Epoch  29/100, valid loss: 0.0000, valid bleu4: 69.70, best bleu4: 70.20 (train.py:210, <module>())
[2021-11-05 16:09:25]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 16:12:37]    INFO >> Epoch  30/100, Batch 500/2575, train loss: 2.1041 (train.py:125, train())
[2021-11-05 16:15:43]    INFO >> Epoch  30/100, Batch 1000/2575, train loss: 2.0050 (train.py:125, train())
[2021-11-05 16:18:18]    INFO >> Epoch  30/100, Batch 1500/2575, train loss: 1.9294 (train.py:125, train())
[2021-11-05 16:20:57]    INFO >> Epoch  30/100, Batch 2000/2575, train loss: 1.9606 (train.py:125, train())
[2021-11-05 16:23:35]    INFO >> Epoch  30/100, Batch 2500/2575, train loss: 1.8994 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:24:00]    INFO >> Epoch  30/100, train loss: 1.8938 (train.py:134, <module>())
[2021-11-05 16:24:04]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/30.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:29:54]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 16:29:54]    INFO >> Epoch  30/100, valid loss: 0.0000, valid bleu4: 71.48, best bleu4: 71.48 (train.py:210, <module>())
[2021-11-05 16:30:02]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 16:33:17]    INFO >> Epoch  31/100, Batch 500/2575, train loss: 1.9256 (train.py:125, train())
[2021-11-05 16:36:21]    INFO >> Epoch  31/100, Batch 1000/2575, train loss: 1.9184 (train.py:125, train())
[2021-11-05 16:39:24]    INFO >> Epoch  31/100, Batch 1500/2575, train loss: 1.8067 (train.py:125, train())
[2021-11-05 16:42:00]    INFO >> Epoch  31/100, Batch 2000/2575, train loss: 1.7718 (train.py:125, train())
[2021-11-05 16:44:38]    INFO >> Epoch  31/100, Batch 2500/2575, train loss: 1.7758 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:45:03]    INFO >> Epoch  31/100, train loss: 1.7659 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:50:44]    INFO >> Epoch  31/100, valid loss: 0.0000, valid bleu4: 70.32, best bleu4: 71.48 (train.py:210, <module>())
[2021-11-05 16:50:52]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 16:53:32]    INFO >> Epoch  32/100, Batch 500/2575, train loss: 1.6818 (train.py:125, train())
[2021-11-05 16:56:38]    INFO >> Epoch  32/100, Batch 1000/2575, train loss: 1.7599 (train.py:125, train())
[2021-11-05 16:59:44]    INFO >> Epoch  32/100, Batch 1500/2575, train loss: 1.6930 (train.py:125, train())
[2021-11-05 17:02:49]    INFO >> Epoch  32/100, Batch 2000/2575, train loss: 1.7018 (train.py:125, train())
[2021-11-05 17:05:27]    INFO >> Epoch  32/100, Batch 2500/2575, train loss: 1.7316 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:05:51]    INFO >> Epoch  32/100, train loss: 1.7331 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:11:34]    INFO >> Epoch  32/100, valid loss: 0.0000, valid bleu4: 69.92, best bleu4: 71.48 (train.py:210, <module>())
[2021-11-05 17:11:42]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 17:14:27]    INFO >> Epoch  33/100, Batch 500/2575, train loss: 1.5621 (train.py:125, train())
[2021-11-05 17:17:05]    INFO >> Epoch  33/100, Batch 1000/2575, train loss: 1.6704 (train.py:125, train())
[2021-11-05 17:19:55]    INFO >> Epoch  33/100, Batch 1500/2575, train loss: 1.6179 (train.py:125, train())
[2021-11-05 17:22:36]    INFO >> Epoch  33/100, Batch 2000/2575, train loss: 1.6190 (train.py:125, train())
[2021-11-05 17:25:18]    INFO >> Epoch  33/100, Batch 2500/2575, train loss: 1.6280 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:25:43]    INFO >> Epoch  33/100, train loss: 1.6256 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:30:36]    INFO >> Epoch  33/100, valid loss: 0.0000, valid bleu4: 71.29, best bleu4: 71.48 (train.py:210, <module>())
[2021-11-05 17:30:44]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 17:33:08]    INFO >> Epoch  34/100, Batch 500/2575, train loss: 1.4783 (train.py:125, train())
[2021-11-05 17:35:23]    INFO >> Epoch  34/100, Batch 1000/2575, train loss: 1.4578 (train.py:125, train())
[2021-11-05 17:37:35]    INFO >> Epoch  34/100, Batch 1500/2575, train loss: 1.4398 (train.py:125, train())
[2021-11-05 17:40:16]    INFO >> Epoch  34/100, Batch 2000/2575, train loss: 1.4546 (train.py:125, train())
[2021-11-05 17:42:58]    INFO >> Epoch  34/100, Batch 2500/2575, train loss: 1.4735 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:43:22]    INFO >> Epoch  34/100, train loss: 1.4819 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:48:59]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 17:48:59]    INFO >> Epoch  34/100, valid loss: 0.0000, valid bleu4: 71.56, best bleu4: 71.56 (train.py:210, <module>())
[2021-11-05 17:49:08]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 17:51:31]    INFO >> Epoch  35/100, Batch 500/2575, train loss: 1.2743 (train.py:125, train())
[2021-11-05 17:53:46]    INFO >> Epoch  35/100, Batch 1000/2575, train loss: 1.3740 (train.py:125, train())
[2021-11-05 17:55:59]    INFO >> Epoch  35/100, Batch 1500/2575, train loss: 1.3769 (train.py:125, train())
[2021-11-05 17:58:08]    INFO >> Epoch  35/100, Batch 2000/2575, train loss: 1.4020 (train.py:125, train())
[2021-11-05 18:00:50]    INFO >> Epoch  35/100, Batch 2500/2575, train loss: 1.4092 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:01:15]    INFO >> Epoch  35/100, train loss: 1.4054 (train.py:134, <module>())
[2021-11-05 18:01:19]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/35.pt (train.py:200, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:07:26]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 18:07:26]    INFO >> Epoch  35/100, valid loss: 0.0000, valid bleu4: 71.94, best bleu4: 71.94 (train.py:210, <module>())
[2021-11-05 18:07:34]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 18:09:36]    INFO >> Epoch  36/100, Batch 500/2575, train loss: 1.2639 (train.py:125, train())
[2021-11-05 18:11:52]    INFO >> Epoch  36/100, Batch 1000/2575, train loss: 1.3715 (train.py:125, train())
[2021-11-05 18:14:07]    INFO >> Epoch  36/100, Batch 1500/2575, train loss: 1.3585 (train.py:125, train())
[2021-11-05 18:16:22]    INFO >> Epoch  36/100, Batch 2000/2575, train loss: 1.3736 (train.py:125, train())
[2021-11-05 18:18:40]    INFO >> Epoch  36/100, Batch 2500/2575, train loss: 1.3533 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:19:05]    INFO >> Epoch  36/100, train loss: 1.3443 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:25:11]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/best_checkpoint.pt (train.py:208, <module>())
[2021-11-05 18:25:11]    INFO >> Epoch  36/100, valid loss: 0.0000, valid bleu4: 72.89, best bleu4: 72.89 (train.py:210, <module>())
[2021-11-05 18:25:19]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 18:28:09]    INFO >> Epoch  37/100, Batch 500/2575, train loss: 1.2948 (train.py:125, train())
[2021-11-05 18:30:10]    INFO >> Epoch  37/100, Batch 1000/2575, train loss: 1.2177 (train.py:125, train())
[2021-11-05 18:32:26]    INFO >> Epoch  37/100, Batch 1500/2575, train loss: 1.2344 (train.py:125, train())
[2021-11-05 18:34:42]    INFO >> Epoch  37/100, Batch 2000/2575, train loss: 1.2424 (train.py:125, train())
[2021-11-05 18:36:57]    INFO >> Epoch  37/100, Batch 2500/2575, train loss: 1.2463 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:37:18]    INFO >> Epoch  37/100, train loss: 1.2531 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:42:58]    INFO >> Epoch  37/100, valid loss: 0.0000, valid bleu4: 71.70, best bleu4: 72.89 (train.py:210, <module>())
[2021-11-05 18:43:06]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 18:45:56]    INFO >> Epoch  38/100, Batch 500/2575, train loss: 1.3606 (train.py:125, train())
[2021-11-05 18:48:32]    INFO >> Epoch  38/100, Batch 1000/2575, train loss: 1.2935 (train.py:125, train())
[2021-11-05 18:50:36]    INFO >> Epoch  38/100, Batch 1500/2575, train loss: 1.2500 (train.py:125, train())
[2021-11-05 18:52:44]    INFO >> Epoch  38/100, Batch 2000/2575, train loss: 1.2573 (train.py:125, train())
[2021-11-05 18:54:53]    INFO >> Epoch  38/100, Batch 2500/2575, train loss: 1.2297 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:55:14]    INFO >> Epoch  38/100, train loss: 1.2450 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:00:24]    INFO >> Epoch  38/100, valid loss: 0.0000, valid bleu4: 71.84, best bleu4: 72.89 (train.py:210, <module>())
[2021-11-05 19:00:32]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
[2021-11-05 19:03:22]    INFO >> Epoch  39/100, Batch 500/2575, train loss: 1.3174 (train.py:125, train())
[2021-11-05 19:06:03]    INFO >> Epoch  39/100, Batch 1000/2575, train loss: 1.2212 (train.py:125, train())
[2021-11-05 19:09:08]    INFO >> Epoch  39/100, Batch 1500/2575, train loss: 1.1741 (train.py:125, train())
[2021-11-05 19:12:25]    INFO >> Epoch  39/100, Batch 2000/2575, train loss: 1.2046 (train.py:125, train())
[2021-11-05 19:15:49]    INFO >> Epoch  39/100, Batch 2500/2575, train loss: 1.1943 (train.py:125, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:16:21]    INFO >> Epoch  39/100, train loss: 1.1856 (train.py:134, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:23:29]    INFO >> Epoch  39/100, valid loss: 0.0000, valid bleu4: 71.55, best bleu4: 72.89 (train.py:210, <module>())
[2021-11-05 19:23:37]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/codebert/data-mmap/csharp-java/last_checkpoint.pt (train.py:215, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Traceback (most recent call last):
  File "/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/wanyao/yang/naturalcc-dev/run/translation/codebert/train.py", line 132, in <module>
    train_loss = train()
  File "/home/wanyao/yang/naturalcc-dev/run/translation/codebert/train.py", line 115, in train
    scaler.scale(batch_loss).backward()
  File "/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/site-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/site-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 31.75 GiB total capacity; 4.84 GiB already allocated; 102.19 MiB free; 5.22 GiB reserved in total by PyTorch)
