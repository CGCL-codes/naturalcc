nohup: ignoring input
Using backend: pytorch
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2021-11-05 19:06:47]    INFO >> No /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt to initialize model (train.py:88, <module>())
[2021-11-05 19:06:47]    INFO >> Start training epoch   1/100, best bleu4: 0.00 (train.py:90, <module>())
/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[2021-11-05 19:13:08]    INFO >> Epoch   1/100, Batch 500/10106, train loss: 2478.1749 (train.py:127, train())
[2021-11-05 19:18:42]    INFO >> Epoch   1/100, Batch 1000/10106, train loss: 1951.1637 (train.py:127, train())
[2021-11-05 19:24:21]    INFO >> Epoch   1/100, Batch 1500/10106, train loss: 1717.9411 (train.py:127, train())
[2021-11-05 19:28:38]    INFO >> Epoch   1/100, Batch 2000/10106, train loss: 1575.8504 (train.py:127, train())
[2021-11-05 19:33:08]    INFO >> Epoch   1/100, Batch 2500/10106, train loss: 1460.4102 (train.py:127, train())
[2021-11-05 19:36:46]    INFO >> Epoch   1/100, Batch 3000/10106, train loss: 1361.9380 (train.py:127, train())
[2021-11-05 19:40:27]    INFO >> Epoch   1/100, Batch 3500/10106, train loss: 1281.9232 (train.py:127, train())
[2021-11-05 19:44:06]    INFO >> Epoch   1/100, Batch 4000/10106, train loss: 1215.1306 (train.py:127, train())
[2021-11-05 19:48:01]    INFO >> Epoch   1/100, Batch 4500/10106, train loss: 1160.7875 (train.py:127, train())
[2021-11-05 19:52:30]    INFO >> Epoch   1/100, Batch 5000/10106, train loss: 1113.0493 (train.py:127, train())
[2021-11-05 19:56:42]    INFO >> Epoch   1/100, Batch 5500/10106, train loss: 1071.3723 (train.py:127, train())
[2021-11-05 20:00:18]    INFO >> Epoch   1/100, Batch 6000/10106, train loss: 1035.9288 (train.py:127, train())
[2021-11-05 20:03:57]    INFO >> Epoch   1/100, Batch 6500/10106, train loss: 1004.2203 (train.py:127, train())
[2021-11-05 20:07:37]    INFO >> Epoch   1/100, Batch 7000/10106, train loss: 976.0236 (train.py:127, train())
[2021-11-05 20:12:06]    INFO >> Epoch   1/100, Batch 7500/10106, train loss: 950.3270 (train.py:127, train())
[2021-11-05 20:16:35]    INFO >> Epoch   1/100, Batch 8000/10106, train loss: 927.0525 (train.py:127, train())
[2021-11-05 20:20:09]    INFO >> Epoch   1/100, Batch 8500/10106, train loss: 904.7273 (train.py:127, train())
[2021-11-05 20:23:48]    INFO >> Epoch   1/100, Batch 9000/10106, train loss: 884.4513 (train.py:127, train())
[2021-11-05 20:27:28]    INFO >> Epoch   1/100, Batch 9500/10106, train loss: 864.4701 (train.py:127, train())
[2021-11-05 20:31:32]    INFO >> Epoch   1/100, Batch 10000/10106, train loss: 845.6675 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:32:37]    INFO >> Epoch   1/100, train loss: 841.9896 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:38:38]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 20:38:38]    INFO >> Epoch   1/100, valid loss: 0.0000, valid bleu4: 23.88, best bleu4: 23.88 (train.py:217, <module>())
[2021-11-05 20:38:42]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 20:43:13]    INFO >> Epoch   2/100, Batch 500/10106, train loss: 466.1789 (train.py:127, train())
[2021-11-05 20:46:52]    INFO >> Epoch   2/100, Batch 1000/10106, train loss: 462.6312 (train.py:127, train())
[2021-11-05 20:50:40]    INFO >> Epoch   2/100, Batch 1500/10106, train loss: 453.9641 (train.py:127, train())
[2021-11-05 20:55:10]    INFO >> Epoch   2/100, Batch 2000/10106, train loss: 447.8255 (train.py:127, train())
[2021-11-05 20:59:40]    INFO >> Epoch   2/100, Batch 2500/10106, train loss: 443.6116 (train.py:127, train())
[2021-11-05 21:02:59]    INFO >> Epoch   2/100, Batch 3000/10106, train loss: 439.6664 (train.py:127, train())
[2021-11-05 21:06:39]    INFO >> Epoch   2/100, Batch 3500/10106, train loss: 435.6512 (train.py:127, train())
[2021-11-05 21:10:17]    INFO >> Epoch   2/100, Batch 4000/10106, train loss: 429.7241 (train.py:127, train())
[2021-11-05 21:14:33]    INFO >> Epoch   2/100, Batch 4500/10106, train loss: 425.2631 (train.py:127, train())
[2021-11-05 21:19:02]    INFO >> Epoch   2/100, Batch 5000/10106, train loss: 420.8566 (train.py:127, train())
[2021-11-05 21:22:42]    INFO >> Epoch   2/100, Batch 5500/10106, train loss: 415.9767 (train.py:127, train())
[2021-11-05 21:26:21]    INFO >> Epoch   2/100, Batch 6000/10106, train loss: 411.1526 (train.py:127, train())
[2021-11-05 21:30:01]    INFO >> Epoch   2/100, Batch 6500/10106, train loss: 406.8655 (train.py:127, train())
[2021-11-05 21:33:59]    INFO >> Epoch   2/100, Batch 7000/10106, train loss: 402.9366 (train.py:127, train())
[2021-11-05 21:38:28]    INFO >> Epoch   2/100, Batch 7500/10106, train loss: 399.7528 (train.py:127, train())
[2021-11-05 21:42:38]    INFO >> Epoch   2/100, Batch 8000/10106, train loss: 396.3268 (train.py:127, train())
[2021-11-05 21:46:14]    INFO >> Epoch   2/100, Batch 8500/10106, train loss: 392.1258 (train.py:127, train())
[2021-11-05 21:49:53]    INFO >> Epoch   2/100, Batch 9000/10106, train loss: 388.7251 (train.py:127, train())
[2021-11-05 21:53:34]    INFO >> Epoch   2/100, Batch 9500/10106, train loss: 385.9271 (train.py:127, train())
[2021-11-05 21:58:05]    INFO >> Epoch   2/100, Batch 10000/10106, train loss: 382.5245 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:59:07]    INFO >> Epoch   2/100, train loss: 381.9683 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:04:36]    INFO >> Epoch   2/100, valid loss: 0.0000, valid bleu4: 19.14, best bleu4: 23.88 (train.py:217, <module>())
[2021-11-05 22:04:44]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 22:09:19]    INFO >> Epoch   3/100, Batch 500/10106, train loss: 310.5266 (train.py:127, train())
[2021-11-05 22:12:59]    INFO >> Epoch   3/100, Batch 1000/10106, train loss: 305.6516 (train.py:127, train())
[2021-11-05 22:17:06]    INFO >> Epoch   3/100, Batch 1500/10106, train loss: 303.9810 (train.py:127, train())
[2021-11-05 22:21:35]    INFO >> Epoch   3/100, Batch 2000/10106, train loss: 300.4608 (train.py:127, train())
[2021-11-05 22:25:27]    INFO >> Epoch   3/100, Batch 2500/10106, train loss: 299.2545 (train.py:127, train())
[2021-11-05 22:29:07]    INFO >> Epoch   3/100, Batch 3000/10106, train loss: 297.5526 (train.py:127, train())
[2021-11-05 22:32:46]    INFO >> Epoch   3/100, Batch 3500/10106, train loss: 296.0389 (train.py:127, train())
[2021-11-05 22:36:41]    INFO >> Epoch   3/100, Batch 4000/10106, train loss: 293.9821 (train.py:127, train())
[2021-11-05 22:41:10]    INFO >> Epoch   3/100, Batch 4500/10106, train loss: 292.6006 (train.py:127, train())
[2021-11-05 22:45:25]    INFO >> Epoch   3/100, Batch 5000/10106, train loss: 290.5069 (train.py:127, train())
[2021-11-05 22:48:58]    INFO >> Epoch   3/100, Batch 5500/10106, train loss: 288.0999 (train.py:127, train())
[2021-11-05 22:52:37]    INFO >> Epoch   3/100, Batch 6000/10106, train loss: 286.8603 (train.py:127, train())
[2021-11-05 22:56:15]    INFO >> Epoch   3/100, Batch 6500/10106, train loss: 285.2069 (train.py:127, train())
[2021-11-05 23:00:44]    INFO >> Epoch   3/100, Batch 7000/10106, train loss: 283.9754 (train.py:127, train())
[2021-11-05 23:05:13]    INFO >> Epoch   3/100, Batch 7500/10106, train loss: 282.9135 (train.py:127, train())
[2021-11-05 23:08:51]    INFO >> Epoch   3/100, Batch 8000/10106, train loss: 281.5751 (train.py:127, train())
[2021-11-05 23:12:34]    INFO >> Epoch   3/100, Batch 8500/10106, train loss: 280.3671 (train.py:127, train())
[2021-11-05 23:16:14]    INFO >> Epoch   3/100, Batch 9000/10106, train loss: 278.8689 (train.py:127, train())
[2021-11-05 23:20:26]    INFO >> Epoch   3/100, Batch 9500/10106, train loss: 277.6268 (train.py:127, train())
[2021-11-05 23:24:55]    INFO >> Epoch   3/100, Batch 10000/10106, train loss: 276.3226 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:25:58]    INFO >> Epoch   3/100, train loss: 275.9269 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:30:57]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 23:30:57]    INFO >> Epoch   3/100, valid loss: 0.0000, valid bleu4: 24.06, best bleu4: 24.06 (train.py:217, <module>())
[2021-11-05 23:31:05]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 23:35:34]    INFO >> Epoch   4/100, Batch 500/10106, train loss: 241.1723 (train.py:127, train())
[2021-11-05 23:39:30]    INFO >> Epoch   4/100, Batch 1000/10106, train loss: 239.5133 (train.py:127, train())
[2021-11-05 23:43:59]    INFO >> Epoch   4/100, Batch 1500/10106, train loss: 237.5732 (train.py:127, train())
[2021-11-05 23:48:10]    INFO >> Epoch   4/100, Batch 2000/10106, train loss: 233.8754 (train.py:127, train())
[2021-11-05 23:51:44]    INFO >> Epoch   4/100, Batch 2500/10106, train loss: 233.0042 (train.py:127, train())
[2021-11-05 23:55:23]    INFO >> Epoch   4/100, Batch 3000/10106, train loss: 232.7938 (train.py:127, train())
[2021-11-05 23:58:53]    INFO >> Epoch   4/100, Batch 3500/10106, train loss: 232.8727 (train.py:127, train())
[2021-11-06 00:03:22]    INFO >> Epoch   4/100, Batch 4000/10106, train loss: 231.3776 (train.py:127, train())
[2021-11-06 00:07:51]    INFO >> Epoch   4/100, Batch 4500/10106, train loss: 230.4985 (train.py:127, train())
[2021-11-06 00:11:30]    INFO >> Epoch   4/100, Batch 5000/10106, train loss: 229.7541 (train.py:127, train())
[2021-11-06 00:15:12]    INFO >> Epoch   4/100, Batch 5500/10106, train loss: 228.4539 (train.py:127, train())
[2021-11-06 00:18:51]    INFO >> Epoch   4/100, Batch 6000/10106, train loss: 227.5327 (train.py:127, train())
[2021-11-06 00:22:58]    INFO >> Epoch   4/100, Batch 6500/10106, train loss: 226.3600 (train.py:127, train())
[2021-11-06 00:27:27]    INFO >> Epoch   4/100, Batch 7000/10106, train loss: 225.2622 (train.py:127, train())
[2021-11-06 00:31:22]    INFO >> Epoch   4/100, Batch 7500/10106, train loss: 224.1501 (train.py:127, train())
[2021-11-06 00:34:58]    INFO >> Epoch   4/100, Batch 8000/10106, train loss: 223.2507 (train.py:127, train())
[2021-11-06 00:38:36]    INFO >> Epoch   4/100, Batch 8500/10106, train loss: 222.4699 (train.py:127, train())
[2021-11-06 00:42:24]    INFO >> Epoch   4/100, Batch 9000/10106, train loss: 221.3900 (train.py:127, train())
[2021-11-06 00:46:53]    INFO >> Epoch   4/100, Batch 9500/10106, train loss: 220.4789 (train.py:127, train())
[2021-11-06 00:51:22]    INFO >> Epoch   4/100, Batch 10000/10106, train loss: 219.5613 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:52:02]    INFO >> Epoch   4/100, train loss: 219.2103 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:57:14]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 00:57:14]    INFO >> Epoch   4/100, valid loss: 0.0000, valid bleu4: 25.90, best bleu4: 25.90 (train.py:217, <module>())
[2021-11-06 00:57:22]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 01:01:58]    INFO >> Epoch   5/100, Batch 500/10106, train loss: 196.8542 (train.py:127, train())
[2021-11-06 01:06:27]    INFO >> Epoch   5/100, Batch 1000/10106, train loss: 195.2916 (train.py:127, train())
[2021-11-06 01:10:56]    INFO >> Epoch   5/100, Batch 1500/10106, train loss: 194.6642 (train.py:127, train())
[2021-11-06 01:14:30]    INFO >> Epoch   5/100, Batch 2000/10106, train loss: 192.9869 (train.py:127, train())
[2021-11-06 01:18:10]    INFO >> Epoch   5/100, Batch 2500/10106, train loss: 191.8682 (train.py:127, train())
[2021-11-06 01:21:49]    INFO >> Epoch   5/100, Batch 3000/10106, train loss: 191.6854 (train.py:127, train())
[2021-11-06 01:26:01]    INFO >> Epoch   5/100, Batch 3500/10106, train loss: 189.5183 (train.py:127, train())
[2021-11-06 01:30:30]    INFO >> Epoch   5/100, Batch 4000/10106, train loss: 188.9588 (train.py:127, train())
[2021-11-06 01:34:22]    INFO >> Epoch   5/100, Batch 4500/10106, train loss: 188.1300 (train.py:127, train())
[2021-11-06 01:38:06]    INFO >> Epoch   5/100, Batch 5000/10106, train loss: 187.3936 (train.py:127, train())
[2021-11-06 01:41:47]    INFO >> Epoch   5/100, Batch 5500/10106, train loss: 186.5974 (train.py:127, train())
[2021-11-06 01:45:37]    INFO >> Epoch   5/100, Batch 6000/10106, train loss: 186.0462 (train.py:127, train())
[2021-11-06 01:50:06]    INFO >> Epoch   5/100, Batch 6500/10106, train loss: 185.2637 (train.py:127, train())
[2021-11-06 01:54:18]    INFO >> Epoch   5/100, Batch 7000/10106, train loss: 184.6426 (train.py:127, train())
[2021-11-06 01:57:46]    INFO >> Epoch   5/100, Batch 7500/10106, train loss: 183.9715 (train.py:127, train())
[2021-11-06 02:01:23]    INFO >> Epoch   5/100, Batch 8000/10106, train loss: 183.0023 (train.py:127, train())
[2021-11-06 02:04:59]    INFO >> Epoch   5/100, Batch 8500/10106, train loss: 182.3418 (train.py:127, train())
[2021-11-06 02:09:27]    INFO >> Epoch   5/100, Batch 9000/10106, train loss: 181.5828 (train.py:127, train())
[2021-11-06 02:13:56]    INFO >> Epoch   5/100, Batch 9500/10106, train loss: 180.7170 (train.py:127, train())
[2021-11-06 02:17:36]    INFO >> Epoch   5/100, Batch 10000/10106, train loss: 180.2576 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 02:18:30]    INFO >> Epoch   5/100, train loss: 180.2220 (train.py:136, <module>())
[2021-11-06 02:18:35]    INFO >> save /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/5.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 02:23:46]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 02:23:46]    INFO >> Epoch   5/100, valid loss: 0.0000, valid bleu4: 27.55, best bleu4: 27.55 (train.py:217, <module>())
[2021-11-06 02:23:54]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 02:29:00]    INFO >> Epoch   6/100, Batch 500/10106, train loss: 155.3759 (train.py:127, train())
[2021-11-06 02:33:31]    INFO >> Epoch   6/100, Batch 1000/10106, train loss: 154.7507 (train.py:127, train())
[2021-11-06 02:37:25]    INFO >> Epoch   6/100, Batch 1500/10106, train loss: 156.0475 (train.py:127, train())
[2021-11-06 02:41:41]    INFO >> Epoch   6/100, Batch 2000/10106, train loss: 156.3286 (train.py:127, train())
[2021-11-06 02:45:57]    INFO >> Epoch   6/100, Batch 2500/10106, train loss: 157.8130 (train.py:127, train())
[2021-11-06 02:50:34]    INFO >> Epoch   6/100, Batch 3000/10106, train loss: 157.2669 (train.py:127, train())
[2021-11-06 02:55:37]    INFO >> Epoch   6/100, Batch 3500/10106, train loss: 157.1945 (train.py:127, train())
[2021-11-06 03:00:21]    INFO >> Epoch   6/100, Batch 4000/10106, train loss: 157.1854 (train.py:127, train())
[2021-11-06 03:04:41]    INFO >> Epoch   6/100, Batch 4500/10106, train loss: 156.8271 (train.py:127, train())
[2021-11-06 03:08:56]    INFO >> Epoch   6/100, Batch 5000/10106, train loss: 155.9141 (train.py:127, train())
[2021-11-06 03:13:19]    INFO >> Epoch   6/100, Batch 5500/10106, train loss: 155.7080 (train.py:127, train())
[2021-11-06 03:18:20]    INFO >> Epoch   6/100, Batch 6000/10106, train loss: 154.9767 (train.py:127, train())
[2021-11-06 03:23:24]    INFO >> Epoch   6/100, Batch 6500/10106, train loss: 154.2036 (train.py:127, train())
[2021-11-06 03:27:40]    INFO >> Epoch   6/100, Batch 7000/10106, train loss: 153.5712 (train.py:127, train())
[2021-11-06 03:31:56]    INFO >> Epoch   6/100, Batch 7500/10106, train loss: 153.3090 (train.py:127, train())
[2021-11-06 03:36:11]    INFO >> Epoch   6/100, Batch 8000/10106, train loss: 152.9333 (train.py:127, train())
[2021-11-06 03:41:08]    INFO >> Epoch   6/100, Batch 8500/10106, train loss: 152.7783 (train.py:127, train())
[2021-11-06 03:45:53]    INFO >> Epoch   6/100, Batch 9000/10106, train loss: 152.2209 (train.py:127, train())
[2021-11-06 03:49:36]    INFO >> Epoch   6/100, Batch 9500/10106, train loss: 151.6595 (train.py:127, train())
[2021-11-06 03:53:14]    INFO >> Epoch   6/100, Batch 10000/10106, train loss: 150.9626 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 03:54:07]    INFO >> Epoch   6/100, train loss: 150.8747 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 03:59:12]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 03:59:12]    INFO >> Epoch   6/100, valid loss: 0.0000, valid bleu4: 29.53, best bleu4: 29.53 (train.py:217, <module>())
[2021-11-06 03:59:20]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 04:04:40]    INFO >> Epoch   7/100, Batch 500/10106, train loss: 136.5954 (train.py:127, train())
[2021-11-06 04:08:44]    INFO >> Epoch   7/100, Batch 1000/10106, train loss: 135.8278 (train.py:127, train())
[2021-11-06 04:12:23]    INFO >> Epoch   7/100, Batch 1500/10106, train loss: 132.6458 (train.py:127, train())
[2021-11-06 04:16:04]    INFO >> Epoch   7/100, Batch 2000/10106, train loss: 131.3271 (train.py:127, train())
[2021-11-06 04:19:51]    INFO >> Epoch   7/100, Batch 2500/10106, train loss: 131.8188 (train.py:127, train())
[2021-11-06 04:24:21]    INFO >> Epoch   7/100, Batch 3000/10106, train loss: 132.0512 (train.py:127, train())
[2021-11-06 04:28:50]    INFO >> Epoch   7/100, Batch 3500/10106, train loss: 131.4788 (train.py:127, train())
[2021-11-06 04:32:19]    INFO >> Epoch   7/100, Batch 4000/10106, train loss: 130.9651 (train.py:127, train())
[2021-11-06 04:36:01]    INFO >> Epoch   7/100, Batch 4500/10106, train loss: 130.7204 (train.py:127, train())
[2021-11-06 04:39:42]    INFO >> Epoch   7/100, Batch 5000/10106, train loss: 130.2861 (train.py:127, train())
[2021-11-06 04:43:59]    INFO >> Epoch   7/100, Batch 5500/10106, train loss: 130.2087 (train.py:127, train())
[2021-11-06 04:48:28]    INFO >> Epoch   7/100, Batch 6000/10106, train loss: 129.4779 (train.py:127, train())
[2021-11-06 04:52:13]    INFO >> Epoch   7/100, Batch 6500/10106, train loss: 129.1448 (train.py:127, train())
[2021-11-06 04:55:54]    INFO >> Epoch   7/100, Batch 7000/10106, train loss: 129.0164 (train.py:127, train())
[2021-11-06 04:59:35]    INFO >> Epoch   7/100, Batch 7500/10106, train loss: 128.6103 (train.py:127, train())
[2021-11-06 05:03:35]    INFO >> Epoch   7/100, Batch 8000/10106, train loss: 128.1023 (train.py:127, train())
[2021-11-06 05:08:04]    INFO >> Epoch   7/100, Batch 8500/10106, train loss: 127.7967 (train.py:127, train())
[2021-11-06 05:12:06]    INFO >> Epoch   7/100, Batch 9000/10106, train loss: 127.5497 (train.py:127, train())
[2021-11-06 05:15:48]    INFO >> Epoch   7/100, Batch 9500/10106, train loss: 127.2152 (train.py:127, train())
[2021-11-06 05:19:27]    INFO >> Epoch   7/100, Batch 10000/10106, train loss: 126.9973 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 05:20:20]    INFO >> Epoch   7/100, train loss: 126.8587 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 05:25:50]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 05:25:50]    INFO >> Epoch   7/100, valid loss: 0.0000, valid bleu4: 30.70, best bleu4: 30.70 (train.py:217, <module>())
[2021-11-06 05:25:58]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 05:31:19]    INFO >> Epoch   8/100, Batch 500/10106, train loss: 113.7436 (train.py:127, train())
[2021-11-06 05:33:43]    INFO >> Epoch   8/100, Batch 1000/10106, train loss: 110.9587 (train.py:127, train())
[2021-11-06 05:35:37]    INFO >> Epoch   8/100, Batch 1500/10106, train loss: 110.0951 (train.py:127, train())
[2021-11-06 05:37:32]    INFO >> Epoch   8/100, Batch 2000/10106, train loss: 108.6322 (train.py:127, train())
[2021-11-06 05:39:25]    INFO >> Epoch   8/100, Batch 2500/10106, train loss: 109.0803 (train.py:127, train())
[2021-11-06 05:41:19]    INFO >> Epoch   8/100, Batch 3000/10106, train loss: 109.6728 (train.py:127, train())
[2021-11-06 05:43:12]    INFO >> Epoch   8/100, Batch 3500/10106, train loss: 109.4206 (train.py:127, train())
[2021-11-06 05:45:05]    INFO >> Epoch   8/100, Batch 4000/10106, train loss: 109.5156 (train.py:127, train())
[2021-11-06 05:46:57]    INFO >> Epoch   8/100, Batch 4500/10106, train loss: 109.3007 (train.py:127, train())
[2021-11-06 05:49:18]    INFO >> Epoch   8/100, Batch 5000/10106, train loss: 108.9141 (train.py:127, train())
[2021-11-06 05:51:39]    INFO >> Epoch   8/100, Batch 5500/10106, train loss: 108.5151 (train.py:127, train())
[2021-11-06 05:53:31]    INFO >> Epoch   8/100, Batch 6000/10106, train loss: 108.3402 (train.py:127, train())
[2021-11-06 05:55:23]    INFO >> Epoch   8/100, Batch 6500/10106, train loss: 107.8764 (train.py:127, train())
[2021-11-06 05:57:17]    INFO >> Epoch   8/100, Batch 7000/10106, train loss: 107.7804 (train.py:127, train())
[2021-11-06 05:59:10]    INFO >> Epoch   8/100, Batch 7500/10106, train loss: 107.4364 (train.py:127, train())
[2021-11-06 06:01:03]    INFO >> Epoch   8/100, Batch 8000/10106, train loss: 107.3647 (train.py:127, train())
[2021-11-06 06:02:56]    INFO >> Epoch   8/100, Batch 8500/10106, train loss: 106.8915 (train.py:127, train())
[2021-11-06 06:04:49]    INFO >> Epoch   8/100, Batch 9000/10106, train loss: 106.6743 (train.py:127, train())
[2021-11-06 06:06:39]    INFO >> Epoch   8/100, Batch 9500/10106, train loss: 106.2681 (train.py:127, train())
[2021-11-06 06:08:34]    INFO >> Epoch   8/100, Batch 10000/10106, train loss: 106.0678 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 06:09:04]    INFO >> Epoch   8/100, train loss: 105.9555 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 06:11:49]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 06:11:49]    INFO >> Epoch   8/100, valid loss: 0.0000, valid bleu4: 33.09, best bleu4: 33.09 (train.py:217, <module>())
[2021-11-06 06:11:57]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 06:14:39]    INFO >> Epoch   9/100, Batch 500/10106, train loss: 92.1118 (train.py:127, train())
[2021-11-06 06:16:32]    INFO >> Epoch   9/100, Batch 1000/10106, train loss: 91.9104 (train.py:127, train())
[2021-11-06 06:18:26]    INFO >> Epoch   9/100, Batch 1500/10106, train loss: 92.1466 (train.py:127, train())
[2021-11-06 06:20:20]    INFO >> Epoch   9/100, Batch 2000/10106, train loss: 91.9023 (train.py:127, train())
[2021-11-06 06:22:13]    INFO >> Epoch   9/100, Batch 2500/10106, train loss: 91.8829 (train.py:127, train())
[2021-11-06 06:24:07]    INFO >> Epoch   9/100, Batch 3000/10106, train loss: 91.3015 (train.py:127, train())
[2021-11-06 06:26:01]    INFO >> Epoch   9/100, Batch 3500/10106, train loss: 90.8180 (train.py:127, train())
[2021-11-06 06:27:54]    INFO >> Epoch   9/100, Batch 4000/10106, train loss: 90.5709 (train.py:127, train())
[2021-11-06 06:29:47]    INFO >> Epoch   9/100, Batch 4500/10106, train loss: 90.1414 (train.py:127, train())
[2021-11-06 06:31:41]    INFO >> Epoch   9/100, Batch 5000/10106, train loss: 89.9244 (train.py:127, train())
[2021-11-06 06:33:34]    INFO >> Epoch   9/100, Batch 5500/10106, train loss: 89.7990 (train.py:127, train())
[2021-11-06 06:35:28]    INFO >> Epoch   9/100, Batch 6000/10106, train loss: 89.5988 (train.py:127, train())
[2021-11-06 06:37:22]    INFO >> Epoch   9/100, Batch 6500/10106, train loss: 89.3285 (train.py:127, train())
[2021-11-06 06:39:17]    INFO >> Epoch   9/100, Batch 7000/10106, train loss: 89.3353 (train.py:127, train())
[2021-11-06 06:41:10]    INFO >> Epoch   9/100, Batch 7500/10106, train loss: 89.2116 (train.py:127, train())
[2021-11-06 06:43:03]    INFO >> Epoch   9/100, Batch 8000/10106, train loss: 88.8297 (train.py:127, train())
[2021-11-06 06:44:56]    INFO >> Epoch   9/100, Batch 8500/10106, train loss: 88.6637 (train.py:127, train())
[2021-11-06 06:46:49]    INFO >> Epoch   9/100, Batch 9000/10106, train loss: 88.4767 (train.py:127, train())
[2021-11-06 06:48:43]    INFO >> Epoch   9/100, Batch 9500/10106, train loss: 88.0150 (train.py:127, train())
[2021-11-06 06:50:38]    INFO >> Epoch   9/100, Batch 10000/10106, train loss: 87.9023 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 06:51:08]    INFO >> Epoch   9/100, train loss: 87.8799 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 06:53:51]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 06:53:51]    INFO >> Epoch   9/100, valid loss: 0.0000, valid bleu4: 33.40, best bleu4: 33.40 (train.py:217, <module>())
[2021-11-06 06:54:00]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 06:56:43]    INFO >> Epoch  10/100, Batch 500/10106, train loss: 71.9245 (train.py:127, train())
[2021-11-06 06:58:35]    INFO >> Epoch  10/100, Batch 1000/10106, train loss: 72.8827 (train.py:127, train())
[2021-11-06 07:00:30]    INFO >> Epoch  10/100, Batch 1500/10106, train loss: 73.4208 (train.py:127, train())
[2021-11-06 07:02:23]    INFO >> Epoch  10/100, Batch 2000/10106, train loss: 74.1489 (train.py:127, train())
[2021-11-06 07:04:16]    INFO >> Epoch  10/100, Batch 2500/10106, train loss: 74.3440 (train.py:127, train())
[2021-11-06 07:06:11]    INFO >> Epoch  10/100, Batch 3000/10106, train loss: 74.5952 (train.py:127, train())
[2021-11-06 07:08:03]    INFO >> Epoch  10/100, Batch 3500/10106, train loss: 74.1026 (train.py:127, train())
[2021-11-06 07:09:56]    INFO >> Epoch  10/100, Batch 4000/10106, train loss: 73.9263 (train.py:127, train())
[2021-11-06 07:11:50]    INFO >> Epoch  10/100, Batch 4500/10106, train loss: 74.1260 (train.py:127, train())
[2021-11-06 07:13:44]    INFO >> Epoch  10/100, Batch 5000/10106, train loss: 74.1836 (train.py:127, train())
[2021-11-06 07:16:48]    INFO >> Epoch  10/100, Batch 5500/10106, train loss: 74.2243 (train.py:127, train())
[2021-11-06 07:20:42]    INFO >> Epoch  10/100, Batch 6000/10106, train loss: 74.0010 (train.py:127, train())
[2021-11-06 07:24:36]    INFO >> Epoch  10/100, Batch 6500/10106, train loss: 73.8527 (train.py:127, train())
[2021-11-06 07:28:29]    INFO >> Epoch  10/100, Batch 7000/10106, train loss: 73.6752 (train.py:127, train())
[2021-11-06 07:32:23]    INFO >> Epoch  10/100, Batch 7500/10106, train loss: 73.6709 (train.py:127, train())
[2021-11-06 07:36:19]    INFO >> Epoch  10/100, Batch 8000/10106, train loss: 73.7500 (train.py:127, train())
[2021-11-06 07:40:11]    INFO >> Epoch  10/100, Batch 8500/10106, train loss: 73.6200 (train.py:127, train())
[2021-11-06 07:44:03]    INFO >> Epoch  10/100, Batch 9000/10106, train loss: 73.2814 (train.py:127, train())
[2021-11-06 07:48:05]    INFO >> Epoch  10/100, Batch 9500/10106, train loss: 73.0524 (train.py:127, train())
[2021-11-06 07:52:09]    INFO >> Epoch  10/100, Batch 10000/10106, train loss: 72.9031 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 07:53:08]    INFO >> Epoch  10/100, train loss: 72.8307 (train.py:136, <module>())
[2021-11-06 07:53:13]    INFO >> save /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/10.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 07:58:37]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 07:58:37]    INFO >> Epoch  10/100, valid loss: 0.0000, valid bleu4: 34.35, best bleu4: 34.35 (train.py:217, <module>())
[2021-11-06 07:58:45]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 08:03:35]    INFO >> Epoch  11/100, Batch 500/10106, train loss: 61.3509 (train.py:127, train())
[2021-11-06 08:07:30]    INFO >> Epoch  11/100, Batch 1000/10106, train loss: 61.8479 (train.py:127, train())
[2021-11-06 08:11:36]    INFO >> Epoch  11/100, Batch 1500/10106, train loss: 62.4212 (train.py:127, train())
[2021-11-06 08:15:46]    INFO >> Epoch  11/100, Batch 2000/10106, train loss: 62.0924 (train.py:127, train())
[2021-11-06 08:19:54]    INFO >> Epoch  11/100, Batch 2500/10106, train loss: 62.1232 (train.py:127, train())
[2021-11-06 08:23:50]    INFO >> Epoch  11/100, Batch 3000/10106, train loss: 61.9459 (train.py:127, train())
[2021-11-06 08:27:51]    INFO >> Epoch  11/100, Batch 3500/10106, train loss: 61.8252 (train.py:127, train())
[2021-11-06 08:32:03]    INFO >> Epoch  11/100, Batch 4000/10106, train loss: 61.6945 (train.py:127, train())
[2021-11-06 08:36:05]    INFO >> Epoch  11/100, Batch 4500/10106, train loss: 61.5975 (train.py:127, train())
[2021-11-06 08:40:15]    INFO >> Epoch  11/100, Batch 5000/10106, train loss: 61.3927 (train.py:127, train())
[2021-11-06 08:44:19]    INFO >> Epoch  11/100, Batch 5500/10106, train loss: 61.1177 (train.py:127, train())
[2021-11-06 08:48:26]    INFO >> Epoch  11/100, Batch 6000/10106, train loss: 61.1181 (train.py:127, train())
[2021-11-06 08:52:32]    INFO >> Epoch  11/100, Batch 6500/10106, train loss: 61.0249 (train.py:127, train())
[2021-11-06 08:56:37]    INFO >> Epoch  11/100, Batch 7000/10106, train loss: 60.9265 (train.py:127, train())
[2021-11-06 09:00:35]    INFO >> Epoch  11/100, Batch 7500/10106, train loss: 60.7331 (train.py:127, train())
[2021-11-06 09:04:39]    INFO >> Epoch  11/100, Batch 8000/10106, train loss: 60.5387 (train.py:127, train())
[2021-11-06 09:08:45]    INFO >> Epoch  11/100, Batch 8500/10106, train loss: 60.2265 (train.py:127, train())
[2021-11-06 09:12:58]    INFO >> Epoch  11/100, Batch 9000/10106, train loss: 60.0046 (train.py:127, train())
[2021-11-06 09:16:57]    INFO >> Epoch  11/100, Batch 9500/10106, train loss: 59.8449 (train.py:127, train())
[2021-11-06 09:20:57]    INFO >> Epoch  11/100, Batch 10000/10106, train loss: 59.6266 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 09:21:55]    INFO >> Epoch  11/100, train loss: 59.5568 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 09:27:14]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 09:27:14]    INFO >> Epoch  11/100, valid loss: 0.0000, valid bleu4: 39.44, best bleu4: 39.44 (train.py:217, <module>())
[2021-11-06 09:27:22]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 09:32:16]    INFO >> Epoch  12/100, Batch 500/10106, train loss: 48.2185 (train.py:127, train())
[2021-11-06 09:36:17]    INFO >> Epoch  12/100, Batch 1000/10106, train loss: 48.4874 (train.py:127, train())
[2021-11-06 09:41:10]    INFO >> Epoch  12/100, Batch 1500/10106, train loss: 48.8222 (train.py:127, train())
[2021-11-06 09:45:15]    INFO >> Epoch  12/100, Batch 2000/10106, train loss: 48.8362 (train.py:127, train())
[2021-11-06 09:49:11]    INFO >> Epoch  12/100, Batch 2500/10106, train loss: 49.0310 (train.py:127, train())
[2021-11-06 09:53:11]    INFO >> Epoch  12/100, Batch 3000/10106, train loss: 48.5826 (train.py:127, train())
[2021-11-06 09:57:13]    INFO >> Epoch  12/100, Batch 3500/10106, train loss: 48.7710 (train.py:127, train())
[2021-11-06 10:01:09]    INFO >> Epoch  12/100, Batch 4000/10106, train loss: 48.7269 (train.py:127, train())
[2021-11-06 10:05:10]    INFO >> Epoch  12/100, Batch 4500/10106, train loss: 48.6836 (train.py:127, train())
[2021-11-06 10:09:19]    INFO >> Epoch  12/100, Batch 5000/10106, train loss: 48.7352 (train.py:127, train())
[2021-11-06 10:13:22]    INFO >> Epoch  12/100, Batch 5500/10106, train loss: 48.7232 (train.py:127, train())
[2021-11-06 10:17:27]    INFO >> Epoch  12/100, Batch 6000/10106, train loss: 48.6055 (train.py:127, train())
[2021-11-06 10:21:36]    INFO >> Epoch  12/100, Batch 6500/10106, train loss: 48.6149 (train.py:127, train())
[2021-11-06 10:25:38]    INFO >> Epoch  12/100, Batch 7000/10106, train loss: 48.5689 (train.py:127, train())
[2021-11-06 10:29:41]    INFO >> Epoch  12/100, Batch 7500/10106, train loss: 48.4874 (train.py:127, train())
[2021-11-06 10:33:38]    INFO >> Epoch  12/100, Batch 8000/10106, train loss: 48.3264 (train.py:127, train())
[2021-11-06 10:37:34]    INFO >> Epoch  12/100, Batch 8500/10106, train loss: 48.3036 (train.py:127, train())
[2021-11-06 10:41:37]    INFO >> Epoch  12/100, Batch 9000/10106, train loss: 48.0648 (train.py:127, train())
[2021-11-06 10:45:39]    INFO >> Epoch  12/100, Batch 9500/10106, train loss: 47.8638 (train.py:127, train())
[2021-11-06 10:49:42]    INFO >> Epoch  12/100, Batch 10000/10106, train loss: 47.7421 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 10:50:40]    INFO >> Epoch  12/100, train loss: 47.6899 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 10:55:56]    INFO >> Epoch  12/100, valid loss: 0.0000, valid bleu4: 39.16, best bleu4: 39.44 (train.py:217, <module>())
[2021-11-06 10:56:04]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 11:00:57]    INFO >> Epoch  13/100, Batch 500/10106, train loss: 39.3576 (train.py:127, train())
[2021-11-06 11:05:02]    INFO >> Epoch  13/100, Batch 1000/10106, train loss: 39.9273 (train.py:127, train())
[2021-11-06 11:09:00]    INFO >> Epoch  13/100, Batch 1500/10106, train loss: 39.2420 (train.py:127, train())
[2021-11-06 11:13:05]    INFO >> Epoch  13/100, Batch 2000/10106, train loss: 39.5225 (train.py:127, train())
[2021-11-06 11:17:18]    INFO >> Epoch  13/100, Batch 2500/10106, train loss: 39.2698 (train.py:127, train())
[2021-11-06 11:21:05]    INFO >> Epoch  13/100, Batch 3000/10106, train loss: 39.5943 (train.py:127, train())
[2021-11-06 11:24:53]    INFO >> Epoch  13/100, Batch 3500/10106, train loss: 39.6787 (train.py:127, train())
[2021-11-06 11:28:44]    INFO >> Epoch  13/100, Batch 4000/10106, train loss: 39.9356 (train.py:127, train())
[2021-11-06 11:32:39]    INFO >> Epoch  13/100, Batch 4500/10106, train loss: 39.8394 (train.py:127, train())
[2021-11-06 11:36:35]    INFO >> Epoch  13/100, Batch 5000/10106, train loss: 39.7159 (train.py:127, train())
[2021-11-06 11:40:23]    INFO >> Epoch  13/100, Batch 5500/10106, train loss: 39.9017 (train.py:127, train())
[2021-11-06 11:44:19]    INFO >> Epoch  13/100, Batch 6000/10106, train loss: 39.9383 (train.py:127, train())
[2021-11-06 11:48:07]    INFO >> Epoch  13/100, Batch 6500/10106, train loss: 40.0484 (train.py:127, train())
[2021-11-06 11:52:02]    INFO >> Epoch  13/100, Batch 7000/10106, train loss: 40.1685 (train.py:127, train())
[2021-11-06 11:55:53]    INFO >> Epoch  13/100, Batch 7500/10106, train loss: 40.0753 (train.py:127, train())
[2021-11-06 11:59:50]    INFO >> Epoch  13/100, Batch 8000/10106, train loss: 39.9116 (train.py:127, train())
[2021-11-06 12:03:40]    INFO >> Epoch  13/100, Batch 8500/10106, train loss: 39.8300 (train.py:127, train())
[2021-11-06 12:07:23]    INFO >> Epoch  13/100, Batch 9000/10106, train loss: 39.6271 (train.py:127, train())
[2021-11-06 12:11:11]    INFO >> Epoch  13/100, Batch 9500/10106, train loss: 39.5268 (train.py:127, train())
[2021-11-06 12:15:00]    INFO >> Epoch  13/100, Batch 10000/10106, train loss: 39.3825 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 12:15:57]    INFO >> Epoch  13/100, train loss: 39.3491 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 12:21:12]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 12:21:12]    INFO >> Epoch  13/100, valid loss: 0.0000, valid bleu4: 40.83, best bleu4: 40.83 (train.py:217, <module>())
[2021-11-06 12:21:21]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 12:26:00]    INFO >> Epoch  14/100, Batch 500/10106, train loss: 31.3661 (train.py:127, train())
[2021-11-06 12:29:49]    INFO >> Epoch  14/100, Batch 1000/10106, train loss: 32.4853 (train.py:127, train())
[2021-11-06 12:33:34]    INFO >> Epoch  14/100, Batch 1500/10106, train loss: 32.7531 (train.py:127, train())
[2021-11-06 12:37:28]    INFO >> Epoch  14/100, Batch 2000/10106, train loss: 33.5070 (train.py:127, train())
[2021-11-06 12:41:22]    INFO >> Epoch  14/100, Batch 2500/10106, train loss: 33.4092 (train.py:127, train())
[2021-11-06 12:45:15]    INFO >> Epoch  14/100, Batch 3000/10106, train loss: 33.5169 (train.py:127, train())
[2021-11-06 12:49:11]    INFO >> Epoch  14/100, Batch 3500/10106, train loss: 34.0370 (train.py:127, train())
[2021-11-06 12:53:06]    INFO >> Epoch  14/100, Batch 4000/10106, train loss: 38.9809 (train.py:127, train())
[2021-11-06 12:56:57]    INFO >> Epoch  14/100, Batch 4500/10106, train loss: 46.6299 (train.py:127, train())
[2021-11-06 13:00:43]    INFO >> Epoch  14/100, Batch 5000/10106, train loss: 52.0443 (train.py:127, train())
[2021-11-06 13:04:39]    INFO >> Epoch  14/100, Batch 5500/10106, train loss: 56.3303 (train.py:127, train())
[2021-11-06 13:08:21]    INFO >> Epoch  14/100, Batch 6000/10106, train loss: 59.9545 (train.py:127, train())
[2021-11-06 13:12:11]    INFO >> Epoch  14/100, Batch 6500/10106, train loss: 62.3803 (train.py:127, train())
[2021-11-06 13:16:01]    INFO >> Epoch  14/100, Batch 7000/10106, train loss: 64.3000 (train.py:127, train())
[2021-11-06 13:20:01]    INFO >> Epoch  14/100, Batch 7500/10106, train loss: 65.7931 (train.py:127, train())
[2021-11-06 13:23:49]    INFO >> Epoch  14/100, Batch 8000/10106, train loss: 66.8841 (train.py:127, train())
[2021-11-06 13:27:41]    INFO >> Epoch  14/100, Batch 8500/10106, train loss: 68.0972 (train.py:127, train())
[2021-11-06 13:31:29]    INFO >> Epoch  14/100, Batch 9000/10106, train loss: 68.8912 (train.py:127, train())
[2021-11-06 13:35:27]    INFO >> Epoch  14/100, Batch 9500/10106, train loss: 69.6996 (train.py:127, train())
[2021-11-06 13:39:14]    INFO >> Epoch  14/100, Batch 10000/10106, train loss: 70.3879 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 13:40:09]    INFO >> Epoch  14/100, train loss: 70.4924 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 13:45:16]    INFO >> Epoch  14/100, valid loss: 0.0000, valid bleu4: 18.88, best bleu4: 40.83 (train.py:217, <module>())
[2021-11-06 13:45:25]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 13:50:05]    INFO >> Epoch  15/100, Batch 500/10106, train loss: 74.6093 (train.py:127, train())
[2021-11-06 13:53:57]    INFO >> Epoch  15/100, Batch 1000/10106, train loss: 75.0158 (train.py:127, train())
[2021-11-06 13:57:48]    INFO >> Epoch  15/100, Batch 1500/10106, train loss: 74.8781 (train.py:127, train())
[2021-11-06 14:01:35]    INFO >> Epoch  15/100, Batch 2000/10106, train loss: 74.7376 (train.py:127, train())
[2021-11-06 14:05:26]    INFO >> Epoch  15/100, Batch 2500/10106, train loss: 74.1746 (train.py:127, train())
[2021-11-06 14:09:16]    INFO >> Epoch  15/100, Batch 3000/10106, train loss: 73.7514 (train.py:127, train())
[2021-11-06 14:13:03]    INFO >> Epoch  15/100, Batch 3500/10106, train loss: 73.7076 (train.py:127, train())
[2021-11-06 14:17:01]    INFO >> Epoch  15/100, Batch 4000/10106, train loss: 73.7726 (train.py:127, train())
[2021-11-06 14:20:50]    INFO >> Epoch  15/100, Batch 4500/10106, train loss: 73.5087 (train.py:127, train())
[2021-11-06 14:24:39]    INFO >> Epoch  15/100, Batch 5000/10106, train loss: 73.4430 (train.py:127, train())
[2021-11-06 14:28:30]    INFO >> Epoch  15/100, Batch 5500/10106, train loss: 73.3470 (train.py:127, train())
[2021-11-06 14:32:17]    INFO >> Epoch  15/100, Batch 6000/10106, train loss: 73.1372 (train.py:127, train())
[2021-11-06 14:36:02]    INFO >> Epoch  15/100, Batch 6500/10106, train loss: 72.9507 (train.py:127, train())
[2021-11-06 14:39:59]    INFO >> Epoch  15/100, Batch 7000/10106, train loss: 72.7943 (train.py:127, train())
[2021-11-06 14:43:51]    INFO >> Epoch  15/100, Batch 7500/10106, train loss: 72.6312 (train.py:127, train())
[2021-11-06 14:47:38]    INFO >> Epoch  15/100, Batch 8000/10106, train loss: 72.4398 (train.py:127, train())
[2021-11-06 14:51:29]    INFO >> Epoch  15/100, Batch 8500/10106, train loss: 72.3643 (train.py:127, train())
[2021-11-06 14:55:16]    INFO >> Epoch  15/100, Batch 9000/10106, train loss: 72.0808 (train.py:127, train())
[2021-11-06 14:59:07]    INFO >> Epoch  15/100, Batch 9500/10106, train loss: 71.7921 (train.py:127, train())
[2021-11-06 15:02:56]    INFO >> Epoch  15/100, Batch 10000/10106, train loss: 71.6761 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 15:03:55]    INFO >> Epoch  15/100, train loss: 71.6333 (train.py:136, <module>())
[2021-11-06 15:03:59]    INFO >> save /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/15.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 15:09:08]    INFO >> Epoch  15/100, valid loss: 0.0000, valid bleu4: 0.01, best bleu4: 40.83 (train.py:217, <module>())
[2021-11-06 15:09:15]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/python-java/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 15:13:56]    INFO >> Epoch  16/100, Batch 500/10106, train loss: 60.3524 (train.py:127, train())
[2021-11-06 15:17:37]    INFO >> Epoch  16/100, Batch 1000/10106, train loss: 58.9518 (train.py:127, train())
[2021-11-06 15:20:38]    INFO >> Epoch  16/100, Batch 1500/10106, train loss: 59.2918 (train.py:127, train())
[2021-11-06 15:23:39]    INFO >> Epoch  16/100, Batch 2000/10106, train loss: 59.8773 (train.py:127, train())
[2021-11-06 15:26:35]    INFO >> Epoch  16/100, Batch 2500/10106, train loss: 60.5158 (train.py:127, train())
[2021-11-06 15:29:39]    INFO >> Epoch  16/100, Batch 3000/10106, train loss: 60.7268 (train.py:127, train())
[2021-11-06 15:32:46]    INFO >> Epoch  16/100, Batch 3500/10106, train loss: 60.6702 (train.py:127, train())
[2021-11-06 15:35:49]    INFO >> Epoch  16/100, Batch 4000/10106, train loss: 60.7712 (train.py:127, train())
[2021-11-06 15:38:42]    INFO >> Epoch  16/100, Batch 4500/10106, train loss: 60.7391 (train.py:127, train())
[2021-11-06 15:40:35]    INFO >> Epoch  16/100, Batch 5000/10106, train loss: 60.6082 (train.py:127, train())
[2021-11-06 15:42:28]    INFO >> Epoch  16/100, Batch 5500/10106, train loss: 60.5002 (train.py:127, train())
[2021-11-06 15:44:21]    INFO >> Epoch  16/100, Batch 6000/10106, train loss: 60.6101 (train.py:127, train())
[2021-11-06 15:46:13]    INFO >> Epoch  16/100, Batch 6500/10106, train loss: 60.4700 (train.py:127, train())
[2021-11-06 15:48:06]    INFO >> Epoch  16/100, Batch 7000/10106, train loss: 60.5523 (train.py:127, train())
[2021-11-06 15:49:58]    INFO >> Epoch  16/100, Batch 7500/10106, train loss: 60.4346 (train.py:127, train())
