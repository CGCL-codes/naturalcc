nohup: ignoring input
Using backend: pytorch
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2021-11-05 23:58:52]    INFO >> No /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt to initialize model (train.py:88, <module>())
[2021-11-05 23:58:52]    INFO >> Start training epoch   1/100, best bleu4: 0.00 (train.py:90, <module>())
/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[2021-11-06 00:01:50]    INFO >> Epoch   1/100, Batch 500/10106, train loss: 1892.1856 (train.py:127, train())
[2021-11-06 00:03:44]    INFO >> Epoch   1/100, Batch 1000/10106, train loss: 1496.4403 (train.py:127, train())
[2021-11-06 00:05:37]    INFO >> Epoch   1/100, Batch 1500/10106, train loss: 1300.2284 (train.py:127, train())
[2021-11-06 00:07:29]    INFO >> Epoch   1/100, Batch 2000/10106, train loss: 1176.7430 (train.py:127, train())
[2021-11-06 00:09:20]    INFO >> Epoch   1/100, Batch 2500/10106, train loss: 1083.3106 (train.py:127, train())
[2021-11-06 00:11:13]    INFO >> Epoch   1/100, Batch 3000/10106, train loss: 1015.6697 (train.py:127, train())
[2021-11-06 00:13:06]    INFO >> Epoch   1/100, Batch 3500/10106, train loss: 958.2717 (train.py:127, train())
[2021-11-06 00:15:00]    INFO >> Epoch   1/100, Batch 4000/10106, train loss: 912.3226 (train.py:127, train())
[2021-11-06 00:16:52]    INFO >> Epoch   1/100, Batch 4500/10106, train loss: 875.1941 (train.py:127, train())
[2021-11-06 00:18:45]    INFO >> Epoch   1/100, Batch 5000/10106, train loss: 842.5482 (train.py:127, train())
[2021-11-06 00:20:44]    INFO >> Epoch   1/100, Batch 5500/10106, train loss: 814.1234 (train.py:127, train())
[2021-11-06 00:22:42]    INFO >> Epoch   1/100, Batch 6000/10106, train loss: 789.5547 (train.py:127, train())
[2021-11-06 00:24:35]    INFO >> Epoch   1/100, Batch 6500/10106, train loss: 766.8977 (train.py:127, train())
[2021-11-06 00:26:27]    INFO >> Epoch   1/100, Batch 7000/10106, train loss: 747.1627 (train.py:127, train())
[2021-11-06 00:28:21]    INFO >> Epoch   1/100, Batch 7500/10106, train loss: 729.1081 (train.py:127, train())
[2021-11-06 00:30:15]    INFO >> Epoch   1/100, Batch 8000/10106, train loss: 712.7812 (train.py:127, train())
[2021-11-06 00:32:20]    INFO >> Epoch   1/100, Batch 8500/10106, train loss: 697.9476 (train.py:127, train())
[2021-11-06 00:35:52]    INFO >> Epoch   1/100, Batch 9000/10106, train loss: 684.6398 (train.py:127, train())
[2021-11-06 00:39:24]    INFO >> Epoch   1/100, Batch 9500/10106, train loss: 671.3137 (train.py:127, train())
[2021-11-06 00:42:56]    INFO >> Epoch   1/100, Batch 10000/10106, train loss: 659.0068 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:43:47]    INFO >> Epoch   1/100, train loss: 656.6774 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:49:37]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 00:49:37]    INFO >> Epoch   1/100, valid loss: 0.0000, valid bleu4: 9.38, best bleu4: 9.38 (train.py:217, <module>())
[2021-11-06 00:49:42]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 00:54:17]    INFO >> Epoch   2/100, Batch 500/10106, train loss: 411.3516 (train.py:127, train())
[2021-11-06 00:57:49]    INFO >> Epoch   2/100, Batch 1000/10106, train loss: 407.0301 (train.py:127, train())
[2021-11-06 01:01:16]    INFO >> Epoch   2/100, Batch 1500/10106, train loss: 398.7703 (train.py:127, train())
[2021-11-06 01:05:45]    INFO >> Epoch   2/100, Batch 2000/10106, train loss: 396.5665 (train.py:127, train())
[2021-11-06 01:09:07]    INFO >> Epoch   2/100, Batch 2500/10106, train loss: 394.1724 (train.py:127, train())
[2021-11-06 01:12:39]    INFO >> Epoch   2/100, Batch 3000/10106, train loss: 390.6757 (train.py:127, train())
[2021-11-06 01:16:11]    INFO >> Epoch   2/100, Batch 3500/10106, train loss: 387.7193 (train.py:127, train())
[2021-11-06 01:19:54]    INFO >> Epoch   2/100, Batch 4000/10106, train loss: 385.7457 (train.py:127, train())
[2021-11-06 01:23:59]    INFO >> Epoch   2/100, Batch 4500/10106, train loss: 383.9493 (train.py:127, train())
[2021-11-06 01:27:31]    INFO >> Epoch   2/100, Batch 5000/10106, train loss: 381.2414 (train.py:127, train())
[2021-11-06 01:31:03]    INFO >> Epoch   2/100, Batch 5500/10106, train loss: 378.4749 (train.py:127, train())
[2021-11-06 01:34:35]    INFO >> Epoch   2/100, Batch 6000/10106, train loss: 375.3623 (train.py:127, train())
[2021-11-06 01:38:33]    INFO >> Epoch   2/100, Batch 6500/10106, train loss: 372.8080 (train.py:127, train())
[2021-11-06 01:42:23]    INFO >> Epoch   2/100, Batch 7000/10106, train loss: 370.3933 (train.py:127, train())
[2021-11-06 01:45:55]    INFO >> Epoch   2/100, Batch 7500/10106, train loss: 368.3768 (train.py:127, train())
[2021-11-06 01:49:27]    INFO >> Epoch   2/100, Batch 8000/10106, train loss: 365.8571 (train.py:127, train())
[2021-11-06 01:52:59]    INFO >> Epoch   2/100, Batch 8500/10106, train loss: 363.4799 (train.py:127, train())
[2021-11-06 01:57:01]    INFO >> Epoch   2/100, Batch 9000/10106, train loss: 361.0705 (train.py:127, train())
[2021-11-06 02:00:40]    INFO >> Epoch   2/100, Batch 9500/10106, train loss: 359.2722 (train.py:127, train())
[2021-11-06 02:04:13]    INFO >> Epoch   2/100, Batch 10000/10106, train loss: 356.9634 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 02:05:04]    INFO >> Epoch   2/100, train loss: 356.8325 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 02:10:02]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 02:10:02]    INFO >> Epoch   2/100, valid loss: 0.0000, valid bleu4: 13.42, best bleu4: 13.42 (train.py:217, <module>())
[2021-11-06 02:10:10]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 02:15:33]    INFO >> Epoch   3/100, Batch 500/10106, train loss: 303.2337 (train.py:127, train())
[2021-11-06 02:18:48]    INFO >> Epoch   3/100, Batch 1000/10106, train loss: 298.6211 (train.py:127, train())
[2021-11-06 02:22:20]    INFO >> Epoch   3/100, Batch 1500/10106, train loss: 300.5413 (train.py:127, train())
[2021-11-06 02:25:53]    INFO >> Epoch   3/100, Batch 2000/10106, train loss: 298.2153 (train.py:127, train())
[2021-11-06 02:29:39]    INFO >> Epoch   3/100, Batch 2500/10106, train loss: 296.8458 (train.py:127, train())
[2021-11-06 02:33:41]    INFO >> Epoch   3/100, Batch 3000/10106, train loss: 296.4120 (train.py:127, train())
[2021-11-06 02:37:13]    INFO >> Epoch   3/100, Batch 3500/10106, train loss: 295.7513 (train.py:127, train())
[2021-11-06 02:40:45]    INFO >> Epoch   3/100, Batch 4000/10106, train loss: 294.1781 (train.py:127, train())
[2021-11-06 02:44:17]    INFO >> Epoch   3/100, Batch 4500/10106, train loss: 292.3195 (train.py:127, train())
[2021-11-06 02:48:19]    INFO >> Epoch   3/100, Batch 5000/10106, train loss: 290.3918 (train.py:127, train())
[2021-11-06 02:52:49]    INFO >> Epoch   3/100, Batch 5500/10106, train loss: 288.3488 (train.py:127, train())
[2021-11-06 02:57:02]    INFO >> Epoch   3/100, Batch 6000/10106, train loss: 286.7821 (train.py:127, train())
[2021-11-06 03:01:15]    INFO >> Epoch   3/100, Batch 6500/10106, train loss: 285.0550 (train.py:127, train())
[2021-11-06 03:05:01]    INFO >> Epoch   3/100, Batch 7000/10106, train loss: 284.6804 (train.py:127, train())
[2021-11-06 03:09:20]    INFO >> Epoch   3/100, Batch 7500/10106, train loss: 283.1445 (train.py:127, train())
[2021-11-06 03:12:42]    INFO >> Epoch   3/100, Batch 8000/10106, train loss: 282.5847 (train.py:127, train())
[2021-11-06 03:16:14]    INFO >> Epoch   3/100, Batch 8500/10106, train loss: 281.4675 (train.py:127, train())
[2021-11-06 03:19:46]    INFO >> Epoch   3/100, Batch 9000/10106, train loss: 280.3657 (train.py:127, train())
[2021-11-06 03:23:08]    INFO >> Epoch   3/100, Batch 9500/10106, train loss: 279.2057 (train.py:127, train())
[2021-11-06 03:27:38]    INFO >> Epoch   3/100, Batch 10000/10106, train loss: 278.1940 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 03:28:19]    INFO >> Epoch   3/100, train loss: 277.7006 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 03:33:16]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 03:33:16]    INFO >> Epoch   3/100, valid loss: 0.0000, valid bleu4: 15.69, best bleu4: 15.69 (train.py:217, <module>())
[2021-11-06 03:33:24]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 03:37:51]    INFO >> Epoch   4/100, Batch 500/10106, train loss: 244.2617 (train.py:127, train())
[2021-11-06 03:41:41]    INFO >> Epoch   4/100, Batch 1000/10106, train loss: 242.5823 (train.py:127, train())
[2021-11-06 03:45:39]    INFO >> Epoch   4/100, Batch 1500/10106, train loss: 242.6674 (train.py:127, train())
[2021-11-06 03:49:11]    INFO >> Epoch   4/100, Batch 2000/10106, train loss: 242.8995 (train.py:127, train())
[2021-11-06 03:52:43]    INFO >> Epoch   4/100, Batch 2500/10106, train loss: 241.4379 (train.py:127, train())
[2021-11-06 03:56:15]    INFO >> Epoch   4/100, Batch 3000/10106, train loss: 241.0379 (train.py:127, train())
[2021-11-06 04:00:21]    INFO >> Epoch   4/100, Batch 3500/10106, train loss: 240.8162 (train.py:127, train())
[2021-11-06 04:04:02]    INFO >> Epoch   4/100, Batch 4000/10106, train loss: 239.8926 (train.py:127, train())
[2021-11-06 04:07:35]    INFO >> Epoch   4/100, Batch 4500/10106, train loss: 238.7316 (train.py:127, train())
[2021-11-06 04:11:07]    INFO >> Epoch   4/100, Batch 5000/10106, train loss: 238.3454 (train.py:127, train())
[2021-11-06 04:14:38]    INFO >> Epoch   4/100, Batch 5500/10106, train loss: 236.7421 (train.py:127, train())
[2021-11-06 04:19:01]    INFO >> Epoch   4/100, Batch 6000/10106, train loss: 235.8892 (train.py:127, train())
[2021-11-06 04:22:19]    INFO >> Epoch   4/100, Batch 6500/10106, train loss: 234.2694 (train.py:127, train())
[2021-11-06 04:25:51]    INFO >> Epoch   4/100, Batch 7000/10106, train loss: 233.0274 (train.py:127, train())
[2021-11-06 04:29:23]    INFO >> Epoch   4/100, Batch 7500/10106, train loss: 231.5802 (train.py:127, train())
[2021-11-06 04:32:57]    INFO >> Epoch   4/100, Batch 8000/10106, train loss: 230.8182 (train.py:127, train())
[2021-11-06 04:37:21]    INFO >> Epoch   4/100, Batch 8500/10106, train loss: 229.6161 (train.py:127, train())
[2021-11-06 04:40:43]    INFO >> Epoch   4/100, Batch 9000/10106, train loss: 228.8082 (train.py:127, train())
[2021-11-06 04:44:15]    INFO >> Epoch   4/100, Batch 9500/10106, train loss: 227.7426 (train.py:127, train())
[2021-11-06 04:47:47]    INFO >> Epoch   4/100, Batch 10000/10106, train loss: 226.9677 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 04:48:37]    INFO >> Epoch   4/100, train loss: 226.6344 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 04:54:09]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 04:54:09]    INFO >> Epoch   4/100, valid loss: 0.0000, valid bleu4: 19.16, best bleu4: 19.16 (train.py:217, <module>())
[2021-11-06 04:54:17]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 04:58:45]    INFO >> Epoch   5/100, Batch 500/10106, train loss: 203.6448 (train.py:127, train())
[2021-11-06 05:02:17]    INFO >> Epoch   5/100, Batch 1000/10106, train loss: 201.0315 (train.py:127, train())
[2021-11-06 05:05:50]    INFO >> Epoch   5/100, Batch 1500/10106, train loss: 200.9105 (train.py:127, train())
[2021-11-06 05:09:55]    INFO >> Epoch   5/100, Batch 2000/10106, train loss: 199.4114 (train.py:127, train())
[2021-11-06 05:13:37]    INFO >> Epoch   5/100, Batch 2500/10106, train loss: 197.5366 (train.py:127, train())
[2021-11-06 05:17:09]    INFO >> Epoch   5/100, Batch 3000/10106, train loss: 197.2623 (train.py:127, train())
[2021-11-06 05:20:41]    INFO >> Epoch   5/100, Batch 3500/10106, train loss: 195.7516 (train.py:127, train())
[2021-11-06 05:24:13]    INFO >> Epoch   5/100, Batch 4000/10106, train loss: 195.3817 (train.py:127, train())
[2021-11-06 05:28:34]    INFO >> Epoch   5/100, Batch 4500/10106, train loss: 195.0596 (train.py:127, train())
[2021-11-06 05:32:01]    INFO >> Epoch   5/100, Batch 5000/10106, train loss: 194.5163 (train.py:127, train())
[2021-11-06 05:35:33]    INFO >> Epoch   5/100, Batch 5500/10106, train loss: 194.0851 (train.py:127, train())
[2021-11-06 05:39:06]    INFO >> Epoch   5/100, Batch 6000/10106, train loss: 193.3964 (train.py:127, train())
[2021-11-06 05:42:46]    INFO >> Epoch   5/100, Batch 6500/10106, train loss: 193.0839 (train.py:127, train())
[2021-11-06 05:46:57]    INFO >> Epoch   5/100, Batch 7000/10106, train loss: 192.4416 (train.py:127, train())
[2021-11-06 05:50:26]    INFO >> Epoch   5/100, Batch 7500/10106, train loss: 191.7438 (train.py:127, train())
[2021-11-06 05:53:59]    INFO >> Epoch   5/100, Batch 8000/10106, train loss: 191.1429 (train.py:127, train())
[2021-11-06 05:57:31]    INFO >> Epoch   5/100, Batch 8500/10106, train loss: 190.3647 (train.py:127, train())
[2021-11-06 06:01:27]    INFO >> Epoch   5/100, Batch 9000/10106, train loss: 189.6191 (train.py:127, train())
[2021-11-06 06:05:20]    INFO >> Epoch   5/100, Batch 9500/10106, train loss: 188.5934 (train.py:127, train())
[2021-11-06 06:08:52]    INFO >> Epoch   5/100, Batch 10000/10106, train loss: 187.9895 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 06:09:43]    INFO >> Epoch   5/100, train loss: 187.9327 (train.py:136, <module>())
[2021-11-06 06:09:47]    INFO >> save /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/5.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 06:14:43]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 06:14:43]    INFO >> Epoch   5/100, valid loss: 0.0000, valid bleu4: 25.31, best bleu4: 25.31 (train.py:217, <module>())
[2021-11-06 06:14:52]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 06:20:02]    INFO >> Epoch   6/100, Batch 500/10106, train loss: 161.2010 (train.py:127, train())
[2021-11-06 06:23:24]    INFO >> Epoch   6/100, Batch 1000/10106, train loss: 165.7367 (train.py:127, train())
[2021-11-06 06:26:56]    INFO >> Epoch   6/100, Batch 1500/10106, train loss: 165.0278 (train.py:127, train())
[2021-11-06 06:30:29]    INFO >> Epoch   6/100, Batch 2000/10106, train loss: 165.1980 (train.py:127, train())
[2021-11-06 06:34:02]    INFO >> Epoch   6/100, Batch 2500/10106, train loss: 165.7801 (train.py:127, train())
[2021-11-06 06:38:32]    INFO >> Epoch   6/100, Batch 3000/10106, train loss: 165.1655 (train.py:127, train())
[2021-11-06 06:41:50]    INFO >> Epoch   6/100, Batch 3500/10106, train loss: 165.3036 (train.py:127, train())
[2021-11-06 06:45:22]    INFO >> Epoch   6/100, Batch 4000/10106, train loss: 164.1990 (train.py:127, train())
[2021-11-06 06:48:55]    INFO >> Epoch   6/100, Batch 4500/10106, train loss: 163.3950 (train.py:127, train())
[2021-11-06 06:52:42]    INFO >> Epoch   6/100, Batch 5000/10106, train loss: 162.5088 (train.py:127, train())
[2021-11-06 06:56:43]    INFO >> Epoch   6/100, Batch 5500/10106, train loss: 162.5443 (train.py:127, train())
[2021-11-06 07:00:14]    INFO >> Epoch   6/100, Batch 6000/10106, train loss: 162.1630 (train.py:127, train())
[2021-11-06 07:03:46]    INFO >> Epoch   6/100, Batch 6500/10106, train loss: 161.4188 (train.py:127, train())
[2021-11-06 07:07:19]    INFO >> Epoch   6/100, Batch 7000/10106, train loss: 160.9624 (train.py:127, train())
[2021-11-06 07:11:21]    INFO >> Epoch   6/100, Batch 7500/10106, train loss: 160.4020 (train.py:127, train())
[2021-11-06 07:15:06]    INFO >> Epoch   6/100, Batch 8000/10106, train loss: 159.9032 (train.py:127, train())
[2021-11-06 07:18:38]    INFO >> Epoch   6/100, Batch 8500/10106, train loss: 159.5458 (train.py:127, train())
[2021-11-06 07:22:10]    INFO >> Epoch   6/100, Batch 9000/10106, train loss: 159.1110 (train.py:127, train())
[2021-11-06 07:25:42]    INFO >> Epoch   6/100, Batch 9500/10106, train loss: 158.5364 (train.py:127, train())
[2021-11-06 07:29:59]    INFO >> Epoch   6/100, Batch 10000/10106, train loss: 158.1191 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 07:31:03]    INFO >> Epoch   6/100, train loss: 158.1227 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 07:35:56]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 07:35:56]    INFO >> Epoch   6/100, valid loss: 0.0000, valid bleu4: 28.94, best bleu4: 28.94 (train.py:217, <module>())
[2021-11-06 07:36:08]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 07:40:37]    INFO >> Epoch   7/100, Batch 500/10106, train loss: 139.8293 (train.py:127, train())
[2021-11-06 07:44:12]    INFO >> Epoch   7/100, Batch 1000/10106, train loss: 141.1849 (train.py:127, train())
[2021-11-06 07:48:18]    INFO >> Epoch   7/100, Batch 1500/10106, train loss: 140.0000 (train.py:127, train())
[2021-11-06 07:51:50]    INFO >> Epoch   7/100, Batch 2000/10106, train loss: 138.6480 (train.py:127, train())
[2021-11-06 07:55:22]    INFO >> Epoch   7/100, Batch 2500/10106, train loss: 139.0833 (train.py:127, train())
[2021-11-06 07:58:54]    INFO >> Epoch   7/100, Batch 3000/10106, train loss: 139.1836 (train.py:127, train())
[2021-11-06 08:02:51]    INFO >> Epoch   7/100, Batch 3500/10106, train loss: 139.2490 (train.py:127, train())
[2021-11-06 08:06:42]    INFO >> Epoch   7/100, Batch 4000/10106, train loss: 138.8324 (train.py:127, train())
[2021-11-06 08:10:14]    INFO >> Epoch   7/100, Batch 4500/10106, train loss: 138.6342 (train.py:127, train())
[2021-11-06 08:13:46]    INFO >> Epoch   7/100, Batch 5000/10106, train loss: 138.2746 (train.py:127, train())
[2021-11-06 08:17:18]    INFO >> Epoch   7/100, Batch 5500/10106, train loss: 138.1407 (train.py:127, train())
[2021-11-06 08:21:30]    INFO >> Epoch   7/100, Batch 6000/10106, train loss: 137.5253 (train.py:127, train())
[2021-11-06 08:25:05]    INFO >> Epoch   7/100, Batch 6500/10106, train loss: 137.3270 (train.py:127, train())
[2021-11-06 08:28:37]    INFO >> Epoch   7/100, Batch 7000/10106, train loss: 137.1952 (train.py:127, train())
[2021-11-06 08:32:09]    INFO >> Epoch   7/100, Batch 7500/10106, train loss: 136.8942 (train.py:127, train())
[2021-11-06 08:35:39]    INFO >> Epoch   7/100, Batch 8000/10106, train loss: 136.6034 (train.py:127, train())
[2021-11-06 08:40:09]    INFO >> Epoch   7/100, Batch 8500/10106, train loss: 136.3548 (train.py:127, train())
[2021-11-06 08:43:28]    INFO >> Epoch   7/100, Batch 9000/10106, train loss: 136.1883 (train.py:127, train())
[2021-11-06 08:47:00]    INFO >> Epoch   7/100, Batch 9500/10106, train loss: 135.7904 (train.py:127, train())
[2021-11-06 08:50:32]    INFO >> Epoch   7/100, Batch 10000/10106, train loss: 135.5241 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 08:51:23]    INFO >> Epoch   7/100, train loss: 135.4589 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 08:57:00]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 08:57:00]    INFO >> Epoch   7/100, valid loss: 0.0000, valid bleu4: 33.24, best bleu4: 33.24 (train.py:217, <module>())
[2021-11-06 08:57:08]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 09:01:36]    INFO >> Epoch   8/100, Batch 500/10106, train loss: 128.9206 (train.py:127, train())
[2021-11-06 09:05:08]    INFO >> Epoch   8/100, Batch 1000/10106, train loss: 122.8832 (train.py:127, train())
[2021-11-06 09:08:40]    INFO >> Epoch   8/100, Batch 1500/10106, train loss: 121.8748 (train.py:127, train())
[2021-11-06 09:12:32]    INFO >> Epoch   8/100, Batch 2000/10106, train loss: 121.4832 (train.py:127, train())
[2021-11-06 09:15:50]    INFO >> Epoch   8/100, Batch 2500/10106, train loss: 121.3929 (train.py:127, train())
[2021-11-06 09:17:38]    INFO >> Epoch   8/100, Batch 3000/10106, train loss: 121.1479 (train.py:127, train())
[2021-11-06 09:19:29]    INFO >> Epoch   8/100, Batch 3500/10106, train loss: 120.6662 (train.py:127, train())
[2021-11-06 09:21:17]    INFO >> Epoch   8/100, Batch 4000/10106, train loss: 120.6693 (train.py:127, train())
[2021-11-06 09:23:10]    INFO >> Epoch   8/100, Batch 4500/10106, train loss: 120.5558 (train.py:127, train())
[2021-11-06 09:25:02]    INFO >> Epoch   8/100, Batch 5000/10106, train loss: 119.9195 (train.py:127, train())
[2021-11-06 09:26:55]    INFO >> Epoch   8/100, Batch 5500/10106, train loss: 119.5713 (train.py:127, train())
[2021-11-06 09:28:48]    INFO >> Epoch   8/100, Batch 6000/10106, train loss: 119.3016 (train.py:127, train())
[2021-11-06 09:30:41]    INFO >> Epoch   8/100, Batch 6500/10106, train loss: 118.7352 (train.py:127, train())
[2021-11-06 09:32:34]    INFO >> Epoch   8/100, Batch 7000/10106, train loss: 118.6130 (train.py:127, train())
[2021-11-06 09:34:28]    INFO >> Epoch   8/100, Batch 7500/10106, train loss: 118.2658 (train.py:127, train())
[2021-11-06 09:36:21]    INFO >> Epoch   8/100, Batch 8000/10106, train loss: 118.2504 (train.py:127, train())
[2021-11-06 09:39:08]    INFO >> Epoch   8/100, Batch 8500/10106, train loss: 117.8339 (train.py:127, train())
[2021-11-06 09:41:01]    INFO >> Epoch   8/100, Batch 9000/10106, train loss: 117.9372 (train.py:127, train())
[2021-11-06 09:42:54]    INFO >> Epoch   8/100, Batch 9500/10106, train loss: 117.8327 (train.py:127, train())
[2021-11-06 09:44:48]    INFO >> Epoch   8/100, Batch 10000/10106, train loss: 117.4987 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 09:45:17]    INFO >> Epoch   8/100, train loss: 117.4257 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 09:48:03]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 09:48:03]    INFO >> Epoch   8/100, valid loss: 0.0000, valid bleu4: 35.15, best bleu4: 35.15 (train.py:217, <module>())
[2021-11-06 09:48:11]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 09:50:58]    INFO >> Epoch   9/100, Batch 500/10106, train loss: 104.4177 (train.py:127, train())
[2021-11-06 09:52:52]    INFO >> Epoch   9/100, Batch 1000/10106, train loss: 103.2367 (train.py:127, train())
[2021-11-06 09:54:50]    INFO >> Epoch   9/100, Batch 1500/10106, train loss: 103.7648 (train.py:127, train())
[2021-11-06 09:58:22]    INFO >> Epoch   9/100, Batch 2000/10106, train loss: 103.5799 (train.py:127, train())
[2021-11-06 10:00:30]    INFO >> Epoch   9/100, Batch 2500/10106, train loss: 103.7122 (train.py:127, train())
[2021-11-06 10:02:23]    INFO >> Epoch   9/100, Batch 3000/10106, train loss: 103.0850 (train.py:127, train())
[2021-11-06 10:04:16]    INFO >> Epoch   9/100, Batch 3500/10106, train loss: 102.8226 (train.py:127, train())
[2021-11-06 10:06:40]    INFO >> Epoch   9/100, Batch 4000/10106, train loss: 102.8215 (train.py:127, train())
[2021-11-06 10:10:13]    INFO >> Epoch   9/100, Batch 4500/10106, train loss: 102.8957 (train.py:127, train())
[2021-11-06 10:13:46]    INFO >> Epoch   9/100, Batch 5000/10106, train loss: 102.2905 (train.py:127, train())
[2021-11-06 10:17:20]    INFO >> Epoch   9/100, Batch 5500/10106, train loss: 102.2966 (train.py:127, train())
[2021-11-06 10:20:40]    INFO >> Epoch   9/100, Batch 6000/10106, train loss: 102.2132 (train.py:127, train())
[2021-11-06 10:23:37]    INFO >> Epoch   9/100, Batch 6500/10106, train loss: 102.2041 (train.py:127, train())
[2021-11-06 10:27:10]    INFO >> Epoch   9/100, Batch 7000/10106, train loss: 102.4735 (train.py:127, train())
[2021-11-06 10:30:44]    INFO >> Epoch   9/100, Batch 7500/10106, train loss: 102.2473 (train.py:127, train())
[2021-11-06 10:34:17]    INFO >> Epoch   9/100, Batch 8000/10106, train loss: 101.9230 (train.py:127, train())
[2021-11-06 10:37:02]    INFO >> Epoch   9/100, Batch 8500/10106, train loss: 101.8383 (train.py:127, train())
[2021-11-06 10:40:26]    INFO >> Epoch   9/100, Batch 9000/10106, train loss: 101.5124 (train.py:127, train())
[2021-11-06 10:44:00]    INFO >> Epoch   9/100, Batch 9500/10106, train loss: 101.3158 (train.py:127, train())
[2021-11-06 10:47:47]    INFO >> Epoch   9/100, Batch 10000/10106, train loss: 101.1061 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 10:48:37]    INFO >> Epoch   9/100, train loss: 101.0523 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 10:53:16]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 10:53:16]    INFO >> Epoch   9/100, valid loss: 0.0000, valid bleu4: 35.78, best bleu4: 35.78 (train.py:217, <module>())
[2021-11-06 10:53:24]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 10:58:02]    INFO >> Epoch  10/100, Batch 500/10106, train loss: 84.3052 (train.py:127, train())
[2021-11-06 11:00:46]    INFO >> Epoch  10/100, Batch 1000/10106, train loss: 85.5435 (train.py:127, train())
[2021-11-06 11:02:39]    INFO >> Epoch  10/100, Batch 1500/10106, train loss: 87.3237 (train.py:127, train())
[2021-11-06 11:04:32]    INFO >> Epoch  10/100, Batch 2000/10106, train loss: 87.5705 (train.py:127, train())
[2021-11-06 11:06:25]    INFO >> Epoch  10/100, Batch 2500/10106, train loss: 87.7965 (train.py:127, train())
[2021-11-06 11:08:19]    INFO >> Epoch  10/100, Batch 3000/10106, train loss: 88.2379 (train.py:127, train())
[2021-11-06 11:10:12]    INFO >> Epoch  10/100, Batch 3500/10106, train loss: 88.7196 (train.py:127, train())
[2021-11-06 11:12:02]    INFO >> Epoch  10/100, Batch 4000/10106, train loss: 88.6340 (train.py:127, train())
[2021-11-06 11:14:00]    INFO >> Epoch  10/100, Batch 4500/10106, train loss: 88.4259 (train.py:127, train())
[2021-11-06 11:15:53]    INFO >> Epoch  10/100, Batch 5000/10106, train loss: 88.3567 (train.py:127, train())
[2021-11-06 11:17:48]    INFO >> Epoch  10/100, Batch 5500/10106, train loss: 88.1519 (train.py:127, train())
[2021-11-06 11:20:06]    INFO >> Epoch  10/100, Batch 6000/10106, train loss: 88.2053 (train.py:127, train())
[2021-11-06 11:23:35]    INFO >> Epoch  10/100, Batch 6500/10106, train loss: 88.1912 (train.py:127, train())
[2021-11-06 11:27:04]    INFO >> Epoch  10/100, Batch 7000/10106, train loss: 87.9631 (train.py:127, train())
[2021-11-06 11:30:32]    INFO >> Epoch  10/100, Batch 7500/10106, train loss: 87.6375 (train.py:127, train())
[2021-11-06 11:33:59]    INFO >> Epoch  10/100, Batch 8000/10106, train loss: 87.9162 (train.py:127, train())
[2021-11-06 11:37:20]    INFO >> Epoch  10/100, Batch 8500/10106, train loss: 87.9455 (train.py:127, train())
[2021-11-06 11:40:07]    INFO >> Epoch  10/100, Batch 9000/10106, train loss: 87.6209 (train.py:127, train())
[2021-11-06 11:43:35]    INFO >> Epoch  10/100, Batch 9500/10106, train loss: 87.5072 (train.py:127, train())
[2021-11-06 11:47:03]    INFO >> Epoch  10/100, Batch 10000/10106, train loss: 87.5045 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 11:47:52]    INFO >> Epoch  10/100, train loss: 87.4075 (train.py:136, <module>())
[2021-11-06 11:47:56]    INFO >> save /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/10.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 11:52:47]    INFO >> Epoch  10/100, valid loss: 0.0000, valid bleu4: 35.62, best bleu4: 35.78 (train.py:217, <module>())
[2021-11-06 11:52:55]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 11:56:38]    INFO >> Epoch  11/100, Batch 500/10106, train loss: 71.5921 (train.py:127, train())
[2021-11-06 12:00:01]    INFO >> Epoch  11/100, Batch 1000/10106, train loss: 74.0654 (train.py:127, train())
[2021-11-06 12:03:29]    INFO >> Epoch  11/100, Batch 1500/10106, train loss: 74.6001 (train.py:127, train())
[2021-11-06 12:06:58]    INFO >> Epoch  11/100, Batch 2000/10106, train loss: 74.3473 (train.py:127, train())
[2021-11-06 12:10:25]    INFO >> Epoch  11/100, Batch 2500/10106, train loss: 74.8763 (train.py:127, train())
[2021-11-06 12:13:53]    INFO >> Epoch  11/100, Batch 3000/10106, train loss: 75.2971 (train.py:127, train())
[2021-11-06 12:16:20]    INFO >> Epoch  11/100, Batch 3500/10106, train loss: 74.9136 (train.py:127, train())
[2021-11-06 12:19:48]    INFO >> Epoch  11/100, Batch 4000/10106, train loss: 75.2134 (train.py:127, train())
[2021-11-06 12:23:15]    INFO >> Epoch  11/100, Batch 4500/10106, train loss: 75.1900 (train.py:127, train())
[2021-11-06 12:26:42]    INFO >> Epoch  11/100, Batch 5000/10106, train loss: 75.0883 (train.py:127, train())
[2021-11-06 12:30:10]    INFO >> Epoch  11/100, Batch 5500/10106, train loss: 75.0137 (train.py:127, train())
[2021-11-06 12:33:38]    INFO >> Epoch  11/100, Batch 6000/10106, train loss: 75.1820 (train.py:127, train())
[2021-11-06 12:36:19]    INFO >> Epoch  11/100, Batch 6500/10106, train loss: 75.3281 (train.py:127, train())
[2021-11-06 12:39:46]    INFO >> Epoch  11/100, Batch 7000/10106, train loss: 75.3857 (train.py:127, train())
[2021-11-06 12:43:14]    INFO >> Epoch  11/100, Batch 7500/10106, train loss: 75.3116 (train.py:127, train())
[2021-11-06 12:46:43]    INFO >> Epoch  11/100, Batch 8000/10106, train loss: 75.0573 (train.py:127, train())
[2021-11-06 12:50:11]    INFO >> Epoch  11/100, Batch 8500/10106, train loss: 74.7687 (train.py:127, train())
[2021-11-06 12:53:21]    INFO >> Epoch  11/100, Batch 9000/10106, train loss: 74.5935 (train.py:127, train())
[2021-11-06 12:56:06]    INFO >> Epoch  11/100, Batch 9500/10106, train loss: 74.5879 (train.py:127, train())
[2021-11-06 12:59:34]    INFO >> Epoch  11/100, Batch 10000/10106, train loss: 74.4916 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 13:00:23]    INFO >> Epoch  11/100, train loss: 74.4325 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 13:05:22]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/best_checkpoint.pt (train.py:215, <module>())
[2021-11-06 13:05:22]    INFO >> Epoch  11/100, valid loss: 0.0000, valid bleu4: 37.20, best bleu4: 37.20 (train.py:217, <module>())
[2021-11-06 13:05:30]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 13:09:51]    INFO >> Epoch  12/100, Batch 500/10106, train loss: 60.8711 (train.py:127, train())
[2021-11-06 13:12:33]    INFO >> Epoch  12/100, Batch 1000/10106, train loss: 62.2049 (train.py:127, train())
[2021-11-06 13:15:58]    INFO >> Epoch  12/100, Batch 1500/10106, train loss: 63.0372 (train.py:127, train())
[2021-11-06 13:19:27]    INFO >> Epoch  12/100, Batch 2000/10106, train loss: 63.0215 (train.py:127, train())
[2021-11-06 13:22:55]    INFO >> Epoch  12/100, Batch 2500/10106, train loss: 63.3129 (train.py:127, train())
[2021-11-06 13:26:22]    INFO >> Epoch  12/100, Batch 3000/10106, train loss: 63.0551 (train.py:127, train())
[2021-11-06 13:29:49]    INFO >> Epoch  12/100, Batch 3500/10106, train loss: 63.1015 (train.py:127, train())
[2021-11-06 13:32:19]    INFO >> Epoch  12/100, Batch 4000/10106, train loss: 63.0730 (train.py:127, train())
[2021-11-06 13:35:47]    INFO >> Epoch  12/100, Batch 4500/10106, train loss: 63.3983 (train.py:127, train())
[2021-11-06 13:39:15]    INFO >> Epoch  12/100, Batch 5000/10106, train loss: 63.3154 (train.py:127, train())
[2021-11-06 13:42:43]    INFO >> Epoch  12/100, Batch 5500/10106, train loss: 63.2594 (train.py:127, train())
[2021-11-06 13:46:12]    INFO >> Epoch  12/100, Batch 6000/10106, train loss: 63.0830 (train.py:127, train())
[2021-11-06 13:49:38]    INFO >> Epoch  12/100, Batch 6500/10106, train loss: 63.1705 (train.py:127, train())
[2021-11-06 13:52:13]    INFO >> Epoch  12/100, Batch 7000/10106, train loss: 62.9184 (train.py:127, train())
[2021-11-06 13:55:40]    INFO >> Epoch  12/100, Batch 7500/10106, train loss: 62.8087 (train.py:127, train())
[2021-11-06 13:59:08]    INFO >> Epoch  12/100, Batch 8000/10106, train loss: 62.5806 (train.py:127, train())
[2021-11-06 14:02:36]    INFO >> Epoch  12/100, Batch 8500/10106, train loss: 62.5504 (train.py:127, train())
[2021-11-06 14:06:03]    INFO >> Epoch  12/100, Batch 9000/10106, train loss: 62.2937 (train.py:127, train())
[2021-11-06 14:09:17]    INFO >> Epoch  12/100, Batch 9500/10106, train loss: 62.1397 (train.py:127, train())
[2021-11-06 14:12:04]    INFO >> Epoch  12/100, Batch 10000/10106, train loss: 61.9789 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 14:12:53]    INFO >> Epoch  12/100, train loss: 61.9878 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 14:17:45]    INFO >> Epoch  12/100, valid loss: 0.0000, valid bleu4: 36.70, best bleu4: 37.20 (train.py:217, <module>())
[2021-11-06 14:17:52]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 14:22:15]    INFO >> Epoch  13/100, Batch 500/10106, train loss: 49.9730 (train.py:127, train())
[2021-11-06 14:25:42]    INFO >> Epoch  13/100, Batch 1000/10106, train loss: 51.4746 (train.py:127, train())
[2021-11-06 14:28:27]    INFO >> Epoch  13/100, Batch 1500/10106, train loss: 51.5749 (train.py:127, train())
[2021-11-06 14:31:36]    INFO >> Epoch  13/100, Batch 2000/10106, train loss: 52.2845 (train.py:127, train())
[2021-11-06 14:35:04]    INFO >> Epoch  13/100, Batch 2500/10106, train loss: 52.9178 (train.py:127, train())
[2021-11-06 14:38:31]    INFO >> Epoch  13/100, Batch 3000/10106, train loss: 53.1722 (train.py:127, train())
[2021-11-06 14:41:58]    INFO >> Epoch  13/100, Batch 3500/10106, train loss: 53.1059 (train.py:127, train())
[2021-11-06 14:45:26]    INFO >> Epoch  13/100, Batch 4000/10106, train loss: 53.4962 (train.py:127, train())
[2021-11-06 14:47:58]    INFO >> Epoch  13/100, Batch 4500/10106, train loss: 53.6664 (train.py:127, train())
[2021-11-06 14:51:25]    INFO >> Epoch  13/100, Batch 5000/10106, train loss: 53.6086 (train.py:127, train())
[2021-11-06 14:54:52]    INFO >> Epoch  13/100, Batch 5500/10106, train loss: 53.7721 (train.py:127, train())
[2021-11-06 14:58:19]    INFO >> Epoch  13/100, Batch 6000/10106, train loss: 53.7139 (train.py:127, train())
[2021-11-06 15:01:47]    INFO >> Epoch  13/100, Batch 6500/10106, train loss: 53.7567 (train.py:127, train())
[2021-11-06 15:05:14]    INFO >> Epoch  13/100, Batch 7000/10106, train loss: 53.7580 (train.py:127, train())
[2021-11-06 15:07:45]    INFO >> Epoch  13/100, Batch 7500/10106, train loss: 53.6382 (train.py:127, train())
[2021-11-06 15:11:13]    INFO >> Epoch  13/100, Batch 8000/10106, train loss: 53.4786 (train.py:127, train())
[2021-11-06 15:14:41]    INFO >> Epoch  13/100, Batch 8500/10106, train loss: 53.4082 (train.py:127, train())
[2021-11-06 15:18:08]    INFO >> Epoch  13/100, Batch 9000/10106, train loss: 53.2548 (train.py:127, train())
[2021-11-06 15:21:35]    INFO >> Epoch  13/100, Batch 9500/10106, train loss: 53.1142 (train.py:127, train())
[2021-11-06 15:24:58]    INFO >> Epoch  13/100, Batch 10000/10106, train loss: 53.1071 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 15:25:34]    INFO >> Epoch  13/100, train loss: 53.0828 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 15:29:51]    INFO >> Epoch  13/100, valid loss: 0.0000, valid bleu4: 37.06, best bleu4: 37.20 (train.py:217, <module>())
[2021-11-06 15:29:59]    INFO >> update /mnt/wanyao/ncc_data/avatar/translation/top5/graphcodebert/data-mmap/java-python/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 15:34:22]    INFO >> Epoch  14/100, Batch 500/10106, train loss: 43.5583 (train.py:127, train())
[2021-11-06 15:37:49]    INFO >> Epoch  14/100, Batch 1000/10106, train loss: 44.2243 (train.py:127, train())
[2021-11-06 15:41:17]    INFO >> Epoch  14/100, Batch 1500/10106, train loss: 44.6747 (train.py:127, train())
[2021-11-06 15:44:16]    INFO >> Epoch  14/100, Batch 2000/10106, train loss: 44.5940 (train.py:127, train())
[2021-11-06 15:47:14]    INFO >> Epoch  14/100, Batch 2500/10106, train loss: 44.7499 (train.py:127, train())
