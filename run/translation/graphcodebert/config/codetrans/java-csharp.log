nohup: ignoring input
Using backend: pytorch
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[2021-11-05 05:53:34]    INFO >> No /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt to initialize model (train.py:88, <module>())
[2021-11-05 05:53:34]    INFO >> Start training epoch   1/100, best bleu4: 0.00 (train.py:90, <module>())
/home/wanyao/anaconda3/envs/py37-1.7/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[2021-11-05 05:56:11]    INFO >> Epoch   1/100, Batch 500/2575, train loss: 623.7381 (train.py:127, train())
[2021-11-05 05:58:32]    INFO >> Epoch   1/100, Batch 1000/2575, train loss: 529.4831 (train.py:127, train())
[2021-11-05 06:00:59]    INFO >> Epoch   1/100, Batch 1500/2575, train loss: 479.2387 (train.py:127, train())
[2021-11-05 06:03:15]    INFO >> Epoch   1/100, Batch 2000/2575, train loss: 438.9243 (train.py:127, train())
[2021-11-05 06:05:34]    INFO >> Epoch   1/100, Batch 2500/2575, train loss: 405.6676 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 06:05:55]    INFO >> Epoch   1/100, train loss: 402.3186 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 06:08:13]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 06:08:13]    INFO >> Epoch   1/100, valid loss: 0.0000, valid bleu4: 9.25, best bleu4: 9.25 (train.py:217, <module>())
[2021-11-05 06:08:17]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 06:10:43]    INFO >> Epoch   2/100, Batch 500/2575, train loss: 258.0062 (train.py:127, train())
[2021-11-05 06:13:04]    INFO >> Epoch   2/100, Batch 1000/2575, train loss: 241.7997 (train.py:127, train())
[2021-11-05 06:15:26]    INFO >> Epoch   2/100, Batch 1500/2575, train loss: 231.1586 (train.py:127, train())
[2021-11-05 06:17:45]    INFO >> Epoch   2/100, Batch 2000/2575, train loss: 221.6028 (train.py:127, train())
[2021-11-05 06:20:01]    INFO >> Epoch   2/100, Batch 2500/2575, train loss: 212.4531 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 06:20:23]    INFO >> Epoch   2/100, train loss: 211.2517 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 06:22:43]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 06:22:44]    INFO >> Epoch   2/100, valid loss: 0.0000, valid bleu4: 10.39, best bleu4: 10.39 (train.py:217, <module>())
[2021-11-05 06:22:52]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 06:25:29]    INFO >> Epoch   3/100, Batch 500/2575, train loss: 160.4825 (train.py:127, train())
[2021-11-05 06:29:02]    INFO >> Epoch   3/100, Batch 1000/2575, train loss: 157.4358 (train.py:127, train())
[2021-11-05 06:33:22]    INFO >> Epoch   3/100, Batch 1500/2575, train loss: 150.7368 (train.py:127, train())
[2021-11-05 06:37:21]    INFO >> Epoch   3/100, Batch 2000/2575, train loss: 146.0012 (train.py:127, train())
[2021-11-05 06:41:25]    INFO >> Epoch   3/100, Batch 2500/2575, train loss: 143.5046 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 06:42:02]    INFO >> Epoch   3/100, train loss: 143.2378 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 06:45:57]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 06:45:57]    INFO >> Epoch   3/100, valid loss: 0.0000, valid bleu4: 20.25, best bleu4: 20.25 (train.py:217, <module>())
[2021-11-05 06:46:07]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 06:50:41]    INFO >> Epoch   4/100, Batch 500/2575, train loss: 119.0386 (train.py:127, train())
[2021-11-05 06:54:52]    INFO >> Epoch   4/100, Batch 1000/2575, train loss: 109.9019 (train.py:127, train())
[2021-11-05 06:58:59]    INFO >> Epoch   4/100, Batch 1500/2575, train loss: 107.2679 (train.py:127, train())
[2021-11-05 07:01:17]    INFO >> Epoch   4/100, Batch 2000/2575, train loss: 103.3126 (train.py:127, train())
[2021-11-05 07:04:09]    INFO >> Epoch   4/100, Batch 2500/2575, train loss: 102.0026 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:05:19]    INFO >> Epoch   4/100, train loss: 101.5083 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:10:20]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 07:10:20]    INFO >> Epoch   4/100, valid loss: 0.0000, valid bleu4: 32.10, best bleu4: 32.10 (train.py:217, <module>())
[2021-11-05 07:10:28]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 07:16:01]    INFO >> Epoch   5/100, Batch 500/2575, train loss: 78.9507 (train.py:127, train())
[2021-11-05 07:18:26]    INFO >> Epoch   5/100, Batch 1000/2575, train loss: 77.3911 (train.py:127, train())
[2021-11-05 07:20:38]    INFO >> Epoch   5/100, Batch 1500/2575, train loss: 76.0912 (train.py:127, train())
[2021-11-05 07:22:57]    INFO >> Epoch   5/100, Batch 2000/2575, train loss: 74.4257 (train.py:127, train())
[2021-11-05 07:26:50]    INFO >> Epoch   5/100, Batch 2500/2575, train loss: 71.7764 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:27:52]    INFO >> Epoch   5/100, train loss: 71.4170 (train.py:136, <module>())
[2021-11-05 07:27:57]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/5.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:30:18]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 07:30:18]    INFO >> Epoch   5/100, valid loss: 0.0000, valid bleu4: 40.47, best bleu4: 40.47 (train.py:217, <module>())
[2021-11-05 07:30:27]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 07:34:09]    INFO >> Epoch   6/100, Batch 500/2575, train loss: 52.5412 (train.py:127, train())
[2021-11-05 07:37:16]    INFO >> Epoch   6/100, Batch 1000/2575, train loss: 52.5083 (train.py:127, train())
[2021-11-05 07:39:30]    INFO >> Epoch   6/100, Batch 1500/2575, train loss: 50.7306 (train.py:127, train())
[2021-11-05 07:41:52]    INFO >> Epoch   6/100, Batch 2000/2575, train loss: 49.5432 (train.py:127, train())
[2021-11-05 07:44:31]    INFO >> Epoch   6/100, Batch 2500/2575, train loss: 49.2960 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:44:52]    INFO >> Epoch   6/100, train loss: 49.2640 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:47:12]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 07:47:12]    INFO >> Epoch   6/100, valid loss: 0.0000, valid bleu4: 47.52, best bleu4: 47.52 (train.py:217, <module>())
[2021-11-05 07:47:20]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 07:49:50]    INFO >> Epoch   7/100, Batch 500/2575, train loss: 37.2244 (train.py:127, train())
[2021-11-05 07:52:09]    INFO >> Epoch   7/100, Batch 1000/2575, train loss: 36.1571 (train.py:127, train())
[2021-11-05 07:54:47]    INFO >> Epoch   7/100, Batch 1500/2575, train loss: 36.2172 (train.py:127, train())
[2021-11-05 07:56:57]    INFO >> Epoch   7/100, Batch 2000/2575, train loss: 35.9881 (train.py:127, train())
[2021-11-05 07:59:07]    INFO >> Epoch   7/100, Batch 2500/2575, train loss: 35.4395 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 07:59:27]    INFO >> Epoch   7/100, train loss: 35.3604 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:01:40]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:01:40]    INFO >> Epoch   7/100, valid loss: 0.0000, valid bleu4: 52.28, best bleu4: 52.28 (train.py:217, <module>())
[2021-11-05 08:01:48]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 08:04:08]    INFO >> Epoch   8/100, Batch 500/2575, train loss: 26.0966 (train.py:127, train())
[2021-11-05 08:06:23]    INFO >> Epoch   8/100, Batch 1000/2575, train loss: 27.0571 (train.py:127, train())
[2021-11-05 08:08:27]    INFO >> Epoch   8/100, Batch 1500/2575, train loss: 27.2745 (train.py:127, train())
[2021-11-05 08:10:36]    INFO >> Epoch   8/100, Batch 2000/2575, train loss: 27.1744 (train.py:127, train())
[2021-11-05 08:12:46]    INFO >> Epoch   8/100, Batch 2500/2575, train loss: 27.5040 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:13:06]    INFO >> Epoch   8/100, train loss: 27.3958 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:15:20]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:15:20]    INFO >> Epoch   8/100, valid loss: 0.0000, valid bleu4: 57.48, best bleu4: 57.48 (train.py:217, <module>())
[2021-11-05 08:15:28]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 08:17:48]    INFO >> Epoch   9/100, Batch 500/2575, train loss: 20.2509 (train.py:127, train())
[2021-11-05 08:20:02]    INFO >> Epoch   9/100, Batch 1000/2575, train loss: 21.8835 (train.py:127, train())
[2021-11-05 08:22:08]    INFO >> Epoch   9/100, Batch 1500/2575, train loss: 22.1232 (train.py:127, train())
[2021-11-05 08:24:17]    INFO >> Epoch   9/100, Batch 2000/2575, train loss: 21.8373 (train.py:127, train())
[2021-11-05 08:26:27]    INFO >> Epoch   9/100, Batch 2500/2575, train loss: 21.9547 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:26:47]    INFO >> Epoch   9/100, train loss: 22.1168 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:29:00]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:29:00]    INFO >> Epoch   9/100, valid loss: 0.0000, valid bleu4: 60.75, best bleu4: 60.75 (train.py:217, <module>())
[2021-11-05 08:29:08]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 08:31:28]    INFO >> Epoch  10/100, Batch 500/2575, train loss: 18.6822 (train.py:127, train())
[2021-11-05 08:33:40]    INFO >> Epoch  10/100, Batch 1000/2575, train loss: 18.4442 (train.py:127, train())
[2021-11-05 08:36:01]    INFO >> Epoch  10/100, Batch 1500/2575, train loss: 18.4672 (train.py:127, train())
[2021-11-05 08:38:19]    INFO >> Epoch  10/100, Batch 2000/2575, train loss: 18.4625 (train.py:127, train())
[2021-11-05 08:40:38]    INFO >> Epoch  10/100, Batch 2500/2575, train loss: 18.3732 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:41:00]    INFO >> Epoch  10/100, train loss: 18.3180 (train.py:136, <module>())
[2021-11-05 08:41:04]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/10.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:43:25]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:43:25]    INFO >> Epoch  10/100, valid loss: 0.0000, valid bleu4: 63.44, best bleu4: 63.44 (train.py:217, <module>())
[2021-11-05 08:43:34]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 08:46:02]    INFO >> Epoch  11/100, Batch 500/2575, train loss: 15.3440 (train.py:127, train())
[2021-11-05 08:48:28]    INFO >> Epoch  11/100, Batch 1000/2575, train loss: 15.1973 (train.py:127, train())
[2021-11-05 08:50:45]    INFO >> Epoch  11/100, Batch 1500/2575, train loss: 14.8015 (train.py:127, train())
[2021-11-05 08:53:02]    INFO >> Epoch  11/100, Batch 2000/2575, train loss: 14.8808 (train.py:127, train())
[2021-11-05 08:55:21]    INFO >> Epoch  11/100, Batch 2500/2575, train loss: 14.9022 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:55:42]    INFO >> Epoch  11/100, train loss: 15.1170 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 08:58:03]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 08:58:03]    INFO >> Epoch  11/100, valid loss: 0.0000, valid bleu4: 64.50, best bleu4: 64.50 (train.py:217, <module>())
[2021-11-05 08:58:11]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 09:00:38]    INFO >> Epoch  12/100, Batch 500/2575, train loss: 11.5765 (train.py:127, train())
[2021-11-05 09:03:04]    INFO >> Epoch  12/100, Batch 1000/2575, train loss: 12.1417 (train.py:127, train())
[2021-11-05 09:05:28]    INFO >> Epoch  12/100, Batch 1500/2575, train loss: 11.8156 (train.py:127, train())
[2021-11-05 09:07:45]    INFO >> Epoch  12/100, Batch 2000/2575, train loss: 12.1455 (train.py:127, train())
[2021-11-05 09:10:03]    INFO >> Epoch  12/100, Batch 2500/2575, train loss: 12.1239 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:10:25]    INFO >> Epoch  12/100, train loss: 12.1554 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:12:49]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:12:49]    INFO >> Epoch  12/100, valid loss: 0.0000, valid bleu4: 67.56, best bleu4: 67.56 (train.py:217, <module>())
[2021-11-05 09:12:58]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 09:15:26]    INFO >> Epoch  13/100, Batch 500/2575, train loss: 9.7879 (train.py:127, train())
[2021-11-05 09:17:55]    INFO >> Epoch  13/100, Batch 1000/2575, train loss: 9.3396 (train.py:127, train())
[2021-11-05 09:20:16]    INFO >> Epoch  13/100, Batch 1500/2575, train loss: 9.8151 (train.py:127, train())
[2021-11-05 09:22:35]    INFO >> Epoch  13/100, Batch 2000/2575, train loss: 9.9161 (train.py:127, train())
[2021-11-05 09:24:51]    INFO >> Epoch  13/100, Batch 2500/2575, train loss: 9.9245 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:25:13]    INFO >> Epoch  13/100, train loss: 9.9028 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:27:33]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:27:33]    INFO >> Epoch  13/100, valid loss: 0.0000, valid bleu4: 68.12, best bleu4: 68.12 (train.py:217, <module>())
[2021-11-05 09:27:42]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 09:30:11]    INFO >> Epoch  14/100, Batch 500/2575, train loss: 7.6273 (train.py:127, train())
[2021-11-05 09:32:44]    INFO >> Epoch  14/100, Batch 1000/2575, train loss: 7.7544 (train.py:127, train())
[2021-11-05 09:34:54]    INFO >> Epoch  14/100, Batch 1500/2575, train loss: 8.0088 (train.py:127, train())
[2021-11-05 09:37:13]    INFO >> Epoch  14/100, Batch 2000/2575, train loss: 7.8933 (train.py:127, train())
[2021-11-05 09:39:31]    INFO >> Epoch  14/100, Batch 2500/2575, train loss: 8.0562 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:39:52]    INFO >> Epoch  14/100, train loss: 8.0995 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:42:13]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:42:13]    INFO >> Epoch  14/100, valid loss: 0.0000, valid bleu4: 69.44, best bleu4: 69.44 (train.py:217, <module>())
[2021-11-05 09:42:22]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 09:44:52]    INFO >> Epoch  15/100, Batch 500/2575, train loss: 7.4334 (train.py:127, train())
[2021-11-05 09:47:25]    INFO >> Epoch  15/100, Batch 1000/2575, train loss: 7.2133 (train.py:127, train())
[2021-11-05 09:49:32]    INFO >> Epoch  15/100, Batch 1500/2575, train loss: 6.8436 (train.py:127, train())
[2021-11-05 09:51:51]    INFO >> Epoch  15/100, Batch 2000/2575, train loss: 6.9272 (train.py:127, train())
[2021-11-05 09:54:10]    INFO >> Epoch  15/100, Batch 2500/2575, train loss: 7.1274 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:54:32]    INFO >> Epoch  15/100, train loss: 7.0696 (train.py:136, <module>())
[2021-11-05 09:54:36]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/15.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 09:56:54]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 09:56:54]    INFO >> Epoch  15/100, valid loss: 0.0000, valid bleu4: 70.14, best bleu4: 70.14 (train.py:217, <module>())
[2021-11-05 09:57:06]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 09:59:35]    INFO >> Epoch  16/100, Batch 500/2575, train loss: 5.5471 (train.py:127, train())
[2021-11-05 10:02:14]    INFO >> Epoch  16/100, Batch 1000/2575, train loss: 5.7898 (train.py:127, train())
[2021-11-05 10:04:23]    INFO >> Epoch  16/100, Batch 1500/2575, train loss: 5.6190 (train.py:127, train())
[2021-11-05 10:06:41]    INFO >> Epoch  16/100, Batch 2000/2575, train loss: 5.7140 (train.py:127, train())
[2021-11-05 10:09:00]    INFO >> Epoch  16/100, Batch 2500/2575, train loss: 5.7879 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:09:22]    INFO >> Epoch  16/100, train loss: 5.8291 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:11:42]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 10:11:42]    INFO >> Epoch  16/100, valid loss: 0.0000, valid bleu4: 71.36, best bleu4: 71.36 (train.py:217, <module>())
[2021-11-05 10:11:51]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 10:14:19]    INFO >> Epoch  17/100, Batch 500/2575, train loss: 5.4593 (train.py:127, train())
[2021-11-05 10:16:59]    INFO >> Epoch  17/100, Batch 1000/2575, train loss: 5.1001 (train.py:127, train())
[2021-11-05 10:19:03]    INFO >> Epoch  17/100, Batch 1500/2575, train loss: 5.0249 (train.py:127, train())
[2021-11-05 10:21:39]    INFO >> Epoch  17/100, Batch 2000/2575, train loss: 5.1259 (train.py:127, train())
[2021-11-05 10:25:11]    INFO >> Epoch  17/100, Batch 2500/2575, train loss: 5.0679 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:25:44]    INFO >> Epoch  17/100, train loss: 5.0843 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:28:50]    INFO >> Epoch  17/100, valid loss: 0.0000, valid bleu4: 70.35, best bleu4: 71.36 (train.py:217, <module>())
[2021-11-05 10:28:59]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 10:32:40]    INFO >> Epoch  18/100, Batch 500/2575, train loss: 4.8904 (train.py:127, train())
[2021-11-05 10:36:33]    INFO >> Epoch  18/100, Batch 1000/2575, train loss: 4.6790 (train.py:127, train())
[2021-11-05 10:40:32]    INFO >> Epoch  18/100, Batch 1500/2575, train loss: 4.6122 (train.py:127, train())
[2021-11-05 10:44:33]    INFO >> Epoch  18/100, Batch 2000/2575, train loss: 4.4675 (train.py:127, train())
[2021-11-05 10:48:36]    INFO >> Epoch  18/100, Batch 2500/2575, train loss: 4.5171 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:49:14]    INFO >> Epoch  18/100, train loss: 4.5038 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 10:52:26]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 10:52:26]    INFO >> Epoch  18/100, valid loss: 0.0000, valid bleu4: 72.27, best bleu4: 72.27 (train.py:217, <module>())
[2021-11-05 10:52:34]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 10:56:16]    INFO >> Epoch  19/100, Batch 500/2575, train loss: 3.4825 (train.py:127, train())
[2021-11-05 11:00:10]    INFO >> Epoch  19/100, Batch 1000/2575, train loss: 3.7816 (train.py:127, train())
[2021-11-05 11:03:37]    INFO >> Epoch  19/100, Batch 1500/2575, train loss: 3.8009 (train.py:127, train())
[2021-11-05 11:07:19]    INFO >> Epoch  19/100, Batch 2000/2575, train loss: 3.8818 (train.py:127, train())
[2021-11-05 11:11:21]    INFO >> Epoch  19/100, Batch 2500/2575, train loss: 3.9591 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:11:58]    INFO >> Epoch  19/100, train loss: 3.9718 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:15:25]    INFO >> Epoch  19/100, valid loss: 0.0000, valid bleu4: 71.90, best bleu4: 72.27 (train.py:217, <module>())
[2021-11-05 11:15:34]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 11:19:47]    INFO >> Epoch  20/100, Batch 500/2575, train loss: 3.5953 (train.py:127, train())
[2021-11-05 11:23:21]    INFO >> Epoch  20/100, Batch 1000/2575, train loss: 3.4885 (train.py:127, train())
[2021-11-05 11:26:54]    INFO >> Epoch  20/100, Batch 1500/2575, train loss: 3.3573 (train.py:127, train())
[2021-11-05 11:30:27]    INFO >> Epoch  20/100, Batch 2000/2575, train loss: 3.5757 (train.py:127, train())
[2021-11-05 11:33:57]    INFO >> Epoch  20/100, Batch 2500/2575, train loss: 3.5828 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:34:30]    INFO >> Epoch  20/100, train loss: 3.5837 (train.py:136, <module>())
[2021-11-05 11:34:34]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/20.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:38:01]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 11:38:01]    INFO >> Epoch  20/100, valid loss: 0.0000, valid bleu4: 72.34, best bleu4: 72.34 (train.py:217, <module>())
[2021-11-05 11:38:10]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 11:42:23]    INFO >> Epoch  21/100, Batch 500/2575, train loss: 3.1508 (train.py:127, train())
[2021-11-05 11:46:45]    INFO >> Epoch  21/100, Batch 1000/2575, train loss: 3.1099 (train.py:127, train())
[2021-11-05 11:50:25]    INFO >> Epoch  21/100, Batch 1500/2575, train loss: 3.0173 (train.py:127, train())
[2021-11-05 11:53:58]    INFO >> Epoch  21/100, Batch 2000/2575, train loss: 3.0457 (train.py:127, train())
[2021-11-05 11:57:29]    INFO >> Epoch  21/100, Batch 2500/2575, train loss: 3.0864 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 11:58:01]    INFO >> Epoch  21/100, train loss: 3.0759 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:01:15]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 12:01:15]    INFO >> Epoch  21/100, valid loss: 0.0000, valid bleu4: 73.73, best bleu4: 73.73 (train.py:217, <module>())
[2021-11-05 12:01:24]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 12:05:07]    INFO >> Epoch  22/100, Batch 500/2575, train loss: 3.0241 (train.py:127, train())
[2021-11-05 12:09:28]    INFO >> Epoch  22/100, Batch 1000/2575, train loss: 2.8499 (train.py:127, train())
[2021-11-05 12:13:24]    INFO >> Epoch  22/100, Batch 1500/2575, train loss: 2.8776 (train.py:127, train())
[2021-11-05 12:17:27]    INFO >> Epoch  22/100, Batch 2000/2575, train loss: 2.9119 (train.py:127, train())
[2021-11-05 12:21:02]    INFO >> Epoch  22/100, Batch 2500/2575, train loss: 2.8071 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:21:34]    INFO >> Epoch  22/100, train loss: 2.8153 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:24:39]    INFO >> Epoch  22/100, valid loss: 0.0000, valid bleu4: 73.28, best bleu4: 73.73 (train.py:217, <module>())
[2021-11-05 12:24:47]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 12:28:30]    INFO >> Epoch  23/100, Batch 500/2575, train loss: 2.9505 (train.py:127, train())
[2021-11-05 12:32:29]    INFO >> Epoch  23/100, Batch 1000/2575, train loss: 2.6486 (train.py:127, train())
[2021-11-05 12:35:47]    INFO >> Epoch  23/100, Batch 1500/2575, train loss: 2.6126 (train.py:127, train())
[2021-11-05 12:39:50]    INFO >> Epoch  23/100, Batch 2000/2575, train loss: 2.5917 (train.py:127, train())
[2021-11-05 12:43:53]    INFO >> Epoch  23/100, Batch 2500/2575, train loss: 2.5908 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:44:31]    INFO >> Epoch  23/100, train loss: 2.5877 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 12:48:04]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 12:48:04]    INFO >> Epoch  23/100, valid loss: 0.0000, valid bleu4: 74.38, best bleu4: 74.38 (train.py:217, <module>())
[2021-11-05 12:48:12]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 12:51:55]    INFO >> Epoch  24/100, Batch 500/2575, train loss: 2.5781 (train.py:127, train())
[2021-11-05 12:55:53]    INFO >> Epoch  24/100, Batch 1000/2575, train loss: 2.4037 (train.py:127, train())
[2021-11-05 12:59:16]    INFO >> Epoch  24/100, Batch 1500/2575, train loss: 2.4040 (train.py:127, train())
[2021-11-05 13:02:46]    INFO >> Epoch  24/100, Batch 2000/2575, train loss: 2.4049 (train.py:127, train())
[2021-11-05 13:06:24]    INFO >> Epoch  24/100, Batch 2500/2575, train loss: 2.4014 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:07:01]    INFO >> Epoch  24/100, train loss: 2.4050 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:10:28]    INFO >> Epoch  24/100, valid loss: 0.0000, valid bleu4: 74.26, best bleu4: 74.38 (train.py:217, <module>())
[2021-11-05 13:10:35]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 13:14:44]    INFO >> Epoch  25/100, Batch 500/2575, train loss: 2.2772 (train.py:127, train())
[2021-11-05 13:18:59]    INFO >> Epoch  25/100, Batch 1000/2575, train loss: 2.1485 (train.py:127, train())
[2021-11-05 13:21:56]    INFO >> Epoch  25/100, Batch 1500/2575, train loss: 2.1948 (train.py:127, train())
[2021-11-05 13:25:18]    INFO >> Epoch  25/100, Batch 2000/2575, train loss: 2.1666 (train.py:127, train())
[2021-11-05 13:28:41]    INFO >> Epoch  25/100, Batch 2500/2575, train loss: 2.1478 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:29:14]    INFO >> Epoch  25/100, train loss: 2.1670 (train.py:136, <module>())
[2021-11-05 13:29:18]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/25.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:32:27]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 13:32:27]    INFO >> Epoch  25/100, valid loss: 0.0000, valid bleu4: 74.48, best bleu4: 74.48 (train.py:217, <module>())
[2021-11-05 13:32:36]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 13:36:22]    INFO >> Epoch  26/100, Batch 500/2575, train loss: 1.8042 (train.py:127, train())
[2021-11-05 13:40:38]    INFO >> Epoch  26/100, Batch 1000/2575, train loss: 2.0292 (train.py:127, train())
[2021-11-05 13:44:22]    INFO >> Epoch  26/100, Batch 1500/2575, train loss: 2.1097 (train.py:127, train())
[2021-11-05 13:48:06]    INFO >> Epoch  26/100, Batch 2000/2575, train loss: 2.0907 (train.py:127, train())
[2021-11-05 13:51:21]    INFO >> Epoch  26/100, Batch 2500/2575, train loss: 2.1134 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:51:52]    INFO >> Epoch  26/100, train loss: 2.1120 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 13:55:02]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 13:55:02]    INFO >> Epoch  26/100, valid loss: 0.0000, valid bleu4: 75.50, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 13:55:11]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 13:58:47]    INFO >> Epoch  27/100, Batch 500/2575, train loss: 2.0837 (train.py:127, train())
[2021-11-05 14:02:29]    INFO >> Epoch  27/100, Batch 1000/2575, train loss: 1.8888 (train.py:127, train())
[2021-11-05 14:06:17]    INFO >> Epoch  27/100, Batch 1500/2575, train loss: 1.8194 (train.py:127, train())
[2021-11-05 14:10:19]    INFO >> Epoch  27/100, Batch 2000/2575, train loss: 1.8333 (train.py:127, train())
[2021-11-05 14:14:22]    INFO >> Epoch  27/100, Batch 2500/2575, train loss: 1.8459 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:14:59]    INFO >> Epoch  27/100, train loss: 1.8690 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:18:11]    INFO >> Epoch  27/100, valid loss: 0.0000, valid bleu4: 74.54, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 14:18:20]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 14:22:02]    INFO >> Epoch  28/100, Batch 500/2575, train loss: 1.5761 (train.py:127, train())
[2021-11-05 14:25:58]    INFO >> Epoch  28/100, Batch 1000/2575, train loss: 1.6452 (train.py:127, train())
[2021-11-05 14:29:27]    INFO >> Epoch  28/100, Batch 1500/2575, train loss: 1.7384 (train.py:127, train())
[2021-11-05 14:32:57]    INFO >> Epoch  28/100, Batch 2000/2575, train loss: 1.7543 (train.py:127, train())
[2021-11-05 14:37:00]    INFO >> Epoch  28/100, Batch 2500/2575, train loss: 1.7293 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:37:38]    INFO >> Epoch  28/100, train loss: 1.7196 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 14:41:05]    INFO >> Epoch  28/100, valid loss: 0.0000, valid bleu4: 74.81, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 14:41:13]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 14:45:25]    INFO >> Epoch  29/100, Batch 500/2575, train loss: 1.6471 (train.py:127, train())
[2021-11-05 14:49:21]    INFO >> Epoch  29/100, Batch 1000/2575, train loss: 1.5871 (train.py:127, train())
[2021-11-05 14:52:49]    INFO >> Epoch  29/100, Batch 1500/2575, train loss: 1.6405 (train.py:127, train())
[2021-11-05 14:56:20]    INFO >> Epoch  29/100, Batch 2000/2575, train loss: 1.6118 (train.py:127, train())
[2021-11-05 14:59:53]    INFO >> Epoch  29/100, Batch 2500/2575, train loss: 1.6171 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:00:26]    INFO >> Epoch  29/100, train loss: 1.6189 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:03:33]    INFO >> Epoch  29/100, valid loss: 0.0000, valid bleu4: 75.16, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 15:03:41]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 15:07:52]    INFO >> Epoch  30/100, Batch 500/2575, train loss: 1.6786 (train.py:127, train())
[2021-11-05 15:12:18]    INFO >> Epoch  30/100, Batch 1000/2575, train loss: 1.5497 (train.py:127, train())
[2021-11-05 15:16:17]    INFO >> Epoch  30/100, Batch 1500/2575, train loss: 1.5525 (train.py:127, train())
[2021-11-05 15:19:39]    INFO >> Epoch  30/100, Batch 2000/2575, train loss: 1.5370 (train.py:127, train())
[2021-11-05 15:23:12]    INFO >> Epoch  30/100, Batch 2500/2575, train loss: 1.5286 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:23:45]    INFO >> Epoch  30/100, train loss: 1.5249 (train.py:136, <module>())
[2021-11-05 15:23:49]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/30.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:26:54]    INFO >> Epoch  30/100, valid loss: 0.0000, valid bleu4: 74.44, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 15:27:02]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 15:30:43]    INFO >> Epoch  31/100, Batch 500/2575, train loss: 1.7574 (train.py:127, train())
[2021-11-05 15:34:48]    INFO >> Epoch  31/100, Batch 1000/2575, train loss: 1.6414 (train.py:127, train())
[2021-11-05 15:38:47]    INFO >> Epoch  31/100, Batch 1500/2575, train loss: 1.5254 (train.py:127, train())
[2021-11-05 15:42:48]    INFO >> Epoch  31/100, Batch 2000/2575, train loss: 1.4753 (train.py:127, train())
[2021-11-05 15:46:43]    INFO >> Epoch  31/100, Batch 2500/2575, train loss: 1.4726 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:47:07]    INFO >> Epoch  31/100, train loss: 1.4608 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 15:50:13]    INFO >> Epoch  31/100, valid loss: 0.0000, valid bleu4: 74.59, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 15:50:21]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 15:54:04]    INFO >> Epoch  32/100, Batch 500/2575, train loss: 1.2423 (train.py:127, train())
[2021-11-05 15:57:57]    INFO >> Epoch  32/100, Batch 1000/2575, train loss: 1.2954 (train.py:127, train())
[2021-11-05 16:01:26]    INFO >> Epoch  32/100, Batch 1500/2575, train loss: 1.2893 (train.py:127, train())
[2021-11-05 16:05:16]    INFO >> Epoch  32/100, Batch 2000/2575, train loss: 1.3228 (train.py:127, train())
[2021-11-05 16:09:17]    INFO >> Epoch  32/100, Batch 2500/2575, train loss: 1.3575 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:09:55]    INFO >> Epoch  32/100, train loss: 1.3597 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:13:22]    INFO >> Epoch  32/100, valid loss: 0.0000, valid bleu4: 74.13, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 16:13:30]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 16:17:22]    INFO >> Epoch  33/100, Batch 500/2575, train loss: 1.3654 (train.py:127, train())
[2021-11-05 16:21:15]    INFO >> Epoch  33/100, Batch 1000/2575, train loss: 1.4107 (train.py:127, train())
[2021-11-05 16:24:41]    INFO >> Epoch  33/100, Batch 1500/2575, train loss: 1.3376 (train.py:127, train())
[2021-11-05 16:28:13]    INFO >> Epoch  33/100, Batch 2000/2575, train loss: 1.2976 (train.py:127, train())
[2021-11-05 16:31:44]    INFO >> Epoch  33/100, Batch 2500/2575, train loss: 1.2692 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:32:14]    INFO >> Epoch  33/100, train loss: 1.2702 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:35:41]    INFO >> Epoch  33/100, valid loss: 0.0000, valid bleu4: 74.44, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 16:35:50]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 16:40:03]    INFO >> Epoch  34/100, Batch 500/2575, train loss: 1.3230 (train.py:127, train())
[2021-11-05 16:44:30]    INFO >> Epoch  34/100, Batch 1000/2575, train loss: 1.2454 (train.py:127, train())
[2021-11-05 16:47:57]    INFO >> Epoch  34/100, Batch 1500/2575, train loss: 1.2216 (train.py:127, train())
[2021-11-05 16:51:29]    INFO >> Epoch  34/100, Batch 2000/2575, train loss: 1.1737 (train.py:127, train())
[2021-11-05 16:55:02]    INFO >> Epoch  34/100, Batch 2500/2575, train loss: 1.1786 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:55:34]    INFO >> Epoch  34/100, train loss: 1.1748 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 16:58:39]    INFO >> Epoch  34/100, valid loss: 0.0000, valid bleu4: 75.43, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 16:58:47]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 17:02:29]    INFO >> Epoch  35/100, Batch 500/2575, train loss: 1.1611 (train.py:127, train())
[2021-11-05 17:06:55]    INFO >> Epoch  35/100, Batch 1000/2575, train loss: 1.2213 (train.py:127, train())
[2021-11-05 17:10:50]    INFO >> Epoch  35/100, Batch 1500/2575, train loss: 1.1883 (train.py:127, train())
[2021-11-05 17:14:54]    INFO >> Epoch  35/100, Batch 2000/2575, train loss: 1.2126 (train.py:127, train())
[2021-11-05 17:18:23]    INFO >> Epoch  35/100, Batch 2500/2575, train loss: 1.1835 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:18:56]    INFO >> Epoch  35/100, train loss: 1.1856 (train.py:136, <module>())
[2021-11-05 17:19:01]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/35.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:22:05]    INFO >> Epoch  35/100, valid loss: 0.0000, valid bleu4: 74.14, best bleu4: 75.50 (train.py:217, <module>())
[2021-11-05 17:22:13]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 17:25:56]    INFO >> Epoch  36/100, Batch 500/2575, train loss: 1.0148 (train.py:127, train())
[2021-11-05 17:29:53]    INFO >> Epoch  36/100, Batch 1000/2575, train loss: 0.9893 (train.py:127, train())
[2021-11-05 17:33:20]    INFO >> Epoch  36/100, Batch 1500/2575, train loss: 0.9940 (train.py:127, train())
[2021-11-05 17:37:23]    INFO >> Epoch  36/100, Batch 2000/2575, train loss: 1.0563 (train.py:127, train())
[2021-11-05 17:41:26]    INFO >> Epoch  36/100, Batch 2500/2575, train loss: 1.0599 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:42:04]    INFO >> Epoch  36/100, train loss: 1.0585 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 17:45:37]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 17:45:37]    INFO >> Epoch  36/100, valid loss: 0.0000, valid bleu4: 76.15, best bleu4: 76.15 (train.py:217, <module>())
[2021-11-05 17:45:49]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 17:49:21]    INFO >> Epoch  37/100, Batch 500/2575, train loss: 0.9893 (train.py:127, train())
[2021-11-05 17:53:14]    INFO >> Epoch  37/100, Batch 1000/2575, train loss: 0.9451 (train.py:127, train())
[2021-11-05 17:56:43]    INFO >> Epoch  37/100, Batch 1500/2575, train loss: 0.9702 (train.py:127, train())
[2021-11-05 18:00:16]    INFO >> Epoch  37/100, Batch 2000/2575, train loss: 0.9924 (train.py:127, train())
[2021-11-05 18:04:01]    INFO >> Epoch  37/100, Batch 2500/2575, train loss: 0.9986 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:04:38]    INFO >> Epoch  37/100, train loss: 1.0081 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:08:04]    INFO >> Epoch  37/100, valid loss: 0.0000, valid bleu4: 74.61, best bleu4: 76.15 (train.py:217, <module>())
[2021-11-05 18:08:15]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 18:12:28]    INFO >> Epoch  38/100, Batch 500/2575, train loss: 0.9889 (train.py:127, train())
[2021-11-05 18:16:44]    INFO >> Epoch  38/100, Batch 1000/2575, train loss: 0.9839 (train.py:127, train())
[2021-11-05 18:19:46]    INFO >> Epoch  38/100, Batch 1500/2575, train loss: 0.9869 (train.py:127, train())
[2021-11-05 18:23:18]    INFO >> Epoch  38/100, Batch 2000/2575, train loss: 0.9701 (train.py:127, train())
[2021-11-05 18:26:51]    INFO >> Epoch  38/100, Batch 2500/2575, train loss: 0.9686 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:27:24]    INFO >> Epoch  38/100, train loss: 0.9757 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:30:29]    INFO >> Epoch  38/100, valid loss: 0.0000, valid bleu4: 75.52, best bleu4: 76.15 (train.py:217, <module>())
[2021-11-05 18:30:38]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 18:34:32]    INFO >> Epoch  39/100, Batch 500/2575, train loss: 0.8973 (train.py:127, train())
[2021-11-05 18:39:00]    INFO >> Epoch  39/100, Batch 1000/2575, train loss: 0.8769 (train.py:127, train())
[2021-11-05 18:42:58]    INFO >> Epoch  39/100, Batch 1500/2575, train loss: 0.9457 (train.py:127, train())
[2021-11-05 18:46:46]    INFO >> Epoch  39/100, Batch 2000/2575, train loss: 0.9722 (train.py:127, train())
[2021-11-05 18:50:18]    INFO >> Epoch  39/100, Batch 2500/2575, train loss: 0.9577 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:50:51]    INFO >> Epoch  39/100, train loss: 0.9556 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 18:53:57]    INFO >> Epoch  39/100, valid loss: 0.0000, valid bleu4: 76.00, best bleu4: 76.15 (train.py:217, <module>())
[2021-11-05 18:54:05]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 18:57:46]    INFO >> Epoch  40/100, Batch 500/2575, train loss: 0.9986 (train.py:127, train())
[2021-11-05 19:01:40]    INFO >> Epoch  40/100, Batch 1000/2575, train loss: 0.9719 (train.py:127, train())
[2021-11-05 19:05:24]    INFO >> Epoch  40/100, Batch 1500/2575, train loss: 0.8992 (train.py:127, train())
[2021-11-05 19:09:25]    INFO >> Epoch  40/100, Batch 2000/2575, train loss: 0.9047 (train.py:127, train())
[2021-11-05 19:13:28]    INFO >> Epoch  40/100, Batch 2500/2575, train loss: 0.9083 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:14:06]    INFO >> Epoch  40/100, train loss: 0.9054 (train.py:136, <module>())
[2021-11-05 19:14:11]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/40.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:17:27]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 19:17:27]    INFO >> Epoch  40/100, valid loss: 0.0000, valid bleu4: 76.58, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 19:17:35]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 19:21:09]    INFO >> Epoch  41/100, Batch 500/2575, train loss: 0.7886 (train.py:127, train())
[2021-11-05 19:24:57]    INFO >> Epoch  41/100, Batch 1000/2575, train loss: 0.8640 (train.py:127, train())
[2021-11-05 19:28:09]    INFO >> Epoch  41/100, Batch 1500/2575, train loss: 0.8267 (train.py:127, train())
[2021-11-05 19:31:32]    INFO >> Epoch  41/100, Batch 2000/2575, train loss: 0.8213 (train.py:127, train())
[2021-11-05 19:35:24]    INFO >> Epoch  41/100, Batch 2500/2575, train loss: 0.8278 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:36:00]    INFO >> Epoch  41/100, train loss: 0.8251 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:39:19]    INFO >> Epoch  41/100, valid loss: 0.0000, valid bleu4: 76.17, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 19:39:27]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 19:43:29]    INFO >> Epoch  42/100, Batch 500/2575, train loss: 0.8778 (train.py:127, train())
[2021-11-05 19:47:11]    INFO >> Epoch  42/100, Batch 1000/2575, train loss: 0.8157 (train.py:127, train())
[2021-11-05 19:50:28]    INFO >> Epoch  42/100, Batch 1500/2575, train loss: 0.8233 (train.py:127, train())
[2021-11-05 19:53:50]    INFO >> Epoch  42/100, Batch 2000/2575, train loss: 0.8396 (train.py:127, train())
[2021-11-05 19:57:12]    INFO >> Epoch  42/100, Batch 2500/2575, train loss: 0.8139 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 19:57:43]    INFO >> Epoch  42/100, train loss: 0.8150 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:00:43]    INFO >> Epoch  42/100, valid loss: 0.0000, valid bleu4: 75.55, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 20:00:50]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 20:04:52]    INFO >> Epoch  43/100, Batch 500/2575, train loss: 0.9843 (train.py:127, train())
[2021-11-05 20:09:08]    INFO >> Epoch  43/100, Batch 1000/2575, train loss: 0.8508 (train.py:127, train())
[2021-11-05 20:12:55]    INFO >> Epoch  43/100, Batch 1500/2575, train loss: 0.8247 (train.py:127, train())
[2021-11-05 20:16:12]    INFO >> Epoch  43/100, Batch 2000/2575, train loss: 0.8093 (train.py:127, train())
[2021-11-05 20:19:34]    INFO >> Epoch  43/100, Batch 2500/2575, train loss: 0.7989 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:20:06]    INFO >> Epoch  43/100, train loss: 0.7931 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:23:03]    INFO >> Epoch  43/100, valid loss: 0.0000, valid bleu4: 75.11, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 20:23:11]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 20:26:43]    INFO >> Epoch  44/100, Batch 500/2575, train loss: 0.6487 (train.py:127, train())
[2021-11-05 20:30:44]    INFO >> Epoch  44/100, Batch 1000/2575, train loss: 0.7373 (train.py:127, train())
[2021-11-05 20:34:30]    INFO >> Epoch  44/100, Batch 1500/2575, train loss: 0.7334 (train.py:127, train())
[2021-11-05 20:38:22]    INFO >> Epoch  44/100, Batch 2000/2575, train loss: 0.7307 (train.py:127, train())
[2021-11-05 20:42:01]    INFO >> Epoch  44/100, Batch 2500/2575, train loss: 0.7542 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:42:32]    INFO >> Epoch  44/100, train loss: 0.7595 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 20:45:29]    INFO >> Epoch  44/100, valid loss: 0.0000, valid bleu4: 75.79, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 20:45:37]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 20:49:09]    INFO >> Epoch  45/100, Batch 500/2575, train loss: 0.8909 (train.py:127, train())
[2021-11-05 20:52:53]    INFO >> Epoch  45/100, Batch 1000/2575, train loss: 0.7674 (train.py:127, train())
[2021-11-05 20:56:08]    INFO >> Epoch  45/100, Batch 1500/2575, train loss: 0.7306 (train.py:127, train())
[2021-11-05 20:59:52]    INFO >> Epoch  45/100, Batch 2000/2575, train loss: 0.7246 (train.py:127, train())
[2021-11-05 21:03:44]    INFO >> Epoch  45/100, Batch 2500/2575, train loss: 0.7307 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:04:20]    INFO >> Epoch  45/100, train loss: 0.7260 (train.py:136, <module>())
[2021-11-05 21:04:25]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/45.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:07:44]    INFO >> Epoch  45/100, valid loss: 0.0000, valid bleu4: 76.24, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 21:07:52]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 21:11:27]    INFO >> Epoch  46/100, Batch 500/2575, train loss: 0.7204 (train.py:127, train())
[2021-11-05 21:15:12]    INFO >> Epoch  46/100, Batch 1000/2575, train loss: 0.6806 (train.py:127, train())
[2021-11-05 21:18:28]    INFO >> Epoch  46/100, Batch 1500/2575, train loss: 0.7049 (train.py:127, train())
[2021-11-05 21:21:51]    INFO >> Epoch  46/100, Batch 2000/2575, train loss: 0.7002 (train.py:127, train())
[2021-11-05 21:25:10]    INFO >> Epoch  46/100, Batch 2500/2575, train loss: 0.6988 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:25:46]    INFO >> Epoch  46/100, train loss: 0.6984 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:29:05]    INFO >> Epoch  46/100, valid loss: 0.0000, valid bleu4: 76.30, best bleu4: 76.58 (train.py:217, <module>())
[2021-11-05 21:29:13]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 21:33:16]    INFO >> Epoch  47/100, Batch 500/2575, train loss: 0.7703 (train.py:127, train())
[2021-11-05 21:37:32]    INFO >> Epoch  47/100, Batch 1000/2575, train loss: 0.7504 (train.py:127, train())
[2021-11-05 21:40:47]    INFO >> Epoch  47/100, Batch 1500/2575, train loss: 0.7066 (train.py:127, train())
[2021-11-05 21:44:09]    INFO >> Epoch  47/100, Batch 2000/2575, train loss: 0.6765 (train.py:127, train())
[2021-11-05 21:47:31]    INFO >> Epoch  47/100, Batch 2500/2575, train loss: 0.6705 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:48:03]    INFO >> Epoch  47/100, train loss: 0.6724 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 21:51:08]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/best_checkpoint.pt (train.py:215, <module>())
[2021-11-05 21:51:08]    INFO >> Epoch  47/100, valid loss: 0.0000, valid bleu4: 76.59, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 21:51:16]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 21:54:53]    INFO >> Epoch  48/100, Batch 500/2575, train loss: 0.5279 (train.py:127, train())
[2021-11-05 21:59:08]    INFO >> Epoch  48/100, Batch 1000/2575, train loss: 0.5394 (train.py:127, train())
[2021-11-05 22:01:56]    INFO >> Epoch  48/100, Batch 1500/2575, train loss: 0.5537 (train.py:127, train())
[2021-11-05 22:04:44]    INFO >> Epoch  48/100, Batch 2000/2575, train loss: 0.5530 (train.py:127, train())
[2021-11-05 22:06:45]    INFO >> Epoch  48/100, Batch 2500/2575, train loss: 0.5776 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:07:07]    INFO >> Epoch  48/100, train loss: 0.5727 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:09:19]    INFO >> Epoch  48/100, valid loss: 0.0000, valid bleu4: 76.03, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 22:09:27]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 22:11:59]    INFO >> Epoch  49/100, Batch 500/2575, train loss: 0.6183 (train.py:127, train())
[2021-11-05 22:14:20]    INFO >> Epoch  49/100, Batch 1000/2575, train loss: 0.5787 (train.py:127, train())
[2021-11-05 22:16:46]    INFO >> Epoch  49/100, Batch 1500/2575, train loss: 0.5611 (train.py:127, train())
[2021-11-05 22:19:33]    INFO >> Epoch  49/100, Batch 2000/2575, train loss: 0.5677 (train.py:127, train())
[2021-11-05 22:22:21]    INFO >> Epoch  49/100, Batch 2500/2575, train loss: 0.5731 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:22:48]    INFO >> Epoch  49/100, train loss: 0.5905 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:25:20]    INFO >> Epoch  49/100, valid loss: 0.0000, valid bleu4: 74.92, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 22:25:30]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 22:28:02]    INFO >> Epoch  50/100, Batch 500/2575, train loss: 0.8681 (train.py:127, train())
[2021-11-05 22:30:24]    INFO >> Epoch  50/100, Batch 1000/2575, train loss: 0.7028 (train.py:127, train())
[2021-11-05 22:32:45]    INFO >> Epoch  50/100, Batch 1500/2575, train loss: 0.6473 (train.py:127, train())
[2021-11-05 22:35:04]    INFO >> Epoch  50/100, Batch 2000/2575, train loss: 0.6131 (train.py:127, train())
[2021-11-05 22:37:48]    INFO >> Epoch  50/100, Batch 2500/2575, train loss: 0.6143 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:38:14]    INFO >> Epoch  50/100, train loss: 0.6060 (train.py:136, <module>())
[2021-11-05 22:38:19]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/50.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:40:52]    INFO >> Epoch  50/100, valid loss: 0.0000, valid bleu4: 76.58, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 22:41:00]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 22:43:58]    INFO >> Epoch  51/100, Batch 500/2575, train loss: 0.5004 (train.py:127, train())
[2021-11-05 22:46:12]    INFO >> Epoch  51/100, Batch 1000/2575, train loss: 0.4896 (train.py:127, train())
[2021-11-05 22:48:33]    INFO >> Epoch  51/100, Batch 1500/2575, train loss: 0.4895 (train.py:127, train())
[2021-11-05 22:50:54]    INFO >> Epoch  51/100, Batch 2000/2575, train loss: 0.4989 (train.py:127, train())
[2021-11-05 22:53:16]    INFO >> Epoch  51/100, Batch 2500/2575, train loss: 0.5450 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:53:38]    INFO >> Epoch  51/100, train loss: 0.5503 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 22:55:54]    INFO >> Epoch  51/100, valid loss: 0.0000, valid bleu4: 76.17, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 22:56:01]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 22:58:59]    INFO >> Epoch  52/100, Batch 500/2575, train loss: 0.5841 (train.py:127, train())
[2021-11-05 23:01:47]    INFO >> Epoch  52/100, Batch 1000/2575, train loss: 0.5716 (train.py:127, train())
[2021-11-05 23:04:27]    INFO >> Epoch  52/100, Batch 1500/2575, train loss: 0.5540 (train.py:127, train())
[2021-11-05 23:06:30]    INFO >> Epoch  52/100, Batch 2000/2575, train loss: 0.5949 (train.py:127, train())
[2021-11-05 23:08:52]    INFO >> Epoch  52/100, Batch 2500/2575, train loss: 0.5974 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:09:14]    INFO >> Epoch  52/100, train loss: 0.5931 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:11:26]    INFO >> Epoch  52/100, valid loss: 0.0000, valid bleu4: 76.26, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 23:11:33]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 23:14:05]    INFO >> Epoch  53/100, Batch 500/2575, train loss: 0.4984 (train.py:127, train())
[2021-11-05 23:16:43]    INFO >> Epoch  53/100, Batch 1000/2575, train loss: 0.4611 (train.py:127, train())
[2021-11-05 23:19:31]    INFO >> Epoch  53/100, Batch 1500/2575, train loss: 0.4511 (train.py:127, train())
[2021-11-05 23:22:19]    INFO >> Epoch  53/100, Batch 2000/2575, train loss: 0.4581 (train.py:127, train())
[2021-11-05 23:24:40]    INFO >> Epoch  53/100, Batch 2500/2575, train loss: 0.4653 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:25:03]    INFO >> Epoch  53/100, train loss: 0.4663 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:27:15]    INFO >> Epoch  53/100, valid loss: 0.0000, valid bleu4: 76.10, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 23:27:22]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 23:29:53]    INFO >> Epoch  54/100, Batch 500/2575, train loss: 0.4093 (train.py:127, train())
[2021-11-05 23:32:14]    INFO >> Epoch  54/100, Batch 1000/2575, train loss: 0.4202 (train.py:127, train())
[2021-11-05 23:34:34]    INFO >> Epoch  54/100, Batch 1500/2575, train loss: 0.4388 (train.py:127, train())
[2021-11-05 23:37:22]    INFO >> Epoch  54/100, Batch 2000/2575, train loss: 0.4498 (train.py:127, train())
[2021-11-05 23:40:10]    INFO >> Epoch  54/100, Batch 2500/2575, train loss: 0.4590 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:40:36]    INFO >> Epoch  54/100, train loss: 0.4600 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:43:10]    INFO >> Epoch  54/100, valid loss: 0.0000, valid bleu4: 76.22, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 23:43:18]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-05 23:45:36]    INFO >> Epoch  55/100, Batch 500/2575, train loss: 0.3839 (train.py:127, train())
[2021-11-05 23:47:57]    INFO >> Epoch  55/100, Batch 1000/2575, train loss: 0.4332 (train.py:127, train())
[2021-11-05 23:50:17]    INFO >> Epoch  55/100, Batch 1500/2575, train loss: 0.4517 (train.py:127, train())
[2021-11-05 23:52:38]    INFO >> Epoch  55/100, Batch 2000/2575, train loss: 0.4576 (train.py:127, train())
[2021-11-05 23:55:04]    INFO >> Epoch  55/100, Batch 2500/2575, train loss: 0.4643 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:55:30]    INFO >> Epoch  55/100, train loss: 0.4642 (train.py:136, <module>())
[2021-11-05 23:55:34]    INFO >> save /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/55.pt (train.py:207, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-05 23:58:08]    INFO >> Epoch  55/100, valid loss: 0.0000, valid bleu4: 76.09, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-05 23:58:16]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 00:01:14]    INFO >> Epoch  56/100, Batch 500/2575, train loss: 0.4275 (train.py:127, train())
[2021-11-06 00:03:39]    INFO >> Epoch  56/100, Batch 1000/2575, train loss: 0.3866 (train.py:127, train())
[2021-11-06 00:06:01]    INFO >> Epoch  56/100, Batch 1500/2575, train loss: 0.3886 (train.py:127, train())
[2021-11-06 00:08:22]    INFO >> Epoch  56/100, Batch 2000/2575, train loss: 0.4199 (train.py:127, train())
[2021-11-06 00:10:44]    INFO >> Epoch  56/100, Batch 2500/2575, train loss: 0.4158 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:11:06]    INFO >> Epoch  56/100, train loss: 0.4181 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:13:18]    INFO >> Epoch  56/100, valid loss: 0.0000, valid bleu4: 75.89, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-06 00:13:26]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 00:16:24]    INFO >> Epoch  57/100, Batch 500/2575, train loss: 0.4725 (train.py:127, train())
[2021-11-06 00:19:12]    INFO >> Epoch  57/100, Batch 1000/2575, train loss: 0.4516 (train.py:127, train())
[2021-11-06 00:22:00]    INFO >> Epoch  57/100, Batch 1500/2575, train loss: 0.4387 (train.py:127, train())
[2021-11-06 00:24:15]    INFO >> Epoch  57/100, Batch 2000/2575, train loss: 0.4324 (train.py:127, train())
[2021-11-06 00:26:37]    INFO >> Epoch  57/100, Batch 2500/2575, train loss: 0.4404 (train.py:127, train())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:26:59]    INFO >> Epoch  57/100, train loss: 0.4398 (train.py:136, <module>())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-06 00:29:11]    INFO >> Epoch  57/100, valid loss: 0.0000, valid bleu4: 75.75, best bleu4: 76.59 (train.py:217, <module>())
[2021-11-06 00:29:19]    INFO >> update /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/graphcodebert/data-mmap/java-csharp/last_checkpoint.pt (train.py:222, <module>())
[2021-11-06 00:29:19]    INFO >> early stop because of no improvement in 10 epochs (train.py:224, <module>())
