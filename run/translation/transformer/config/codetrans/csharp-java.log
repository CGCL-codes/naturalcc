nohup: ignoring input
Using backend: pytorch
[2021-11-13 06:50:43]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/translation/transformer/config/codetrans/csharp-java.yml (train.py:291, cli_main())
[2021-11-13 06:50:44]    INFO >> {'criterion': 'label_smoothed_cross_entropy', 'optimizer': 'fairseq_adam', 'lr_scheduler': 'polynomial_decay', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 1, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'translation', 'seed': 1234, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'bf16': 0, 'memory_efficient_bf16': 0, 'server_ip': '', 'server_port': '', 'amp': 1, 'amp_batch_retries': 2, 'amp_init_scale': '2 ** 7', 'amp_scale_window': None}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 1, 'max_tokens': None, 'max_sentences': 4, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 16, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'distributed_training': {'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'pipeline_model_parallel': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap', 'source_lang': 'csharp', 'target_lang': 'java', 'load_alignments': 0, 'left_pad_source': 0, 'left_pad_target': 0, 'max_source_positions': 320, 'max_target_positions': 256, 'upsample_primary': 1, 'truncate_source': 1, 'truncate_target': 1, 'append_eos_to_target': 1, 'eval_bleu': 1, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': True, 'eval_bleu_remove_bpe': 'sentencepiece', 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_with_sacrebleu': 1}, 'model': {'arch': 'fairseq_transformer', 'offset_positions_by_padding': 1, 'pooler_dropout': 0.1, 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.1, 'relu_dropout': 0.1, 'encoder_positional_embeddings': 0, 'encoder_learned_pos': 1, 'encoder_max_relative_len': 0, 'encoder_embed_path': 0, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_layers': 6, 'encoder_attention_heads': 12, 'encoder_normalize_before': 0, 'decoder_embed_path': '', 'decoder_positional_embeddings': 0, 'decoder_learned_pos': 1, 'decoder_max_relative_len': 0, 'decoder_embed_dim': 768, 'decoder_output_dim': 768, 'decoder_input_dim': 768, 'decoder_ffn_embed_dim': 3072, 'decoder_layers': 6, 'decoder_attention_heads': 12, 'decoder_normalize_before': 0, 'no_decoder_final_norm': 0, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.1, 'adaptive_softmax_factor': 0.0, 'share_decoder_input_output_embed': 1, 'decoder_out_embed_bias': 1, 'share_all_embeddings': 1, 'adaptive_input': 0, 'adaptive_input_factor': 0.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': 0, 'tie_adaptive_proj': 0, 'no_cross_attention': 0, 'cross_self_attention': 0, 'layer_wise_attention': 0, 'encoder_layerdrop': 0.0, 'decoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'decoder_layers_to_keep': None, 'layernorm_embedding': 1, 'no_scale_embedding': 0, 'no_token_positional_embeddings': 0, 'encoder_dropout_in': 0.1, 'encoder_dropout_out': 0.1, 'decoder_dropout_in': 0.1, 'decoder_dropout_out': 0.1, 'max_source_positions': 1024, 'max_target_positions': 1024, 'multihead_attention_version': 'ncc', 'encoder_position_encoding_version': 'ncc_learned', 'decoder_position_encoding_version': 'ncc_learned'}, 'optimization': {'max_epoch': 200, 'max_update': 0, 'clip_norm': 25.0, 'update_freq': [1], 'lrs': [5e-05], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 1500, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': 0, 'label_smoothing': 0.1, 'adam': {'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': 0}}, 'checkpoint': {'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': 1, 'patience': 20, 'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints', 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt', 'remove_bpe': 'sentencepiece', 'quiet': 1, 'results_path': None, 'model_overrides': '{}', 'topk': 5, 'max_sentences': 2, 'beam': 5, 'nbest': 1, 'max_len_a': 0, 'max_len_b': 500, 'min_len': 1, 'match_source_len': 0, 'no_early_stop': 1, 'unnormalized': 0, 'no_beamable_mm': 0, 'lenpen': 1, 'unkpen': 0, 'replace_unk': None, 'sacrebleu': 0, 'score_reference': 0, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': 0, 'sampling_topk': -1, 'sampling_topp': -1, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 0, 'print_step': 0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': 0, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': 0, 'retain_iter_history': 0, 'decoding_format': None, 'nltk_bleu': 1, 'rouge': 1}} (train.py:293, cli_main())
Using backend: pytorch
[2021-11-13 06:50:46]    INFO >> distributed init (rank 0): tcp://localhost:15717 (distributed_utils.py:85, distributed_init())
Using backend: pytorch
[2021-11-13 06:50:46]    INFO >> distributed init (rank 1): tcp://localhost:15717 (distributed_utils.py:85, distributed_init())
[2021-11-13 06:50:46]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
Using backend: pytorch
[2021-11-13 06:50:46]    INFO >> distributed init (rank 2): tcp://localhost:15717 (distributed_utils.py:85, distributed_init())
[2021-11-13 06:50:46]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
Using backend: pytorch
[2021-11-13 06:50:46]    INFO >> distributed init (rank 3): tcp://localhost:15717 (distributed_utils.py:85, distributed_init())
[2021-11-13 06:50:46]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-11-13 06:50:46]    INFO >> Added key: store_based_barrier_key:1 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-11-13 06:50:46]    INFO >> initialized host node12 as rank 0 (distributed_utils.py:94, distributed_init())
[2021-11-13 06:50:46]    INFO >> initialized host node12 as rank 3 (distributed_utils.py:94, distributed_init())
[2021-11-13 06:50:46]    INFO >> initialized host node12 as rank 1 (distributed_utils.py:94, distributed_init())
[2021-11-13 06:50:46]    INFO >> initialized host node12 as rank 2 (distributed_utils.py:94, distributed_init())
[2021-11-13 06:50:55]    INFO >> [csharp] dictionary: 50006 types (translation.py:132, setup_task())
[2021-11-13 06:50:55]    INFO >> [java] dictionary: 50006 types (translation.py:133, setup_task())
[2021-11-13 06:50:55]    INFO >> truncate csharp/valid.code_tokens to 320 (translation.py:71, load_langpair_dataset())
[2021-11-13 06:50:56]    INFO >> truncate java/valid.code_tokens to 256 (translation.py:86, load_langpair_dataset())
[2021-11-13 06:50:59]    INFO >> Added key: store_based_barrier_key:2 to store for rank: 1 (distributed_c10d.py:187, _store_based_barrier())
[2021-11-13 06:50:59]    INFO >> FairseqTransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(50006, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50006, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50006, bias=False)
  )
) (train.py:213, single_main())
[2021-11-13 06:50:59]    INFO >> model fairseq_transformer, criterion LabelSmoothedCrossEntropyCriterion (train.py:214, single_main())
[2021-11-13 06:50:59]    INFO >> num. model params: 139221504 (num. trained: 139221504) (train.py:215, single_main())
[2021-11-13 06:50:59]    INFO >> Added key: store_based_barrier_key:2 to store for rank: 2 (distributed_c10d.py:187, _store_based_barrier())
[2021-11-13 06:50:59]    INFO >> Added key: store_based_barrier_key:2 to store for rank: 0 (distributed_c10d.py:187, _store_based_barrier())
[2021-11-13 06:50:59]    INFO >> Added key: store_based_barrier_key:2 to store for rank: 3 (distributed_c10d.py:187, _store_based_barrier())
[2021-11-13 06:50:59]    INFO >> ***********************CUDA enviroments for all 4 workers*********************** (utils.py:542, pretty_print_cuda_env_list())
[2021-11-13 06:50:59]    INFO >> rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-SXM2-32GB                     (utils.py:544, pretty_print_cuda_env_list())
[2021-11-13 06:50:59]    INFO >> rank   1: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-SXM2-32GB                     (utils.py:544, pretty_print_cuda_env_list())
[2021-11-13 06:50:59]    INFO >> rank   2: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-SXM2-32GB                     (utils.py:544, pretty_print_cuda_env_list())
[2021-11-13 06:50:59]    INFO >> rank   3: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-SXM2-32GB                     (utils.py:544, pretty_print_cuda_env_list())
[2021-11-13 06:50:59]    INFO >> ***********************CUDA enviroments for all 4 workers*********************** (utils.py:550, pretty_print_cuda_env_list())
[2021-11-13 06:50:59]    INFO >> training on 4 GPUs (train.py:222, single_main())
[2021-11-13 06:50:59]    INFO >> max tokens per GPU = None and max sentences per GPU = 4 (train.py:223, single_main())
[2021-11-13 06:50:59]    INFO >> no existing checkpoint found /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (ncc_trainers.py:299, load_checkpoint())
[2021-11-13 06:50:59]    INFO >> loading train data for epoch 1 (ncc_trainers.py:314, get_train_iterator())
[2021-11-13 06:50:59]    INFO >> truncate csharp/train.code_tokens to 320 (translation.py:71, load_langpair_dataset())
[2021-11-13 06:50:59]    INFO >> truncate java/train.code_tokens to 256 (translation.py:86, load_langpair_dataset())
/home/wanyao/anaconda3/envs/py38-1.8/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  warnings.warn(
/home/wanyao/anaconda3/envs/py38-1.8/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  warnings.warn(
/home/wanyao/anaconda3/envs/py38-1.8/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  warnings.warn(
/home/wanyao/anaconda3/envs/py38-1.8/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:425: UserWarning: The `check_reduction` argument in `DistributedDataParallel` module is deprecated. Please avoid using it.
  warnings.warn(
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-11-13 06:51:09]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 06:51:09]    INFO >> Reducer buckets have been rebuilt in this iteration. (distributed.py:693, forward())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-11-13 06:51:09]    INFO >> Reducer buckets have been rebuilt in this iteration. (distributed.py:693, forward())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-11-13 06:51:09]    INFO >> Reducer buckets have been rebuilt in this iteration. (distributed.py:693, forward())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-11-13 06:51:09]    INFO >> Reducer buckets have been rebuilt in this iteration. (distributed.py:693, forward())
[2021-11-13 06:51:19]    INFO >> AMP: overflow detected, setting scale to to 32.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 06:55:24]    INFO >> epoch 001:    500 / 644 loss=102.156, nll_loss=97.761, ppl=2.68489e+29, wps=1427.1, ups=1.96, wpb=728.5, bsz=16, num_updates=500, lr=1.7e-05, gnorm=89.126, clip=100, loss_scale=32, train_wall=254, gb_free=28.7, wall=265 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 06:56:51]    INFO >> epoch 001 | loss 96.228 | nll_loss 91.504 | ppl 3.5116e+27 | wps 1385.6 | ups 1.88 | wpb 736.8 | bsz 16 | num_updates 644 | lr 2.1e-05 | gnorm 78.513 | clip 100 | loss_scale 32 | train_wall 325 | gb_free 28.7 | wall 352 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 06:59:07]    INFO >> epoch 001 | valid on 'valid' subset | loss 60.079 | nll_loss 53.147 | ppl 9.97019e+15 | bleu 1.10114 | wps 182.4 | wpb 3065.4 | bsz 62.5 | num_updates 644 (progress_bar.py:269, print())
[2021-11-13 06:59:13]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 1 @ 644 updates, score 1.101142) (writing took 6.096807 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:02:13]    INFO >> epoch 002:    356 / 644 loss=71.013, nll_loss=64.865, ppl=3.35909e+19, wps=932, ups=1.22, wpb=762.3, bsz=16, num_updates=1000, lr=3.3e-05, gnorm=36.781, clip=97.6, loss_scale=32, train_wall=243, gb_free=28.7, wall=674 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:04:39]    INFO >> epoch 002 | loss 64.915 | nll_loss 58.408 | ppl 3.82333e+17 | wps 1014.7 | ups 1.38 | wpb 736.8 | bsz 16 | num_updates 1288 | lr 4.3e-05 | gnorm 33.082 | clip 95 | loss_scale 32 | train_wall 301 | gb_free 28.7 | wall 820 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:06:47]    INFO >> epoch 002 | valid on 'valid' subset | loss 47.353 | nll_loss 39.502 | ppl 7.7852e+11 | bleu 3.09502 | wps 193.6 | wpb 3065.4 | bsz 62.5 | num_updates 1288 | best_bleu 3.09502 (progress_bar.py:269, print())
[2021-11-13 07:07:00]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 2 @ 1288 updates, score 3.095019) (writing took 12.925848 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:08:50]    INFO >> epoch 003:    212 / 644 loss=57.848, nll_loss=51.038, ppl=2.31182e+15, wps=904.9, ups=1.26, wpb=717.9, bsz=16, num_updates=1500, lr=5e-05, gnorm=29.787, clip=86.4, loss_scale=32, train_wall=232, gb_free=28.7, wall=1070 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:12:37]    INFO >> epoch 003 | loss 51.115 | nll_loss 44.233 | ppl 2.06814e+13 | wps 992.9 | ups 1.35 | wpb 736.8 | bsz 16 | num_updates 1932 | lr 5e-05 | gnorm 27.098 | clip 67.7 | loss_scale 32 | train_wall 313 | gb_free 28.7 | wall 1297 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:15:00]    INFO >> epoch 003 | valid on 'valid' subset | loss 37.398 | nll_loss 29.372 | ppl 6.94731e+08 | bleu 1.9039 | wps 171.8 | wpb 3065.4 | bsz 62.5 | num_updates 1932 | best_bleu 3.09502 (progress_bar.py:269, print())
[2021-11-13 07:15:07]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 3 @ 1932 updates, score 1.903902) (writing took 7.716398 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:15:47]    INFO >> epoch 004:     68 / 644 loss=48.528, nll_loss=41.599, ppl=3.33159e+12, wps=870.1, ups=1.2, wpb=726.5, bsz=16, num_updates=2000, lr=5e-05, gnorm=26.612, clip=63, loss_scale=32, train_wall=243, gb_free=28.7, wall=1488 (progress_bar.py:260, log())
[2021-11-13 07:19:49]    INFO >> epoch 004:    568 / 644 loss=41.651, nll_loss=34.794, ppl=2.97927e+10, wps=1532.1, ups=2.07, wpb=741.6, bsz=16, num_updates=2500, lr=5e-05, gnorm=27.704, clip=72.8, loss_scale=64, train_wall=241, gb_free=28.6, wall=1730 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:20:32]    INFO >> epoch 004 | loss 41.48 | nll_loss 34.629 | ppl 2.65664e+10 | wps 999.5 | ups 1.36 | wpb 736.8 | bsz 16 | num_updates 2576 | lr 5e-05 | gnorm 27.951 | clip 74.5 | loss_scale 64 | train_wall 300 | gb_free 28.7 | wall 1772 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:22:51]    INFO >> epoch 004 | valid on 'valid' subset | loss 30.577 | nll_loss 22.877 | ppl 7.70212e+06 | bleu 2.62284 | wps 172.3 | wpb 3065.4 | bsz 62.5 | num_updates 2576 | best_bleu 3.09502 (progress_bar.py:269, print())
[2021-11-13 07:22:59]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 4 @ 2576 updates, score 2.622836) (writing took 7.458611 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:26:30]    INFO >> epoch 005:    424 / 644 loss=35.652, nll_loss=29.159, ppl=5.99321e+08, wps=924.4, ups=1.25, wpb=741.7, bsz=16, num_updates=3000, lr=5e-05, gnorm=32.475, clip=98.8, loss_scale=64, train_wall=230, gb_free=28.7, wall=2131 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:28:07]    INFO >> epoch 005 | loss 33.819 | nll_loss 27.453 | ppl 1.83784e+08 | wps 1041.2 | ups 1.41 | wpb 736.8 | bsz 16 | num_updates 3220 | lr 5e-05 | gnorm 32.294 | clip 98.8 | loss_scale 64 | train_wall 284 | gb_free 28.7 | wall 2228 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:30:10]    INFO >> epoch 005 | valid on 'valid' subset | loss 24.824 | nll_loss 17.91 | ppl 246272 | bleu 4.34048 | wps 202.3 | wpb 3065.4 | bsz 62.5 | num_updates 3220 | best_bleu 4.34048 (progress_bar.py:269, print())
[2021-11-13 07:30:22]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 5 @ 3220 updates, score 4.340478) (writing took 12.610167 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:32:45]    INFO >> epoch 006:    280 / 644 loss=30.282, nll_loss=24.255, ppl=2.0017e+07, wps=981.8, ups=1.33, wpb=735.7, bsz=16, num_updates=3500, lr=5e-05, gnorm=30.132, clip=93.6, loss_scale=64, train_wall=216, gb_free=28.7, wall=2506 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:35:36]    INFO >> epoch 006 | loss 28.03 | nll_loss 22.217 | ppl 4.87656e+06 | wps 1058.6 | ups 1.44 | wpb 736.8 | bsz 16 | num_updates 3864 | lr 5e-05 | gnorm 28.092 | clip 80.9 | loss_scale 64 | train_wall 289 | gb_free 28.6 | wall 2676 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:37:35]    INFO >> epoch 006 | valid on 'valid' subset | loss 20.985 | nll_loss 14.771 | ppl 27955.5 | bleu 6.56102 | wps 204.5 | wpb 3065.4 | bsz 62.5 | num_updates 3864 | best_bleu 6.56102 (progress_bar.py:269, print())
[2021-11-13 07:37:47]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 6 @ 3864 updates, score 6.561023) (writing took 11.991917 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:39:01]    INFO >> epoch 007:    136 / 644 loss=26.536, nll_loss=20.828, ppl=1.86169e+06, wps=991.6, ups=1.33, wpb=745.6, bsz=16, num_updates=4000, lr=5e-05, gnorm=26.735, clip=68, loss_scale=64, train_wall=220, gb_free=28.7, wall=2882 (progress_bar.py:260, log())
[2021-11-13 07:40:46]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 07:40:46]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
[2021-11-13 07:42:44]    INFO >> epoch 007:    637 / 644 loss=24.145, nll_loss=18.702, ppl=426458, wps=1645.5, ups=2.25, wpb=732.4, bsz=16, num_updates=4500, lr=5e-05, gnorm=24.318, clip=37.4, loss_scale=64, train_wall=221, gb_free=28.7, wall=3104 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:43:00]    INFO >> epoch 007 | loss 24.404 | nll_loss 18.922 | ppl 496553 | wps 1064.2 | ups 1.45 | wpb 736.1 | bsz 16 | num_updates 4507 | lr 5e-05 | gnorm 24.565 | clip 40.7 | loss_scale 64 | train_wall 289 | gb_free 28.7 | wall 3121 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:45:01]    INFO >> epoch 007 | valid on 'valid' subset | loss 18.339 | nll_loss 12.535 | ppl 5934.61 | bleu 5.94825 | wps 203.5 | wpb 3065.4 | bsz 62.5 | num_updates 4507 | best_bleu 6.56102 (progress_bar.py:269, print())
[2021-11-13 07:45:08]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 7 @ 4507 updates, score 5.94825) (writing took 7.488167 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:49:26]    INFO >> epoch 008:    493 / 644 loss=22.021, nll_loss=16.782, ppl=112693, wps=912.5, ups=1.24, wpb=733.8, bsz=16, num_updates=5000, lr=5e-05, gnorm=22.825, clip=18.8, loss_scale=64, train_wall=250, gb_free=28.7, wall=3506 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:50:41]    INFO >> epoch 008 | loss 21.706 | nll_loss 16.498 | ppl 92526.2 | wps 1029.6 | ups 1.4 | wpb 736.8 | bsz 16 | num_updates 5151 | lr 5e-05 | gnorm 22.558 | clip 16.8 | loss_scale 64 | train_wall 309 | gb_free 28.7 | wall 3582 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:52:50]    INFO >> epoch 008 | valid on 'valid' subset | loss 16.689 | nll_loss 11.14 | ppl 2257.43 | bleu 5.33475 | wps 178.7 | wpb 3065.4 | bsz 62.5 | num_updates 5151 | best_bleu 6.56102 (progress_bar.py:269, print())
[2021-11-13 07:52:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 8 @ 5151 updates, score 5.334752) (writing took 7.544757 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 07:55:57]    INFO >> epoch 009:    349 / 644 loss=20.071, nll_loss=15, ppl=32764.5, wps=928, ups=1.28, wpb=727.1, bsz=16, num_updates=5500, lr=5e-05, gnorm=21.27, clip=7.4, loss_scale=64, train_wall=231, gb_free=28.7, wall=3898 (progress_bar.py:260, log())
[2021-11-13 07:57:29]    INFO >> AMP: overflow detected, setting scale to to 32.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 07:57:30]    INFO >> AMP: overflow detected, setting scale to to 16.0 (amp_optimizer.py:66, clip_grad_norm())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 07:58:10]    INFO >> epoch 009 | loss 19.498 | nll_loss 14.538 | ppl 23791.4 | wps 1056.8 | ups 1.43 | wpb 736.8 | bsz 16 | num_updates 5795 | lr 5e-05 | gnorm 21.015 | clip 6.7 | loss_scale 16 | train_wall 288 | gb_free 28.7 | wall 4031 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:00:05]    INFO >> epoch 009 | valid on 'valid' subset | loss 14.88 | nll_loss 9.713 | ppl 839.46 | bleu 6.47579 | wps 215.2 | wpb 3065.4 | bsz 62.5 | num_updates 5795 | best_bleu 6.56102 (progress_bar.py:269, print())
[2021-11-13 08:00:13]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 9 @ 5795 updates, score 6.475792) (writing took 7.493441 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:01:58]    INFO >> epoch 010:    205 / 644 loss=18.649, nll_loss=13.818, ppl=14440.9, wps=1030, ups=1.39, wpb=742.2, bsz=16, num_updates=6000, lr=5e-05, gnorm=20.331, clip=5.8, loss_scale=16, train_wall=214, gb_free=28.7, wall=4258 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:05:25]    INFO >> epoch 010 | loss 17.376 | nll_loss 12.744 | ppl 6861.96 | wps 1090.4 | ups 1.48 | wpb 736.8 | bsz 16 | num_updates 6439 | lr 5e-05 | gnorm 19.039 | clip 1.7 | loss_scale 16 | train_wall 289 | gb_free 28.7 | wall 4466 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:07:32]    INFO >> epoch 010 | valid on 'valid' subset | loss 13.496 | nll_loss 8.574 | ppl 380.98 | bleu 6.00846 | wps 191.8 | wpb 3065.4 | bsz 62.5 | num_updates 6439 | best_bleu 6.56102 (progress_bar.py:269, print())
[2021-11-13 08:07:40]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 10 @ 6439 updates, score 6.008457) (writing took 7.560737 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:08:19]    INFO >> epoch 011:     61 / 644 loss=17.016, nll_loss=12.463, ppl=5646.89, wps=977.7, ups=1.31, wpb=744.7, bsz=16, num_updates=6500, lr=5e-05, gnorm=18.78, clip=1, loss_scale=16, train_wall=222, gb_free=28.7, wall=4639 (progress_bar.py:260, log())
[2021-11-13 08:12:02]    INFO >> epoch 011:    561 / 644 loss=15.577, nll_loss=11.254, ppl=2442.54, wps=1645.9, ups=2.24, wpb=735.7, bsz=16, num_updates=7000, lr=5e-05, gnorm=17.667, clip=0, loss_scale=16, train_wall=222, gb_free=28.7, wall=4863 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:12:44]    INFO >> epoch 011 | loss 15.556 | nll_loss 11.239 | ppl 2416.84 | wps 1082.6 | ups 1.47 | wpb 736.8 | bsz 16 | num_updates 7083 | lr 5e-05 | gnorm 17.662 | clip 0 | loss_scale 16 | train_wall 279 | gb_free 28.7 | wall 4904 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:14:54]    INFO >> epoch 011 | valid on 'valid' subset | loss 12.296 | nll_loss 7.732 | ppl 212.6 | bleu 4.6692 | wps 188 | wpb 3065.4 | bsz 62.5 | num_updates 7083 | best_bleu 6.56102 (progress_bar.py:269, print())
[2021-11-13 08:15:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 11 @ 7083 updates, score 4.6692) (writing took 7.382042 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:18:29]    INFO >> epoch 012:    417 / 644 loss=14.325, nll_loss=10.221, ppl=1193.26, wps=941.6, ups=1.29, wpb=728.8, bsz=16, num_updates=7500, lr=5e-05, gnorm=16.552, clip=0.2, loss_scale=16, train_wall=225, gb_free=28.7, wall=5250 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:20:02]    INFO >> epoch 012 | loss 14.071 | nll_loss 10.047 | ppl 1057.83 | wps 1081.8 | ups 1.47 | wpb 736.8 | bsz 16 | num_updates 7727 | lr 5e-05 | gnorm 16.281 | clip 0.2 | loss_scale 32 | train_wall 277 | gb_free 28.7 | wall 5343 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:22:02]    INFO >> epoch 012 | valid on 'valid' subset | loss 11.059 | nll_loss 6.806 | ppl 111.9 | bleu 9.22622 | wps 208.1 | wpb 3065.4 | bsz 62.5 | num_updates 7727 | best_bleu 9.22622 (progress_bar.py:269, print())
[2021-11-13 08:22:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 12 @ 7727 updates, score 9.226217) (writing took 11.541895 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:24:40]    INFO >> epoch 013:    273 / 644 loss=13.344, nll_loss=9.427, ppl=688.24, wps=977.3, ups=1.35, wpb=725.3, bsz=16, num_updates=8000, lr=5e-05, gnorm=15.599, clip=0.2, loss_scale=32, train_wall=216, gb_free=28.7, wall=5621 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:27:33]    INFO >> epoch 013 | loss 12.841 | nll_loss 9.028 | ppl 521.97 | wps 1052.2 | ups 1.43 | wpb 736.8 | bsz 16 | num_updates 8371 | lr 5e-05 | gnorm 15.052 | clip 0.2 | loss_scale 32 | train_wall 295 | gb_free 28.7 | wall 5794 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:29:36]    INFO >> epoch 013 | valid on 'valid' subset | loss 10.428 | nll_loss 6.42 | ppl 85.61 | bleu 15.1337 | wps 197.2 | wpb 3065.4 | bsz 62.5 | num_updates 8371 | best_bleu 15.1337 (progress_bar.py:269, print())
[2021-11-13 08:29:48]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 13 @ 8371 updates, score 15.133749) (writing took 12.247877 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:30:57]    INFO >> epoch 014:    129 / 644 loss=12.673, nll_loss=8.947, ppl=493.61, wps=1007.2, ups=1.33, wpb=759.1, bsz=16, num_updates=8500, lr=5e-05, gnorm=14.833, clip=0, loss_scale=32, train_wall=218, gb_free=28.7, wall=5998 (progress_bar.py:260, log())
[2021-11-13 08:34:23]    INFO >> epoch 014:    629 / 644 loss=11.821, nll_loss=8.211, ppl=296.38, wps=1791.7, ups=2.43, wpb=737, bsz=16, num_updates=9000, lr=5e-05, gnorm=14.106, clip=0, loss_scale=32, train_wall=205, gb_free=28.7, wall=6203 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:34:44]    INFO >> epoch 014 | loss 11.873 | nll_loss 8.24 | ppl 302.24 | wps 1102.3 | ups 1.5 | wpb 736.8 | bsz 16 | num_updates 9015 | lr 5e-05 | gnorm 14.186 | clip 0 | loss_scale 32 | train_wall 272 | gb_free 28.7 | wall 6225 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:36:50]    INFO >> epoch 014 | valid on 'valid' subset | loss 9.669 | nll_loss 5.805 | ppl 55.92 | bleu 9.15249 | wps 191 | wpb 3065.4 | bsz 62.5 | num_updates 9015 | best_bleu 15.1337 (progress_bar.py:269, print())
[2021-11-13 08:36:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 14 @ 9015 updates, score 9.152492) (writing took 7.758710 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:40:41]    INFO >> epoch 015:    485 / 644 loss=11.024, nll_loss=7.509, ppl=182.21, wps=963, ups=1.32, wpb=728, bsz=16, num_updates=9500, lr=5e-05, gnorm=13.608, clip=0.4, loss_scale=32, train_wall=220, gb_free=28.7, wall=6581 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:42:06]    INFO >> epoch 015 | loss 10.993 | nll_loss 7.52 | ppl 183.51 | wps 1073.4 | ups 1.46 | wpb 736.8 | bsz 16 | num_updates 9659 | lr 5e-05 | gnorm 13.46 | clip 0.3 | loss_scale 32 | train_wall 284 | gb_free 28.7 | wall 6667 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:44:26]    INFO >> epoch 015 | valid on 'valid' subset | loss 9.363 | nll_loss 5.608 | ppl 48.76 | bleu 8.94855 | wps 164.4 | wpb 3065.4 | bsz 62.5 | num_updates 9659 | best_bleu 15.1337 (progress_bar.py:269, print())
[2021-11-13 08:44:33]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 15 @ 9659 updates, score 8.948547) (writing took 7.554127 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:47:06]    INFO >> epoch 016:    341 / 644 loss=10.461, nll_loss=7.073, ppl=134.68, wps=957.2, ups=1.3, wpb=737.8, bsz=16, num_updates=10000, lr=5e-05, gnorm=12.652, clip=0, loss_scale=64, train_wall=214, gb_free=28.7, wall=6967 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:49:16]    INFO >> epoch 016 | loss 10.227 | nll_loss 6.878 | ppl 117.6 | wps 1103 | ups 1.5 | wpb 736.8 | bsz 16 | num_updates 10303 | lr 5e-05 | gnorm 12.445 | clip 0 | loss_scale 64 | train_wall 259 | gb_free 28.7 | wall 7097 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:51:31]    INFO >> epoch 016 | valid on 'valid' subset | loss 8.755 | nll_loss 5.157 | ppl 35.67 | bleu 12.8041 | wps 169.1 | wpb 3065.4 | bsz 62.5 | num_updates 10303 | best_bleu 15.1337 (progress_bar.py:269, print())
[2021-11-13 08:51:39]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 16 @ 10303 updates, score 12.804099) (writing took 7.448481 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:53:19]    INFO >> epoch 017:    197 / 644 loss=10.012, nll_loss=6.716, ppl=105.16, wps=993.5, ups=1.34, wpb=741, bsz=16, num_updates=10500, lr=5e-05, gnorm=12.23, clip=0, loss_scale=64, train_wall=206, gb_free=28.7, wall=7340 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:56:26]    INFO >> epoch 017 | loss 9.631 | nll_loss 6.391 | ppl 83.9 | wps 1104.9 | ups 1.5 | wpb 736.8 | bsz 16 | num_updates 10947 | lr 5e-05 | gnorm 11.808 | clip 0 | loss_scale 64 | train_wall 262 | gb_free 28.7 | wall 7526 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 08:58:41]    INFO >> epoch 017 | valid on 'valid' subset | loss 8.338 | nll_loss 4.863 | ppl 29.11 | bleu 13.1431 | wps 175.8 | wpb 3065.4 | bsz 62.5 | num_updates 10947 | best_bleu 15.1337 (progress_bar.py:269, print())
[2021-11-13 08:58:49]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 17 @ 10947 updates, score 13.14314) (writing took 7.612670 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 08:59:23]    INFO >> epoch 018:     53 / 644 loss=9.555, nll_loss=6.342, ppl=81.13, wps=1014.9, ups=1.37, wpb=739.7, bsz=16, num_updates=11000, lr=5e-05, gnorm=11.696, clip=0, loss_scale=64, train_wall=197, gb_free=28.7, wall=7704 (progress_bar.py:260, log())
[2021-11-13 09:02:55]    INFO >> epoch 018:    553 / 644 loss=9.043, nll_loss=5.889, ppl=59.26, wps=1743, ups=2.37, wpb=736.6, bsz=16, num_updates=11500, lr=4.9e-05, gnorm=11.224, clip=0, loss_scale=64, train_wall=210, gb_free=28.7, wall=7915 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:03:39]    INFO >> epoch 018 | loss 9.072 | nll_loss 5.928 | ppl 60.89 | wps 1096.1 | ups 1.49 | wpb 736.8 | bsz 16 | num_updates 11591 | lr 4.9e-05 | gnorm 11.209 | clip 0 | loss_scale 64 | train_wall 265 | gb_free 28.7 | wall 7959 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:05:49]    INFO >> epoch 018 | valid on 'valid' subset | loss 7.866 | nll_loss 4.559 | ppl 23.57 | bleu 19.3646 | wps 189.4 | wpb 3065.4 | bsz 62.5 | num_updates 11591 | best_bleu 19.3646 (progress_bar.py:269, print())
[2021-11-13 09:06:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 18 @ 11591 updates, score 19.364585) (writing took 12.202143 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:08:56]    INFO >> epoch 019:    409 / 644 loss=8.609, nll_loss=5.515, ppl=45.72, wps=1005.7, ups=1.38, wpb=727.6, bsz=16, num_updates=12000, lr=4.9e-05, gnorm=10.608, clip=0, loss_scale=128, train_wall=195, gb_free=28.7, wall=8277 (progress_bar.py:260, log())
[2021-11-13 09:09:09]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 09:09:09]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:10:32]    INFO >> epoch 019 | loss 8.567 | nll_loss 5.505 | ppl 45.41 | wps 1143.6 | ups 1.55 | wpb 735.7 | bsz 16 | num_updates 12234 | lr 4.9e-05 | gnorm 10.613 | clip 0 | loss_scale 64 | train_wall 247 | gb_free 28.7 | wall 8373 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:12:51]    INFO >> epoch 019 | valid on 'valid' subset | loss 7.565 | nll_loss 4.333 | ppl 20.15 | bleu 14.2579 | wps 176.1 | wpb 3065.4 | bsz 62.5 | num_updates 12234 | best_bleu 19.3646 (progress_bar.py:269, print())
[2021-11-13 09:12:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 19 @ 12234 updates, score 14.257944) (writing took 7.524059 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:14:56]    INFO >> epoch 020:    266 / 644 loss=8.403, nll_loss=5.392, ppl=42, wps=1018, ups=1.39, wpb=731.2, bsz=16, num_updates=12500, lr=4.9e-05, gnorm=10.436, clip=0, loss_scale=64, train_wall=189, gb_free=28.7, wall=8636 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:17:41]    INFO >> epoch 020 | loss 8.148 | nll_loss 5.171 | ppl 36.02 | wps 1108.1 | ups 1.5 | wpb 736.8 | bsz 16 | num_updates 12878 | lr 4.9e-05 | gnorm 10.135 | clip 0 | loss_scale 64 | train_wall 258 | gb_free 28.7 | wall 8801 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:19:47]    INFO >> epoch 020 | valid on 'valid' subset | loss 7.292 | nll_loss 4.154 | ppl 17.8 | bleu 21.013 | wps 195.1 | wpb 3065.4 | bsz 62.5 | num_updates 12878 | best_bleu 21.013 (progress_bar.py:269, print())
[2021-11-13 09:19:59]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 20 @ 12878 updates, score 21.013015) (writing took 12.080082 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:21:04]    INFO >> epoch 021:    122 / 644 loss=8.067, nll_loss=5.122, ppl=34.83, wps=1021.7, ups=1.36, wpb=752.3, bsz=16, num_updates=13000, lr=4.9e-05, gnorm=10.033, clip=0, loss_scale=64, train_wall=205, gb_free=28.7, wall=9004 (progress_bar.py:260, log())
[2021-11-13 09:23:58]    INFO >> epoch 021:    622 / 644 loss=7.686, nll_loss=4.785, ppl=27.58, wps=2103.4, ups=2.87, wpb=732.3, bsz=16, num_updates=13500, lr=4.9e-05, gnorm=9.657, clip=0, loss_scale=64, train_wall=173, gb_free=28.1, wall=9178 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:24:24]    INFO >> epoch 021 | loss 7.732 | nll_loss 4.83 | ppl 28.44 | wps 1177.1 | ups 1.6 | wpb 736.8 | bsz 16 | num_updates 13522 | lr 4.9e-05 | gnorm 9.656 | clip 0 | loss_scale 64 | train_wall 240 | gb_free 28.7 | wall 9204 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:26:21]    INFO >> epoch 021 | valid on 'valid' subset | loss 7.084 | nll_loss 4.009 | ppl 16.1 | bleu 23.1542 | wps 206.9 | wpb 3065.4 | bsz 62.5 | num_updates 13522 | best_bleu 23.1542 (progress_bar.py:269, print())
[2021-11-13 09:26:33]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 21 @ 13522 updates, score 23.154155) (writing took 12.268328 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:29:44]    INFO >> epoch 022:    478 / 644 loss=7.343, nll_loss=4.491, ppl=22.49, wps=1070.7, ups=1.45, wpb=740.4, bsz=16, num_updates=14000, lr=4.9e-05, gnorm=9.183, clip=0, loss_scale=64, train_wall=192, gb_free=28.7, wall=9524 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:31:07]    INFO >> epoch 022 | loss 7.338 | nll_loss 4.507 | ppl 22.74 | wps 1177.5 | ups 1.6 | wpb 736.8 | bsz 16 | num_updates 14166 | lr 4.9e-05 | gnorm 9.13 | clip 0 | loss_scale 128 | train_wall 249 | gb_free 28.7 | wall 9607 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:33:08]    INFO >> epoch 022 | valid on 'valid' subset | loss 6.866 | nll_loss 3.878 | ppl 14.71 | bleu 22.9614 | wps 204.8 | wpb 3065.4 | bsz 62.5 | num_updates 14166 | best_bleu 23.1542 (progress_bar.py:269, print())
[2021-11-13 09:33:15]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 22 @ 14166 updates, score 22.961439) (writing took 6.969238 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:35:41]    INFO >> epoch 023:    334 / 644 loss=7.115, nll_loss=4.326, ppl=20.06, wps=1020.9, ups=1.4, wpb=728.9, bsz=16, num_updates=14500, lr=4.9e-05, gnorm=8.822, clip=0, loss_scale=128, train_wall=204, gb_free=28.5, wall=9881 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:38:01]    INFO >> epoch 023 | loss 6.978 | nll_loss 4.204 | ppl 18.43 | wps 1145 | ups 1.55 | wpb 736.8 | bsz 16 | num_updates 14810 | lr 4.9e-05 | gnorm 8.696 | clip 0 | loss_scale 128 | train_wall 261 | gb_free 28.7 | wall 10022 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:39:58]    INFO >> epoch 023 | valid on 'valid' subset | loss 6.624 | nll_loss 3.73 | ppl 13.27 | bleu 20.6594 | wps 201.6 | wpb 3065.4 | bsz 62.5 | num_updates 14810 | best_bleu 23.1542 (progress_bar.py:269, print())
[2021-11-13 09:40:05]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 23 @ 14810 updates, score 20.659403) (writing took 7.583101 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:41:25]    INFO >> epoch 024:    190 / 644 loss=6.863, nll_loss=4.111, ppl=17.28, wps=1060.1, ups=1.45, wpb=729.1, bsz=16, num_updates=15000, lr=4.9e-05, gnorm=8.533, clip=0, loss_scale=128, train_wall=196, gb_free=28.7, wall=10225 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:44:29]    INFO >> epoch 024 | loss 6.682 | nll_loss 3.966 | ppl 15.63 | wps 1223.8 | ups 1.66 | wpb 736.8 | bsz 16 | num_updates 15454 | lr 4.9e-05 | gnorm 8.238 | clip 0 | loss_scale 128 | train_wall 239 | gb_free 28.7 | wall 10409 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:46:41]    INFO >> epoch 024 | valid on 'valid' subset | loss 6.464 | nll_loss 3.623 | ppl 12.32 | bleu 18.9498 | wps 186.1 | wpb 3065.4 | bsz 62.5 | num_updates 15454 | best_bleu 23.1542 (progress_bar.py:269, print())
[2021-11-13 09:46:48]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 24 @ 15454 updates, score 18.949766) (writing took 7.326648 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:47:18]    INFO >> epoch 025:     46 / 644 loss=6.666, nll_loss=3.969, ppl=15.66, wps=1062, ups=1.41, wpb=751.1, bsz=16, num_updates=15500, lr=4.9e-05, gnorm=8.175, clip=0, loss_scale=128, train_wall=190, gb_free=28.7, wall=10579 (progress_bar.py:260, log())
[2021-11-13 09:48:11]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 09:50:14]    INFO >> epoch 025:    546 / 644 loss=6.438, nll_loss=3.78, ppl=13.74, wps=2098.2, ups=2.85, wpb=736.7, bsz=16, num_updates=16000, lr=4.9e-05, gnorm=8.044, clip=0, loss_scale=64, train_wall=174, gb_free=28.7, wall=10754 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:51:17]    INFO >> epoch 025 | loss 6.427 | nll_loss 3.773 | ppl 13.67 | wps 1163.8 | ups 1.58 | wpb 736.8 | bsz 16 | num_updates 16098 | lr 4.9e-05 | gnorm 8.023 | clip 0 | loss_scale 64 | train_wall 243 | gb_free 28.7 | wall 10817 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:53:08]    INFO >> epoch 025 | valid on 'valid' subset | loss 6.28 | nll_loss 3.51 | ppl 11.39 | bleu 26.3918 | wps 212.7 | wpb 3065.4 | bsz 62.5 | num_updates 16098 | best_bleu 26.3918 (progress_bar.py:269, print())
[2021-11-13 09:53:20]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 25 @ 16098 updates, score 26.391845) (writing took 12.048893 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 09:55:19]    INFO >> epoch 026:    402 / 644 loss=6.181, nll_loss=3.568, ppl=11.86, wps=1182.5, ups=1.64, wpb=721.3, bsz=16, num_updates=16500, lr=4.9e-05, gnorm=7.695, clip=0, loss_scale=64, train_wall=158, gb_free=28.7, wall=11059 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:57:14]    INFO >> epoch 026 | loss 6.143 | nll_loss 3.554 | ppl 11.75 | wps 1329.4 | ups 1.8 | wpb 736.8 | bsz 16 | num_updates 16742 | lr 4.9e-05 | gnorm 7.614 | clip 0 | loss_scale 64 | train_wall 209 | gb_free 28.7 | wall 11174 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 09:58:54]    INFO >> epoch 026 | valid on 'valid' subset | loss 6.046 | nll_loss 3.411 | ppl 10.63 | bleu 26.272 | wps 238.5 | wpb 3065.4 | bsz 62.5 | num_updates 16742 | best_bleu 26.3918 (progress_bar.py:269, print())
[2021-11-13 09:59:02]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 26 @ 16742 updates, score 26.271987) (writing took 7.966323 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:00:30]    INFO >> epoch 027:    258 / 644 loss=6.065, nll_loss=3.519, ppl=11.46, wps=1219.4, ups=1.6, wpb=760.1, bsz=16, num_updates=17000, lr=4.9e-05, gnorm=7.437, clip=0, loss_scale=64, train_wall=178, gb_free=28.7, wall=11371 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:03:03]    INFO >> epoch 027 | loss 5.864 | nll_loss 3.337 | ppl 10.11 | wps 1359.5 | ups 1.85 | wpb 736.8 | bsz 16 | num_updates 17386 | lr 4.9e-05 | gnorm 7.232 | clip 0 | loss_scale 64 | train_wall 215 | gb_free 28.7 | wall 11523 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:04:44]    INFO >> epoch 027 | valid on 'valid' subset | loss 5.931 | nll_loss 3.342 | ppl 10.14 | bleu 21.5619 | wps 255.3 | wpb 3065.4 | bsz 62.5 | num_updates 17386 | best_bleu 26.3918 (progress_bar.py:269, print())
[2021-11-13 10:04:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 27 @ 17386 updates, score 21.561938) (writing took 7.192270 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:05:40]    INFO >> epoch 028:    114 / 644 loss=5.733, nll_loss=3.215, ppl=9.29, wps=1163.2, ups=1.62, wpb=719.6, bsz=16, num_updates=17500, lr=4.9e-05, gnorm=7.195, clip=0, loss_scale=64, train_wall=177, gb_free=28.7, wall=11680 (progress_bar.py:260, log())
[2021-11-13 10:08:49]    INFO >> epoch 028:    614 / 644 loss=5.55, nll_loss=3.086, ppl=8.49, wps=1941, ups=2.63, wpb=736.7, bsz=16, num_updates=18000, lr=4.9e-05, gnorm=6.728, clip=0, loss_scale=128, train_wall=189, gb_free=28.6, wall=11870 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:09:18]    INFO >> epoch 028 | loss 5.576 | nll_loss 3.109 | ppl 8.63 | wps 1264.3 | ups 1.72 | wpb 736.8 | bsz 16 | num_updates 18030 | lr 4.9e-05 | gnorm 6.814 | clip 0 | loss_scale 128 | train_wall 242 | gb_free 28.7 | wall 11899 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:10:54]    INFO >> epoch 028 | valid on 'valid' subset | loss 5.81 | nll_loss 3.262 | ppl 9.59 | bleu 24.7178 | wps 256.2 | wpb 3065.4 | bsz 62.5 | num_updates 18030 | best_bleu 26.3918 (progress_bar.py:269, print())
[2021-11-13 10:11:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 28 @ 18030 updates, score 24.717835) (writing took 7.436354 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:14:04]    INFO >> epoch 029:    470 / 644 loss=5.4, nll_loss=2.986, ppl=7.92, wps=1189.5, ups=1.59, wpb=748.9, bsz=16, num_updates=18500, lr=4.9e-05, gnorm=6.538, clip=0, loss_scale=128, train_wall=187, gb_free=28.7, wall=12185 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:15:38]    INFO >> epoch 029 | loss 5.334 | nll_loss 2.924 | ppl 7.59 | wps 1250.4 | ups 1.7 | wpb 736.8 | bsz 16 | num_updates 18674 | lr 4.9e-05 | gnorm 6.47 | clip 0 | loss_scale 128 | train_wall 252 | gb_free 28.7 | wall 12278 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:17:08]    INFO >> epoch 029 | valid on 'valid' subset | loss 5.624 | nll_loss 3.171 | ppl 9 | bleu 27.547 | wps 272.1 | wpb 3065.4 | bsz 62.5 | num_updates 18674 | best_bleu 27.547 (progress_bar.py:269, print())
[2021-11-13 10:17:20]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 29 @ 18674 updates, score 27.547017) (writing took 11.758732 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:19:30]    INFO >> epoch 030:    326 / 644 loss=5.161, nll_loss=2.784, ppl=6.89, wps=1120.1, ups=1.54, wpb=728.8, bsz=16, num_updates=19000, lr=4.9e-05, gnorm=6.249, clip=0, loss_scale=128, train_wall=199, gb_free=28.7, wall=12510 (progress_bar.py:260, log())
[2021-11-13 10:20:01]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:22:04]    INFO >> epoch 030 | loss 5.122 | nll_loss 2.776 | ppl 6.85 | wps 1227 | ups 1.67 | wpb 736.8 | bsz 16 | num_updates 19318 | lr 4.9e-05 | gnorm 6.206 | clip 0 | loss_scale 64 | train_wall 260 | gb_free 28.7 | wall 12665 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:23:29]    INFO >> epoch 030 | valid on 'valid' subset | loss 5.421 | nll_loss 3.079 | ppl 8.45 | bleu 24.9391 | wps 296.7 | wpb 3065.4 | bsz 62.5 | num_updates 19318 | best_bleu 27.547 (progress_bar.py:269, print())
[2021-11-13 10:23:36]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 30 @ 19318 updates, score 24.939053) (writing took 7.060151 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:24:45]    INFO >> epoch 031:    182 / 644 loss=5.05, nll_loss=2.733, ppl=6.65, wps=1172.7, ups=1.59, wpb=739.8, bsz=16, num_updates=19500, lr=4.9e-05, gnorm=6.097, clip=0, loss_scale=64, train_wall=200, gb_free=28.7, wall=12826 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:28:15]    INFO >> epoch 031 | loss 4.906 | nll_loss 2.634 | ppl 6.21 | wps 1279.9 | ups 1.74 | wpb 736.8 | bsz 16 | num_updates 19962 | lr 4.9e-05 | gnorm 5.874 | clip 0 | loss_scale 64 | train_wall 255 | gb_free 28.7 | wall 13036 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:29:49]    INFO >> epoch 031 | valid on 'valid' subset | loss 5.368 | nll_loss 3.064 | ppl 8.37 | bleu 20.1454 | wps 255.1 | wpb 3065.4 | bsz 62.5 | num_updates 19962 | best_bleu 27.547 (progress_bar.py:269, print())
[2021-11-13 10:29:56]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 31 @ 19962 updates, score 20.145356) (writing took 7.024654 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:30:20]    INFO >> epoch 032:     38 / 644 loss=4.91, nll_loss=2.659, ppl=6.32, wps=1105.4, ups=1.49, wpb=741.3, bsz=16, num_updates=20000, lr=4.9e-05, gnorm=5.845, clip=0, loss_scale=64, train_wall=210, gb_free=28.7, wall=13161 (progress_bar.py:260, log())
[2021-11-13 10:33:43]    INFO >> epoch 032:    538 / 644 loss=4.696, nll_loss=2.489, ppl=5.61, wps=1800.6, ups=2.46, wpb=731, bsz=16, num_updates=20500, lr=4.9e-05, gnorm=5.593, clip=0, loss_scale=64, train_wall=202, gb_free=28.7, wall=13364 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:34:41]    INFO >> epoch 032 | loss 4.691 | nll_loss 2.49 | ppl 5.62 | wps 1229.4 | ups 1.67 | wpb 736.8 | bsz 16 | num_updates 20606 | lr 4.9e-05 | gnorm 5.569 | clip 0 | loss_scale 64 | train_wall 260 | gb_free 28.7 | wall 13422 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:35:49]    INFO >> epoch 032 | valid on 'valid' subset | loss 5.201 | nll_loss 3.011 | ppl 8.06 | bleu 29.1201 | wps 373.4 | wpb 3065.4 | bsz 62.5 | num_updates 20606 | best_bleu 29.1201 (progress_bar.py:269, print())
[2021-11-13 10:36:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 32 @ 20606 updates, score 29.120148) (writing took 11.803548 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:38:55]    INFO >> epoch 033:    394 / 644 loss=4.538, nll_loss=2.38, ppl=5.2, wps=1187.2, ups=1.61, wpb=739.3, bsz=16, num_updates=21000, lr=4.9e-05, gnorm=5.245, clip=0, loss_scale=64, train_wall=207, gb_free=28.7, wall=13675 (progress_bar.py:260, log())
[2021-11-13 10:40:09]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 10:40:09]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:41:01]    INFO >> epoch 033 | loss 4.498 | nll_loss 2.354 | ppl 5.11 | wps 1245.3 | ups 1.69 | wpb 736.2 | bsz 16 | num_updates 21249 | lr 4.9e-05 | gnorm 5.151 | clip 0 | loss_scale 64 | train_wall 275 | gb_free 28.7 | wall 13802 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:42:28]    INFO >> epoch 033 | valid on 'valid' subset | loss 5.077 | nll_loss 2.947 | ppl 7.71 | bleu 27.9598 | wps 295 | wpb 3065.4 | bsz 62.5 | num_updates 21249 | best_bleu 29.1201 (progress_bar.py:269, print())
[2021-11-13 10:42:35]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 33 @ 21249 updates, score 27.959767) (writing took 7.588931 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:44:34]    INFO >> epoch 034:    251 / 644 loss=4.407, nll_loss=2.281, ppl=4.86, wps=1077.3, ups=1.47, wpb=731.6, bsz=16, num_updates=21500, lr=4.9e-05, gnorm=4.985, clip=0, loss_scale=64, train_wall=221, gb_free=28.7, wall=14015 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:47:41]    INFO >> epoch 034 | loss 4.364 | nll_loss 2.259 | ppl 4.79 | wps 1187.7 | ups 1.61 | wpb 736.8 | bsz 16 | num_updates 21893 | lr 4.9e-05 | gnorm 4.904 | clip 0 | loss_scale 64 | train_wall 280 | gb_free 28.7 | wall 14201 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:49:12]    INFO >> epoch 034 | valid on 'valid' subset | loss 5.024 | nll_loss 2.933 | ppl 7.64 | bleu 30.2519 | wps 261.3 | wpb 3065.4 | bsz 62.5 | num_updates 21893 | best_bleu 30.2519 (progress_bar.py:269, print())
[2021-11-13 10:49:26]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 34 @ 21893 updates, score 30.251887) (writing took 13.192784 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:50:20]    INFO >> epoch 035:    107 / 644 loss=4.32, nll_loss=2.223, ppl=4.67, wps=1060.3, ups=1.45, wpb=733.3, bsz=16, num_updates=22000, lr=4.9e-05, gnorm=4.88, clip=0, loss_scale=64, train_wall=217, gb_free=28.7, wall=14361 (progress_bar.py:260, log())
[2021-11-13 10:53:58]    INFO >> epoch 035:    607 / 644 loss=4.254, nll_loss=2.17, ppl=4.5, wps=1702.9, ups=2.3, wpb=741.8, bsz=16, num_updates=22500, lr=4.9e-05, gnorm=4.718, clip=0, loss_scale=64, train_wall=217, gb_free=28.7, wall=14578 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:54:28]    INFO >> epoch 035 | loss 4.25 | nll_loss 2.163 | ppl 4.48 | wps 1166.4 | ups 1.58 | wpb 736.8 | bsz 16 | num_updates 22537 | lr 4.9e-05 | gnorm 4.736 | clip 0 | loss_scale 64 | train_wall 277 | gb_free 28.7 | wall 14608 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 10:55:54]    INFO >> epoch 035 | valid on 'valid' subset | loss 4.963 | nll_loss 2.912 | ppl 7.53 | bleu 26.6411 | wps 290.7 | wpb 3065.4 | bsz 62.5 | num_updates 22537 | best_bleu 30.2519 (progress_bar.py:269, print())
[2021-11-13 10:56:02]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 35 @ 22537 updates, score 26.641097) (writing took 7.937997 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 10:59:35]    INFO >> epoch 036:    463 / 644 loss=4.18, nll_loss=2.104, ppl=4.3, wps=1097.7, ups=1.48, wpb=739.7, bsz=16, num_updates=23000, lr=4.9e-05, gnorm=4.604, clip=0, loss_scale=64, train_wall=218, gb_free=28.7, wall=14915 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:01:10]    INFO >> epoch 036 | loss 4.149 | nll_loss 2.073 | ppl 4.21 | wps 1180.6 | ups 1.6 | wpb 736.8 | bsz 16 | num_updates 23181 | lr 4.9e-05 | gnorm 4.547 | clip 0 | loss_scale 128 | train_wall 283 | gb_free 28.6 | wall 15010 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:02:34]    INFO >> epoch 036 | valid on 'valid' subset | loss 4.933 | nll_loss 2.868 | ppl 7.3 | bleu 28.3414 | wps 292.7 | wpb 3065.4 | bsz 62.5 | num_updates 23181 | best_bleu 30.2519 (progress_bar.py:269, print())
[2021-11-13 11:02:42]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 36 @ 23181 updates, score 28.341356) (writing took 7.615914 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:03:05]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 11:03:05]    INFO >> AMP: overflow detected, setting scale to to 32.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 11:04:59]    INFO >> epoch 037:    319 / 644 loss=4.112, nll_loss=2.043, ppl=4.12, wps=1151, ups=1.54, wpb=746.8, bsz=16, num_updates=23500, lr=4.9e-05, gnorm=4.476, clip=0, loss_scale=32, train_wall=207, gb_free=28.7, wall=15240 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:07:25]    INFO >> epoch 037 | loss 4.087 | nll_loss 2.02 | ppl 4.06 | wps 1262.1 | ups 1.71 | wpb 736.8 | bsz 16 | num_updates 23825 | lr 4.9e-05 | gnorm 4.497 | clip 0 | loss_scale 32 | train_wall 258 | gb_free 28.7 | wall 15386 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:08:43]    INFO >> epoch 037 | valid on 'valid' subset | loss 4.868 | nll_loss 2.845 | ppl 7.19 | bleu 30.0639 | wps 351.6 | wpb 3065.4 | bsz 62.5 | num_updates 23825 | best_bleu 30.2519 (progress_bar.py:269, print())
[2021-11-13 11:08:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 37 @ 23825 updates, score 30.063861) (writing took 7.603774 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:10:10]    INFO >> epoch 038:    175 / 644 loss=4.031, nll_loss=1.962, ppl=3.9, wps=1163, ups=1.61, wpb=723, bsz=16, num_updates=24000, lr=4.9e-05, gnorm=4.456, clip=0, loss_scale=32, train_wall=201, gb_free=28.7, wall=15551 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:13:41]    INFO >> epoch 038 | loss 4.005 | nll_loss 1.944 | ppl 3.85 | wps 1263.1 | ups 1.71 | wpb 736.8 | bsz 16 | num_updates 24469 | lr 4.9e-05 | gnorm 4.419 | clip 0 | loss_scale 32 | train_wall 265 | gb_free 28.6 | wall 15762 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:15:15]    INFO >> epoch 038 | valid on 'valid' subset | loss 4.836 | nll_loss 2.827 | ppl 7.1 | bleu 30.5857 | wps 255.4 | wpb 3065.4 | bsz 62.5 | num_updates 24469 | best_bleu 30.5857 (progress_bar.py:269, print())
[2021-11-13 11:15:30]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 38 @ 24469 updates, score 30.585689) (writing took 14.459629 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:15:51]    INFO >> epoch 039:     31 / 644 loss=4.017, nll_loss=1.96, ppl=3.89, wps=1084.4, ups=1.47, wpb=738.7, bsz=16, num_updates=24500, lr=4.9e-05, gnorm=4.438, clip=0, loss_scale=32, train_wall=208, gb_free=28.7, wall=15891 (progress_bar.py:260, log())
[2021-11-13 11:19:30]    INFO >> epoch 039:    531 / 644 loss=3.897, nll_loss=1.835, ppl=3.57, wps=1680.6, ups=2.28, wpb=737.6, bsz=16, num_updates=25000, lr=4.9e-05, gnorm=4.239, clip=0, loss_scale=32, train_wall=218, gb_free=28.7, wall=16111 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:20:32]    INFO >> epoch 039 | loss 3.92 | nll_loss 1.861 | ppl 3.63 | wps 1154.3 | ups 1.57 | wpb 736.8 | bsz 16 | num_updates 25113 | lr 4.9e-05 | gnorm 4.274 | clip 0 | loss_scale 32 | train_wall 278 | gb_free 28.7 | wall 16173 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:21:52]    INFO >> epoch 039 | valid on 'valid' subset | loss 4.786 | nll_loss 2.795 | ppl 6.94 | bleu 31.2943 | wps 315.3 | wpb 3065.4 | bsz 62.5 | num_updates 25113 | best_bleu 31.2943 (progress_bar.py:269, print())
[2021-11-13 11:22:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 39 @ 25113 updates, score 31.294312) (writing took 12.376928 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:25:01]    INFO >> epoch 040:    387 / 644 loss=3.832, nll_loss=1.771, ppl=3.41, wps=1106.3, ups=1.51, wpb=730.9, bsz=16, num_updates=25500, lr=4.9e-05, gnorm=4.112, clip=0, loss_scale=64, train_wall=215, gb_free=28.7, wall=16441 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:26:57]    INFO >> epoch 040 | loss 3.822 | nll_loss 1.763 | ppl 3.39 | wps 1234.9 | ups 1.68 | wpb 736.8 | bsz 16 | num_updates 25757 | lr 4.9e-05 | gnorm 4.082 | clip 0 | loss_scale 64 | train_wall 268 | gb_free 28.7 | wall 16557 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:28:18]    INFO >> epoch 040 | valid on 'valid' subset | loss 4.775 | nll_loss 2.781 | ppl 6.87 | bleu 31.8922 | wps 300.1 | wpb 3065.4 | bsz 62.5 | num_updates 25757 | best_bleu 31.8922 (progress_bar.py:269, print())
[2021-11-13 11:28:30]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 40 @ 25757 updates, score 31.892171) (writing took 12.333720 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:30:23]    INFO >> epoch 041:    243 / 644 loss=3.835, nll_loss=1.781, ppl=3.44, wps=1169.1, ups=1.55, wpb=754, bsz=16, num_updates=26000, lr=4.9e-05, gnorm=4.032, clip=0, loss_scale=64, train_wall=205, gb_free=28, wall=16764 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:33:15]    INFO >> epoch 041 | loss 3.753 | nll_loss 1.692 | ppl 3.23 | wps 1254.2 | ups 1.7 | wpb 736.8 | bsz 16 | num_updates 26401 | lr 4.9e-05 | gnorm 3.957 | clip 0 | loss_scale 64 | train_wall 260 | gb_free 28.7 | wall 16935 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:34:29]    INFO >> epoch 041 | valid on 'valid' subset | loss 4.779 | nll_loss 2.77 | ppl 6.82 | bleu 31.9644 | wps 343.3 | wpb 3065.4 | bsz 62.5 | num_updates 26401 | best_bleu 31.9644 (progress_bar.py:269, print())
[2021-11-13 11:34:42]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 41 @ 26401 updates, score 31.964429) (writing took 12.521871 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:35:31]    INFO >> epoch 042:     99 / 644 loss=3.725, nll_loss=1.663, ppl=3.17, wps=1163.4, ups=1.62, wpb=716.6, bsz=16, num_updates=26500, lr=4.9e-05, gnorm=3.983, clip=0, loss_scale=64, train_wall=197, gb_free=28.7, wall=17072 (progress_bar.py:260, log())
[2021-11-13 11:38:48]    INFO >> epoch 042:    599 / 644 loss=3.682, nll_loss=1.619, ppl=3.07, wps=1885.6, ups=2.54, wpb=741.4, bsz=16, num_updates=27000, lr=4.9e-05, gnorm=3.833, clip=0, loss_scale=64, train_wall=195, gb_free=28.7, wall=17268 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:39:13]    INFO >> epoch 042 | loss 3.697 | nll_loss 1.636 | ppl 3.11 | wps 1326.4 | ups 1.8 | wpb 736.8 | bsz 16 | num_updates 27045 | lr 4.9e-05 | gnorm 3.86 | clip 0 | loss_scale 64 | train_wall 247 | gb_free 28.7 | wall 17293 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:40:31]    INFO >> epoch 042 | valid on 'valid' subset | loss 4.722 | nll_loss 2.742 | ppl 6.69 | bleu 32.2716 | wps 317.6 | wpb 3065.4 | bsz 62.5 | num_updates 27045 | best_bleu 32.2716 (progress_bar.py:269, print())
[2021-11-13 11:40:45]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 42 @ 27045 updates, score 32.271556) (writing took 14.779739 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:43:51]    INFO >> epoch 043:    455 / 644 loss=3.639, nll_loss=1.578, ppl=2.99, wps=1221.5, ups=1.65, wpb=741.9, bsz=16, num_updates=27500, lr=4.9e-05, gnorm=3.715, clip=0, loss_scale=128, train_wall=187, gb_free=28.7, wall=17572 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:45:27]    INFO >> epoch 043 | loss 3.608 | nll_loss 1.544 | ppl 2.92 | wps 1268.1 | ups 1.72 | wpb 736.8 | bsz 16 | num_updates 27689 | lr 4.9e-05 | gnorm 3.679 | clip 0 | loss_scale 128 | train_wall 257 | gb_free 28.7 | wall 17667 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:46:43]    INFO >> epoch 043 | valid on 'valid' subset | loss 4.698 | nll_loss 2.716 | ppl 6.57 | bleu 32.8871 | wps 328.1 | wpb 3065.4 | bsz 62.5 | num_updates 27689 | best_bleu 32.8871 (progress_bar.py:269, print())
[2021-11-13 11:46:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 43 @ 27689 updates, score 32.88707) (writing took 14.698909 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:47:48]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 11:47:48]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
[2021-11-13 11:49:22]    INFO >> epoch 044:    312 / 644 loss=3.581, nll_loss=1.514, ppl=2.86, wps=1120, ups=1.51, wpb=741.6, bsz=16, num_updates=28000, lr=4.9e-05, gnorm=3.659, clip=0, loss_scale=64, train_wall=216, gb_free=28.7, wall=17903 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:52:02]    INFO >> epoch 044 | loss 3.579 | nll_loss 1.514 | ppl 2.86 | wps 1197 | ups 1.63 | wpb 735.8 | bsz 16 | num_updates 28332 | lr 4.9e-05 | gnorm 3.715 | clip 0 | loss_scale 64 | train_wall 280 | gb_free 28.7 | wall 18063 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:53:14]    INFO >> epoch 044 | valid on 'valid' subset | loss 4.731 | nll_loss 2.741 | ppl 6.69 | bleu 33.1532 | wps 346.6 | wpb 3065.4 | bsz 62.5 | num_updates 28332 | best_bleu 33.1532 (progress_bar.py:269, print())
[2021-11-13 11:53:27]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 44 @ 28332 updates, score 33.153198) (writing took 12.301815 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 11:54:47]    INFO >> AMP: overflow detected, setting scale to to 32.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 11:54:49]    INFO >> epoch 045:    168 / 644 loss=3.579, nll_loss=1.517, ppl=2.86, wps=1119.2, ups=1.53, wpb=730.2, bsz=16, num_updates=28500, lr=4.9e-05, gnorm=3.767, clip=0, loss_scale=32, train_wall=217, gb_free=28.7, wall=18229 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:58:31]    INFO >> epoch 045 | loss 3.566 | nll_loss 1.503 | ppl 2.83 | wps 1219.4 | ups 1.65 | wpb 736.8 | bsz 16 | num_updates 28976 | lr 4.9e-05 | gnorm 3.773 | clip 0 | loss_scale 32 | train_wall 280 | gb_free 28.7 | wall 18452 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 11:59:51]    INFO >> epoch 045 | valid on 'valid' subset | loss 4.706 | nll_loss 2.731 | ppl 6.64 | bleu 32.0513 | wps 316.5 | wpb 3065.4 | bsz 62.5 | num_updates 28976 | best_bleu 33.1532 (progress_bar.py:269, print())
[2021-11-13 11:59:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 45 @ 28976 updates, score 32.051251) (writing took 7.292469 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:00:17]    INFO >> epoch 046:     24 / 644 loss=3.56, nll_loss=1.497, ppl=2.82, wps=1114.9, ups=1.52, wpb=733.3, bsz=16, num_updates=29000, lr=4.9e-05, gnorm=3.771, clip=0, loss_scale=32, train_wall=217, gb_free=28.7, wall=18558 (progress_bar.py:260, log())
[2021-11-13 12:03:57]    INFO >> epoch 046:    524 / 644 loss=3.54, nll_loss=1.479, ppl=2.79, wps=1710.2, ups=2.27, wpb=752.4, bsz=16, num_updates=29500, lr=4.9e-05, gnorm=3.676, clip=0, loss_scale=32, train_wall=219, gb_free=28.7, wall=18778 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:05:04]    INFO >> epoch 046 | loss 3.518 | nll_loss 1.456 | ppl 2.74 | wps 1207 | ups 1.64 | wpb 736.8 | bsz 16 | num_updates 29620 | lr 4.9e-05 | gnorm 3.7 | clip 0 | loss_scale 32 | train_wall 281 | gb_free 28.7 | wall 18845 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:06:25]    INFO >> epoch 046 | valid on 'valid' subset | loss 4.696 | nll_loss 2.72 | ppl 6.59 | bleu 33.318 | wps 318.3 | wpb 3065.4 | bsz 62.5 | num_updates 29620 | best_bleu 33.318 (progress_bar.py:269, print())
[2021-11-13 12:06:37]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 46 @ 29620 updates, score 33.317964) (writing took 12.174963 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:09:20]    INFO >> epoch 047:    380 / 644 loss=3.446, nll_loss=1.379, ppl=2.6, wps=1112.1, ups=1.55, wpb=717.4, bsz=16, num_updates=30000, lr=4.9e-05, gnorm=3.636, clip=0, loss_scale=32, train_wall=204, gb_free=28.7, wall=19101 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:11:20]    INFO >> epoch 047 | loss 3.472 | nll_loss 1.41 | ppl 2.66 | wps 1263.3 | ups 1.71 | wpb 736.8 | bsz 16 | num_updates 30264 | lr 4.9e-05 | gnorm 3.614 | clip 0 | loss_scale 32 | train_wall 257 | gb_free 28.3 | wall 19221 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:12:30]    INFO >> epoch 047 | valid on 'valid' subset | loss 4.651 | nll_loss 2.687 | ppl 6.44 | bleu 32.6295 | wps 358.2 | wpb 3065.4 | bsz 62.5 | num_updates 30264 | best_bleu 33.318 (progress_bar.py:269, print())
[2021-11-13 12:12:38]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 47 @ 30264 updates, score 32.629478) (writing took 7.598052 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:14:03]    INFO >> epoch 048:    236 / 644 loss=3.447, nll_loss=1.383, ppl=2.61, wps=1305, ups=1.76, wpb=739.6, bsz=16, num_updates=30500, lr=4.9e-05, gnorm=3.587, clip=0, loss_scale=64, train_wall=182, gb_free=28.7, wall=19384 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:17:03]    INFO >> epoch 048 | loss 3.408 | nll_loss 1.344 | ppl 2.54 | wps 1384.6 | ups 1.88 | wpb 736.8 | bsz 16 | num_updates 30908 | lr 4.9e-05 | gnorm 3.489 | clip 0 | loss_scale 64 | train_wall 241 | gb_free 28.7 | wall 19563 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:18:09]    INFO >> epoch 048 | valid on 'valid' subset | loss 4.617 | nll_loss 2.663 | ppl 6.33 | bleu 34.7041 | wps 379.6 | wpb 3065.4 | bsz 62.5 | num_updates 30908 | best_bleu 34.7041 (progress_bar.py:269, print())
[2021-11-13 12:18:21]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 48 @ 30908 updates, score 34.70405) (writing took 11.765428 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:19:00]    INFO >> epoch 049:     92 / 644 loss=3.409, nll_loss=1.346, ppl=2.54, wps=1246.5, ups=1.68, wpb=739.8, bsz=16, num_updates=31000, lr=4.9e-05, gnorm=3.454, clip=0, loss_scale=64, train_wall=195, gb_free=28.7, wall=19681 (progress_bar.py:260, log())
[2021-11-13 12:22:39]    INFO >> epoch 049:    592 / 644 loss=3.355, nll_loss=1.288, ppl=2.44, wps=1687.8, ups=2.28, wpb=739.7, bsz=16, num_updates=31500, lr=4.8e-05, gnorm=3.348, clip=0, loss_scale=64, train_wall=218, gb_free=28.7, wall=19900 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:23:17]    INFO >> epoch 049 | loss 3.36 | nll_loss 1.293 | ppl 2.45 | wps 1268.1 | ups 1.72 | wpb 736.8 | bsz 16 | num_updates 31552 | lr 4.8e-05 | gnorm 3.367 | clip 0 | loss_scale 64 | train_wall 272 | gb_free 28.7 | wall 19938 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:24:26]    INFO >> epoch 049 | valid on 'valid' subset | loss 4.617 | nll_loss 2.685 | ppl 6.43 | bleu 33.7251 | wps 356 | wpb 3065.4 | bsz 62.5 | num_updates 31552 | best_bleu 34.7041 (progress_bar.py:269, print())
[2021-11-13 12:24:34]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 49 @ 31552 updates, score 33.725051) (writing took 7.610614 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:27:49]    INFO >> epoch 050:    448 / 644 loss=3.311, nll_loss=1.242, ppl=2.37, wps=1196.7, ups=1.61, wpb=741.3, bsz=16, num_updates=32000, lr=4.8e-05, gnorm=3.329, clip=0, loss_scale=64, train_wall=209, gb_free=28.7, wall=20210 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:29:29]    INFO >> epoch 050 | loss 3.321 | nll_loss 1.254 | ppl 2.38 | wps 1273.9 | ups 1.73 | wpb 736.8 | bsz 16 | num_updates 32196 | lr 4.8e-05 | gnorm 3.322 | clip 0 | loss_scale 64 | train_wall 272 | gb_free 28.7 | wall 20310 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:30:33]    INFO >> epoch 050 | valid on 'valid' subset | loss 4.656 | nll_loss 2.682 | ppl 6.42 | bleu 33.8369 | wps 394.4 | wpb 3065.4 | bsz 62.5 | num_updates 32196 | best_bleu 34.7041 (progress_bar.py:269, print())
[2021-11-13 12:30:41]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 50 @ 32196 updates, score 33.836907) (writing took 7.551329 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:32:54]    INFO >> epoch 051:    304 / 644 loss=3.306, nll_loss=1.237, ppl=2.36, wps=1187.3, ups=1.64, wpb=723.6, bsz=16, num_updates=32500, lr=4.8e-05, gnorm=3.275, clip=0, loss_scale=128, train_wall=209, gb_free=28.7, wall=20514 (progress_bar.py:260, log())
[2021-11-13 12:34:14]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:35:39]    INFO >> epoch 051 | loss 3.275 | nll_loss 1.206 | ppl 2.31 | wps 1284.5 | ups 1.74 | wpb 736.8 | bsz 16 | num_updates 32840 | lr 4.8e-05 | gnorm 3.217 | clip 0 | loss_scale 64 | train_wall 274 | gb_free 28.7 | wall 20679 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:36:46]    INFO >> epoch 051 | valid on 'valid' subset | loss 4.572 | nll_loss 2.622 | ppl 6.15 | bleu 34.3418 | wps 397.6 | wpb 3065.4 | bsz 62.5 | num_updates 32840 | best_bleu 34.7041 (progress_bar.py:269, print())
[2021-11-13 12:36:54]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 51 @ 32840 updates, score 34.341785) (writing took 7.524729 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:38:13]    INFO >> epoch 052:    160 / 644 loss=3.275, nll_loss=1.208, ppl=2.31, wps=1165.6, ups=1.57, wpb=743.6, bsz=16, num_updates=33000, lr=4.8e-05, gnorm=3.223, clip=0, loss_scale=64, train_wall=219, gb_free=28.7, wall=20833 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:41:53]    INFO >> epoch 052 | loss 3.248 | nll_loss 1.179 | ppl 2.26 | wps 1269.3 | ups 1.72 | wpb 736.8 | bsz 16 | num_updates 33484 | lr 4.8e-05 | gnorm 3.203 | clip 0 | loss_scale 64 | train_wall 274 | gb_free 28.7 | wall 21053 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:43:08]    INFO >> epoch 052 | valid on 'valid' subset | loss 4.59 | nll_loss 2.647 | ppl 6.26 | bleu 34.0305 | wps 334.7 | wpb 3065.4 | bsz 62.5 | num_updates 33484 | best_bleu 34.7041 (progress_bar.py:269, print())
[2021-11-13 12:43:16]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 52 @ 33484 updates, score 34.030473) (writing took 7.610009 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:43:30]    INFO >> epoch 053:     16 / 644 loss=3.253, nll_loss=1.186, ppl=2.27, wps=1167.5, ups=1.58, wpb=741, bsz=16, num_updates=33500, lr=4.8e-05, gnorm=3.19, clip=0, loss_scale=64, train_wall=210, gb_free=28.7, wall=21151 (progress_bar.py:260, log())
[2021-11-13 12:46:47]    INFO >> epoch 053:    516 / 644 loss=3.201, nll_loss=1.13, ppl=2.19, wps=1863.8, ups=2.54, wpb=734.6, bsz=16, num_updates=34000, lr=4.8e-05, gnorm=3.103, clip=0, loss_scale=64, train_wall=196, gb_free=28.7, wall=21348 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:47:45]    INFO >> epoch 053 | loss 3.213 | nll_loss 1.142 | ppl 2.21 | wps 1346.1 | ups 1.83 | wpb 736.8 | bsz 16 | num_updates 34128 | lr 4.8e-05 | gnorm 3.118 | clip 0 | loss_scale 64 | train_wall 245 | gb_free 28.7 | wall 21406 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:48:54]    INFO >> epoch 053 | valid on 'valid' subset | loss 4.592 | nll_loss 2.645 | ppl 6.26 | bleu 34.5736 | wps 369.9 | wpb 3065.4 | bsz 62.5 | num_updates 34128 | best_bleu 34.7041 (progress_bar.py:269, print())
[2021-11-13 12:49:02]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 53 @ 34128 updates, score 34.573567) (writing took 7.598432 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:51:36]    INFO >> epoch 054:    372 / 644 loss=3.175, nll_loss=1.101, ppl=2.15, wps=1262.3, ups=1.73, wpb=729.1, bsz=16, num_updates=34500, lr=4.8e-05, gnorm=3.106, clip=0, loss_scale=64, train_wall=188, gb_free=27.9, wall=21636 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:53:50]    INFO >> epoch 054 | loss 3.184 | nll_loss 1.114 | ppl 2.16 | wps 1302.9 | ups 1.77 | wpb 736.8 | bsz 16 | num_updates 34772 | lr 4.8e-05 | gnorm 3.106 | clip 0 | loss_scale 128 | train_wall 263 | gb_free 28.7 | wall 21770 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 12:54:52]    INFO >> epoch 054 | valid on 'valid' subset | loss 4.548 | nll_loss 2.601 | ppl 6.07 | bleu 35.3992 | wps 412.5 | wpb 3065.4 | bsz 62.5 | num_updates 34772 | best_bleu 35.3992 (progress_bar.py:269, print())
[2021-11-13 12:55:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 54 @ 34772 updates, score 35.399163) (writing took 12.345185 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 12:56:53]    INFO >> epoch 055:    228 / 644 loss=3.187, nll_loss=1.119, ppl=2.17, wps=1181.9, ups=1.58, wpb=748.5, bsz=16, num_updates=35000, lr=4.8e-05, gnorm=3.062, clip=0, loss_scale=128, train_wall=217, gb_free=28.7, wall=21953 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:00:09]    INFO >> epoch 055 | loss 3.122 | nll_loss 1.049 | ppl 2.07 | wps 1250.7 | ups 1.7 | wpb 736.8 | bsz 16 | num_updates 35416 | lr 4.8e-05 | gnorm 2.925 | clip 0 | loss_scale 128 | train_wall 280 | gb_free 28.7 | wall 22149 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:01:15]    INFO >> epoch 055 | valid on 'valid' subset | loss 4.572 | nll_loss 2.607 | ppl 6.09 | bleu 34.2873 | wps 388.6 | wpb 3065.4 | bsz 62.5 | num_updates 35416 | best_bleu 35.3992 (progress_bar.py:269, print())
[2021-11-13 13:01:23]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 55 @ 35416 updates, score 34.287295) (writing took 7.475992 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:02:05]    INFO >> epoch 056:     84 / 644 loss=3.117, nll_loss=1.046, ppl=2.06, wps=1166.5, ups=1.6, wpb=729.5, bsz=16, num_updates=35500, lr=4.8e-05, gnorm=2.89, clip=0, loss_scale=128, train_wall=214, gb_free=28.7, wall=22266 (progress_bar.py:260, log())
[2021-11-13 13:02:37]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 13:02:37]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
[2021-11-13 13:05:48]    INFO >> epoch 056:    585 / 644 loss=3.095, nll_loss=1.021, ppl=2.03, wps=1649.7, ups=2.25, wpb=734.6, bsz=16, num_updates=36000, lr=4.8e-05, gnorm=2.954, clip=0, loss_scale=64, train_wall=222, gb_free=28.7, wall=22488 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:06:29]    INFO >> epoch 056 | loss 3.114 | nll_loss 1.041 | ppl 2.06 | wps 1243.7 | ups 1.69 | wpb 735 | bsz 16 | num_updates 36059 | lr 4.8e-05 | gnorm 2.955 | clip 0 | loss_scale 64 | train_wall 281 | gb_free 28.6 | wall 22529 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:07:31]    INFO >> epoch 056 | valid on 'valid' subset | loss 4.567 | nll_loss 2.611 | ppl 6.11 | bleu 35.5382 | wps 408.1 | wpb 3065.4 | bsz 62.5 | num_updates 36059 | best_bleu 35.5382 (progress_bar.py:269, print())
[2021-11-13 13:07:43]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 56 @ 36059 updates, score 35.538208) (writing took 12.097090 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:10:52]    INFO >> epoch 057:    441 / 644 loss=3.109, nll_loss=1.04, ppl=2.06, wps=1217.5, ups=1.64, wpb=740.9, bsz=16, num_updates=36500, lr=4.8e-05, gnorm=2.975, clip=0, loss_scale=64, train_wall=206, gb_free=28.7, wall=22793 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:12:35]    INFO >> epoch 057 | loss 3.103 | nll_loss 1.033 | ppl 2.05 | wps 1295.1 | ups 1.76 | wpb 736.8 | bsz 16 | num_updates 36703 | lr 4.8e-05 | gnorm 2.971 | clip 0 | loss_scale 64 | train_wall 268 | gb_free 28.7 | wall 22896 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:13:30]    INFO >> epoch 057 | valid on 'valid' subset | loss 4.529 | nll_loss 2.614 | ppl 6.12 | bleu 34.6978 | wps 477.1 | wpb 3065.4 | bsz 62.5 | num_updates 36703 | best_bleu 35.5382 (progress_bar.py:269, print())
[2021-11-13 13:13:38]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 57 @ 36703 updates, score 34.697841) (writing took 8.218346 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:15:31]    INFO >> epoch 058:    297 / 644 loss=3.101, nll_loss=1.031, ppl=2.04, wps=1320.3, ups=1.79, wpb=736.7, bsz=16, num_updates=37000, lr=4.8e-05, gnorm=2.941, clip=0, loss_scale=64, train_wall=192, gb_free=28.7, wall=23072 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:18:04]    INFO >> epoch 058 | loss 3.078 | nll_loss 1.007 | ppl 2.01 | wps 1444 | ups 1.96 | wpb 736.8 | bsz 16 | num_updates 37347 | lr 4.8e-05 | gnorm 2.921 | clip 0 | loss_scale 64 | train_wall 241 | gb_free 28.7 | wall 23224 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:18:57]    INFO >> epoch 058 | valid on 'valid' subset | loss 4.528 | nll_loss 2.601 | ppl 6.07 | bleu 35.6682 | wps 491.6 | wpb 3065.4 | bsz 62.5 | num_updates 37347 | best_bleu 35.6682 (progress_bar.py:269, print())
[2021-11-13 13:19:09]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 58 @ 37347 updates, score 35.668199) (writing took 11.736719 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:20:08]    INFO >> epoch 059:    153 / 644 loss=3.052, nll_loss=0.979, ppl=1.97, wps=1324.3, ups=1.81, wpb=732.4, bsz=16, num_updates=37500, lr=4.8e-05, gnorm=2.894, clip=0, loss_scale=64, train_wall=188, gb_free=28.7, wall=23348 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:23:37]    INFO >> epoch 059 | loss 3.032 | nll_loss 0.96 | ppl 1.95 | wps 1426.4 | ups 1.94 | wpb 736.8 | bsz 16 | num_updates 37991 | lr 4.8e-05 | gnorm 2.776 | clip 0 | loss_scale 128 | train_wall 244 | gb_free 28.7 | wall 23557 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:24:43]    INFO >> epoch 059 | valid on 'valid' subset | loss 4.494 | nll_loss 2.567 | ppl 5.93 | bleu 36.2896 | wps 406.2 | wpb 3065.4 | bsz 62.5 | num_updates 37991 | best_bleu 36.2896 (progress_bar.py:269, print())
[2021-11-13 13:24:56]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 59 @ 37991 updates, score 36.289618) (writing took 13.856257 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:25:08]    INFO >> epoch 060:      9 / 644 loss=3.044, nll_loss=0.973, ppl=1.96, wps=1232, ups=1.66, wpb=740.6, bsz=16, num_updates=38000, lr=4.8e-05, gnorm=2.768, clip=0, loss_scale=128, train_wall=196, gb_free=28.7, wall=23649 (progress_bar.py:260, log())
[2021-11-13 13:27:56]    INFO >> epoch 060:    509 / 644 loss=2.989, nll_loss=0.913, ppl=1.88, wps=2199.8, ups=2.98, wpb=737.7, bsz=16, num_updates=38500, lr=4.8e-05, gnorm=2.652, clip=0, loss_scale=128, train_wall=167, gb_free=28.7, wall=23816 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:28:50]    INFO >> epoch 060 | loss 2.989 | nll_loss 0.915 | ppl 1.89 | wps 1512.9 | ups 2.05 | wpb 736.8 | bsz 16 | num_updates 38635 | lr 4.8e-05 | gnorm 2.649 | clip 0 | loss_scale 128 | train_wall 209 | gb_free 28.7 | wall 23871 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:29:44]    INFO >> epoch 060 | valid on 'valid' subset | loss 4.488 | nll_loss 2.572 | ppl 5.95 | bleu 35.7464 | wps 521 | wpb 3065.4 | bsz 62.5 | num_updates 38635 | best_bleu 36.2896 (progress_bar.py:269, print())
[2021-11-13 13:29:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 60 @ 38635 updates, score 35.746431) (writing took 6.985269 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:32:05]    INFO >> epoch 061:    365 / 644 loss=2.972, nll_loss=0.899, ppl=1.86, wps=1467.5, ups=2.01, wpb=731.1, bsz=16, num_updates=39000, lr=4.8e-05, gnorm=2.643, clip=0, loss_scale=128, train_wall=163, gb_free=28.7, wall=24066 (progress_bar.py:260, log())
[2021-11-13 13:33:31]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:33:51]    INFO >> epoch 061 | loss 2.971 | nll_loss 0.898 | ppl 1.86 | wps 1575.9 | ups 2.14 | wpb 736.8 | bsz 16 | num_updates 39279 | lr 4.8e-05 | gnorm 2.648 | clip 0 | loss_scale 64 | train_wall 214 | gb_free 28.7 | wall 24172 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:34:56]    INFO >> epoch 061 | valid on 'valid' subset | loss 4.533 | nll_loss 2.618 | ppl 6.14 | bleu 36.1011 | wps 399.3 | wpb 3065.4 | bsz 62.5 | num_updates 39279 | best_bleu 36.2896 (progress_bar.py:269, print())
[2021-11-13 13:35:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 61 @ 39279 updates, score 36.101123) (writing took 7.786923 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:36:25]    INFO >> epoch 062:    221 / 644 loss=3, nll_loss=0.93, ppl=1.91, wps=1437.6, ups=1.92, wpb=747.5, bsz=16, num_updates=39500, lr=4.8e-05, gnorm=2.706, clip=0, loss_scale=64, train_wall=163, gb_free=27.5, wall=24326 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:38:48]    INFO >> epoch 062 | loss 2.985 | nll_loss 0.912 | ppl 1.88 | wps 1598.3 | ups 2.17 | wpb 736.8 | bsz 16 | num_updates 39923 | lr 4.8e-05 | gnorm 2.774 | clip 0 | loss_scale 64 | train_wall 200 | gb_free 28.7 | wall 24469 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[/home/wanyao/anaconda3/envs/py38-1.8/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 68 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
   INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 62 @ 39923 updates, score 35.963765) (writing took 10.845969 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:40:26]    INFO >> epoch 063:     77 / 644 loss=2.95, nll_loss=0.875, ppl=1.83, wps=1512.2, ups=2.08, wpb=728.8, bsz=16, num_updates=40000, lr=4.8e-05, gnorm=2.753, clip=0, loss_scale=64, train_wall=152, gb_free=28.7, wall=24567 (progress_bar.py:260, log())
[2021-11-13 13:43:16]    INFO >> epoch 063:    577 / 644 loss=2.972, nll_loss=0.901, ppl=1.87, wps=2165.6, ups=2.95, wpb=735.3, bsz=16, num_updates=40500, lr=4.8e-05, gnorm=2.735, clip=0, loss_scale=64, train_wall=169, gb_free=28.7, wall=24736 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:43:48]    INFO >> epoch 063 | loss 2.971 | nll_loss 0.9 | ppl 1.87 | wps 1582.7 | ups 2.15 | wpb 736.8 | bsz 16 | num_updates 40567 | lr 4.8e-05 | gnorm 2.725 | clip 0 | loss_scale 64 | train_wall 210 | gb_free 28.7 | wall 24769 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:44:44]    INFO >> epoch 063 | valid on 'valid' subset | loss 4.512 | nll_loss 2.575 | ppl 5.96 | bleu 35.9734 | wps 490.9 | wpb 3065.4 | bsz 62.5 | num_updates 40567 | best_bleu 36.2896 (progress_bar.py:269, print())
[2021-11-13 13:44:52]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 63 @ 40567 updates, score 35.973411) (writing took 7.807132 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:47:22]    INFO >> epoch 064:    433 / 644 loss=2.959, nll_loss=0.887, ppl=1.85, wps=1504, ups=2.03, wpb=740.7, bsz=16, num_updates=41000, lr=4.8e-05, gnorm=2.692, clip=0, loss_scale=64, train_wall=158, gb_free=28.7, wall=24983 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:48:47]    INFO >> epoch 064 | loss 2.948 | nll_loss 0.875 | ppl 1.83 | wps 1587.1 | ups 2.15 | wpb 736.8 | bsz 16 | num_updates 41211 | lr 4.8e-05 | gnorm 2.667 | clip 0 | loss_scale 64 | train_wall 211 | gb_free 28.7 | wall 25068 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:49:47]    INFO >> epoch 064 | valid on 'valid' subset | loss 4.491 | nll_loss 2.566 | ppl 5.92 | bleu 36.7327 | wps 456.7 | wpb 3065.4 | bsz 62.5 | num_updates 41211 | best_bleu 36.7327 (progress_bar.py:269, print())
[2021-11-13 13:50:00]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 64 @ 41211 updates, score 36.732673) (writing took 13.837533 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:51:44]    INFO >> epoch 065:    289 / 644 loss=2.923, nll_loss=0.853, ppl=1.81, wps=1409.6, ups=1.91, wpb=738.1, bsz=16, num_updates=41500, lr=4.8e-05, gnorm=2.585, clip=0, loss_scale=128, train_wall=164, gb_free=28.6, wall=25244 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:53:54]    INFO >> epoch 065 | loss 2.903 | nll_loss 0.831 | ppl 1.78 | wps 1544.1 | ups 2.1 | wpb 736.8 | bsz 16 | num_updates 41855 | lr 4.8e-05 | gnorm 2.546 | clip 0 | loss_scale 128 | train_wall 210 | gb_free 28.7 | wall 25375 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:54:51]    INFO >> epoch 065 | valid on 'valid' subset | loss 4.474 | nll_loss 2.55 | ppl 5.86 | bleu 36.9212 | wps 472.8 | wpb 3065.4 | bsz 62.5 | num_updates 41855 | best_bleu 36.9212 (progress_bar.py:269, print())
[2021-11-13 13:55:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 65 @ 41855 updates, score 36.921214) (writing took 13.444211 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 13:55:52]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 13:56:01]    INFO >> epoch 066:    145 / 644 loss=2.894, nll_loss=0.821, ppl=1.77, wps=1434.9, ups=1.94, wpb=737.8, bsz=16, num_updates=42000, lr=4.8e-05, gnorm=2.512, clip=0, loss_scale=64, train_wall=163, gb_free=28.7, wall=25501 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 13:58:59]    INFO >> epoch 066 | loss 2.902 | nll_loss 0.829 | ppl 1.78 | wps 1559.4 | ups 2.12 | wpb 736.8 | bsz 16 | num_updates 42499 | lr 4.8e-05 | gnorm 2.559 | clip 0 | loss_scale 64 | train_wall 210 | gb_free 28.7 | wall 25679 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:00:00]    INFO >> epoch 066 | valid on 'valid' subset | loss 4.479 | nll_loss 2.565 | ppl 5.92 | bleu 37.0136 | wps 479.9 | wpb 3065.4 | bsz 62.5 | num_updates 42499 | best_bleu 37.0136 (progress_bar.py:269, print())
[2021-11-13 14:00:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 66 @ 42499 updates, score 37.013566) (writing took 14.172143 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:00:22]    INFO >> epoch 067:      1 / 644 loss=2.909, nll_loss=0.836, ppl=1.78, wps=1404.5, ups=1.91, wpb=734.1, bsz=16, num_updates=42500, lr=4.8e-05, gnorm=2.594, clip=0, loss_scale=64, train_wall=162, gb_free=27.4, wall=25763 (progress_bar.py:260, log())
[2021-11-13 14:03:09]    INFO >> epoch 067:    501 / 644 loss=2.91, nll_loss=0.841, ppl=1.79, wps=2227.9, ups=2.99, wpb=744.2, bsz=16, num_updates=43000, lr=4.8e-05, gnorm=2.58, clip=0, loss_scale=64, train_wall=166, gb_free=27.4, wall=25930 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:04:05]    INFO >> epoch 067 | loss 2.894 | nll_loss 0.824 | ppl 1.77 | wps 1551.3 | ups 2.11 | wpb 736.8 | bsz 16 | num_updates 43143 | lr 4.8e-05 | gnorm 2.563 | clip 0 | loss_scale 64 | train_wall 206 | gb_free 28.7 | wall 25985 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:05:09]    INFO >> epoch 067 | valid on 'valid' subset | loss 4.483 | nll_loss 2.565 | ppl 5.92 | bleu 36.4773 | wps 401.1 | wpb 3065.4 | bsz 62.5 | num_updates 43143 | best_bleu 37.0136 (progress_bar.py:269, print())
[2021-11-13 14:05:17]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 67 @ 43143 updates, score 36.477293) (writing took 7.771320 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:07:24]    INFO >> epoch 068:    357 / 644 loss=2.878, nll_loss=0.805, ppl=1.75, wps=1462.4, ups=1.96, wpb=746.1, bsz=16, num_updates=43500, lr=4.8e-05, gnorm=2.533, clip=0, loss_scale=64, train_wall=159, gb_free=28.7, wall=26185 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:09:05]    INFO >> epoch 068 | loss 2.877 | nll_loss 0.805 | ppl 1.75 | wps 1580.2 | ups 2.14 | wpb 736.8 | bsz 16 | num_updates 43787 | lr 4.8e-05 | gnorm 2.524 | clip 0 | loss_scale 64 | train_wall 204 | gb_free 28.7 | wall 26286 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:09:59]    INFO >> epoch 068 | valid on 'valid' subset | loss 4.468 | nll_loss 2.558 | ppl 5.89 | bleu 35.8312 | wps 481.5 | wpb 3065.4 | bsz 62.5 | num_updates 43787 | best_bleu 37.0136 (progress_bar.py:269, print())
[2021-11-13 14:10:10]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 68 @ 43787 updates, score 35.831176) (writing took 10.998522 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:11:23]    INFO >> epoch 069:    213 / 644 loss=2.84, nll_loss=0.767, ppl=1.7, wps=1488.9, ups=2.09, wpb=711.6, bsz=16, num_updates=44000, lr=4.8e-05, gnorm=2.496, clip=0, loss_scale=128, train_wall=149, gb_free=28.7, wall=26424 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:14:00]    INFO >> epoch 069 | loss 2.843 | nll_loss 0.772 | ppl 1.71 | wps 1610 | ups 2.18 | wpb 736.8 | bsz 16 | num_updates 44431 | lr 4.8e-05 | gnorm 2.428 | clip 0 | loss_scale 128 | train_wall 205 | gb_free 28.7 | wall 26580 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:14:57]    INFO >> epoch 069 | valid on 'valid' subset | loss 4.432 | nll_loss 2.545 | ppl 5.84 | bleu 36.943 | wps 459 | wpb 3065.4 | bsz 62.5 | num_updates 44431 | best_bleu 37.0136 (progress_bar.py:269, print())
[2021-11-13 14:15:07]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 69 @ 44431 updates, score 36.942952) (writing took 9.974252 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:15:39]    INFO >> epoch 070:     69 / 644 loss=2.842, nll_loss=0.773, ppl=1.71, wps=1453.8, ups=1.95, wpb=743.7, bsz=16, num_updates=44500, lr=4.8e-05, gnorm=2.388, clip=0, loss_scale=128, train_wall=164, gb_free=28.7, wall=26680 (progress_bar.py:260, log())
[2021-11-13 14:18:30]    INFO >> epoch 070:    569 / 644 loss=2.816, nll_loss=0.744, ppl=1.67, wps=2173.9, ups=2.92, wpb=743.3, bsz=16, num_updates=45000, lr=4.8e-05, gnorm=2.293, clip=0, loss_scale=128, train_wall=170, gb_free=28.7, wall=26851 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:19:04]    INFO >> epoch 070 | loss 2.81 | nll_loss 0.739 | ppl 1.67 | wps 1559.6 | ups 2.12 | wpb 736.8 | bsz 16 | num_updates 45075 | lr 4.8e-05 | gnorm 2.307 | clip 0 | loss_scale 128 | train_wall 212 | gb_free 28.7 | wall 26885 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:19:59]    INFO >> epoch 070 | valid on 'valid' subset | loss 4.443 | nll_loss 2.541 | ppl 5.82 | bleu 37.0309 | wps 484.9 | wpb 3065.4 | bsz 62.5 | num_updates 45075 | best_bleu 37.0309 (progress_bar.py:269, print())
[2021-11-13 14:20:15]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 70 @ 45075 updates, score 37.030868) (writing took 15.566930 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:22:44]    INFO >> epoch 071:    425 / 644 loss=2.791, nll_loss=0.721, ppl=1.65, wps=1432.8, ups=1.97, wpb=727.4, bsz=16, num_updates=45500, lr=4.8e-05, gnorm=2.285, clip=0, loss_scale=128, train_wall=159, gb_free=28.7, wall=27104 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:24:09]    INFO >> epoch 071 | loss 2.792 | nll_loss 0.721 | ppl 1.65 | wps 1555.1 | ups 2.11 | wpb 736.8 | bsz 16 | num_updates 45719 | lr 4.8e-05 | gnorm 2.283 | clip 0 | loss_scale 128 | train_wall 210 | gb_free 28.7 | wall 27190 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:25:08]    INFO >> epoch 071 | valid on 'valid' subset | loss 4.442 | nll_loss 2.528 | ppl 5.77 | bleu 37.4207 | wps 439.8 | wpb 3065.4 | bsz 62.5 | num_updates 45719 | best_bleu 37.4207 (progress_bar.py:269, print())
[2021-11-13 14:25:23]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 71 @ 45719 updates, score 37.420693) (writing took 14.977292 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:27:08]    INFO >> AMP: overflow detected, setting scale to to 128.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 14:27:08]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
[2021-11-13 14:27:11]    INFO >> epoch 072:    282 / 644 loss=2.797, nll_loss=0.726, ppl=1.65, wps=1398.2, ups=1.87, wpb=747.6, bsz=16, num_updates=46000, lr=4.8e-05, gnorm=2.27, clip=0, loss_scale=128, train_wall=169, gb_free=28.7, wall=27372 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:29:26]    INFO >> epoch 072 | loss 2.776 | nll_loss 0.705 | ppl 1.63 | wps 1492 | ups 2.03 | wpb 734.7 | bsz 16 | num_updates 46362 | lr 4.8e-05 | gnorm 2.26 | clip 0 | loss_scale 128 | train_wall 218 | gb_free 28.7 | wall 27506 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:30:28]    INFO >> epoch 072 | valid on 'valid' subset | loss 4.43 | nll_loss 2.535 | ppl 5.8 | bleu 37.7373 | wps 423 | wpb 3065.4 | bsz 62.5 | num_updates 46362 | best_bleu 37.7373 (progress_bar.py:269, print())
[2021-11-13 14:30:44]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 72 @ 46362 updates, score 37.737339) (writing took 15.774382 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:31:37]    INFO >> epoch 073:    138 / 644 loss=2.771, nll_loss=0.7, ppl=1.62, wps=1383.9, ups=1.88, wpb=736.6, bsz=16, num_updates=46500, lr=4.8e-05, gnorm=2.248, clip=0, loss_scale=128, train_wall=164, gb_free=27.9, wall=27638 (progress_bar.py:260, log())
[2021-11-13 14:34:20]    INFO >> epoch 073:    638 / 644 loss=2.76, nll_loss=0.689, ppl=1.61, wps=2230.1, ups=3.07, wpb=727, bsz=16, num_updates=47000, lr=4.8e-05, gnorm=2.217, clip=0, loss_scale=128, train_wall=162, gb_free=28.7, wall=27801 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:34:36]    INFO >> epoch 073 | loss 2.767 | nll_loss 0.697 | ppl 1.62 | wps 1528.1 | ups 2.07 | wpb 736.8 | bsz 16 | num_updates 47006 | lr 4.8e-05 | gnorm 2.209 | clip 0 | loss_scale 128 | train_wall 208 | gb_free 28.7 | wall 27817 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:35:35]    INFO >> epoch 073 | valid on 'valid' subset | loss 4.425 | nll_loss 2.53 | ppl 5.78 | bleu 37.595 | wps 444.6 | wpb 3065.4 | bsz 62.5 | num_updates 47006 | best_bleu 37.7373 (progress_bar.py:269, print())
[2021-11-13 14:35:46]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 73 @ 47006 updates, score 37.595042) (writing took 11.128363 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:38:41]    INFO >> epoch 074:    494 / 644 loss=2.756, nll_loss=0.686, ppl=1.61, wps=1423.4, ups=1.92, wpb=741.4, bsz=16, num_updates=47500, lr=4.8e-05, gnorm=2.185, clip=0, loss_scale=128, train_wall=166, gb_free=28.7, wall=28061 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:39:42]    INFO >> epoch 074 | loss 2.752 | nll_loss 0.682 | ppl 1.6 | wps 1549.9 | ups 2.1 | wpb 736.8 | bsz 16 | num_updates 47650 | lr 4.8e-05 | gnorm 2.19 | clip 0 | loss_scale 128 | train_wall 211 | gb_free 28.7 | wall 28123 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:40:35]    INFO >> epoch 074 | valid on 'valid' subset | loss 4.452 | nll_loss 2.554 | ppl 5.87 | bleu 37.9552 | wps 531.8 | wpb 3065.4 | bsz 62.5 | num_updates 47650 | best_bleu 37.9552 (progress_bar.py:269, print())
[2021-11-13 14:40:50]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 74 @ 47650 updates, score 37.955207) (writing took 14.948760 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:42:59]    INFO >> epoch 075:    350 / 644 loss=2.746, nll_loss=0.679, ppl=1.6, wps=1418, ups=1.94, wpb=731.7, bsz=16, num_updates=48000, lr=4.8e-05, gnorm=2.185, clip=0, loss_scale=256, train_wall=167, gb_free=28.7, wall=28319 (progress_bar.py:260, log())
[2021-11-13 14:43:58]    INFO >> AMP: overflow detected, setting scale to to 128.0 (amp_optimizer.py:66, clip_grad_norm())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:44:53]    INFO >> epoch 075 | loss 2.738 | nll_loss 0.669 | ppl 1.59 | wps 1529.3 | ups 2.08 | wpb 736.8 | bsz 16 | num_updates 48294 | lr 4.8e-05 | gnorm 2.155 | clip 0 | loss_scale 128 | train_wall 218 | gb_free 28.7 | wall 28433 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:45:51]    INFO >> epoch 075 | valid on 'valid' subset | loss 4.41 | nll_loss 2.546 | ppl 5.84 | bleu 37.9692 | wps 462.3 | wpb 3065.4 | bsz 62.5 | num_updates 48294 | best_bleu 37.9692 (progress_bar.py:269, print())
[2021-11-13 14:46:10]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 75 @ 48294 updates, score 37.969242) (writing took 19.017869 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:47:28]    INFO >> epoch 076:    206 / 644 loss=2.704, nll_loss=0.631, ppl=1.55, wps=1347.7, ups=1.86, wpb=724.2, bsz=16, num_updates=48500, lr=4.8e-05, gnorm=2.116, clip=0, loss_scale=128, train_wall=167, gb_free=28.7, wall=28588 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:50:03]    INFO >> epoch 076 | loss 2.728 | nll_loss 0.659 | ppl 1.58 | wps 1529.7 | ups 2.08 | wpb 736.8 | bsz 16 | num_updates 48938 | lr 4.8e-05 | gnorm 2.125 | clip 0 | loss_scale 128 | train_wall 208 | gb_free 28.7 | wall 28744 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:50:57]    INFO >> epoch 076 | valid on 'valid' subset | loss 4.428 | nll_loss 2.531 | ppl 5.78 | bleu 37.5636 | wps 497.1 | wpb 3065.4 | bsz 62.5 | num_updates 48938 | best_bleu 37.9692 (progress_bar.py:269, print())
[2021-11-13 14:51:08]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 76 @ 48938 updates, score 37.563616) (writing took 10.219124 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:51:36]    INFO >> epoch 077:     62 / 644 loss=2.744, nll_loss=0.676, ppl=1.6, wps=1509.8, ups=2.01, wpb=750.4, bsz=16, num_updates=49000, lr=4.8e-05, gnorm=2.137, clip=0, loss_scale=128, train_wall=160, gb_free=28.7, wall=28837 (progress_bar.py:260, log())
[2021-11-13 14:54:30]    INFO >> epoch 077:    562 / 644 loss=2.729, nll_loss=0.661, ppl=1.58, wps=2135.7, ups=2.88, wpb=741.6, bsz=16, num_updates=49500, lr=4.8e-05, gnorm=2.128, clip=0, loss_scale=128, train_wall=172, gb_free=28.7, wall=29010 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:55:11]    INFO >> epoch 077 | loss 2.719 | nll_loss 0.65 | ppl 1.57 | wps 1539.8 | ups 2.09 | wpb 736.8 | bsz 16 | num_updates 49582 | lr 4.8e-05 | gnorm 2.117 | clip 0 | loss_scale 128 | train_wall 219 | gb_free 28.7 | wall 29052 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 14:56:03]    INFO >> epoch 077 | valid on 'valid' subset | loss 4.442 | nll_loss 2.55 | ppl 5.86 | bleu 38.3988 | wps 527.3 | wpb 3065.4 | bsz 62.5 | num_updates 49582 | best_bleu 38.3988 (progress_bar.py:269, print())
[2021-11-13 14:56:19]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 77 @ 49582 updates, score 38.398787) (writing took 15.598698 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 14:58:50]    INFO >> epoch 078:    418 / 644 loss=2.723, nll_loss=0.656, ppl=1.58, wps=1422.6, ups=1.92, wpb=739.8, bsz=16, num_updates=50000, lr=4.8e-05, gnorm=2.093, clip=0, loss_scale=128, train_wall=168, gb_free=28.7, wall=29270 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:00:21]    INFO >> epoch 078 | loss 2.708 | nll_loss 0.64 | ppl 1.56 | wps 1529.4 | ups 2.08 | wpb 736.8 | bsz 16 | num_updates 50226 | lr 4.8e-05 | gnorm 2.094 | clip 0 | loss_scale 256 | train_wall 218 | gb_free 28.7 | wall 29362 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:01:11]    INFO >> epoch 078 | valid on 'valid' subset | loss 4.397 | nll_loss 2.513 | ppl 5.71 | bleu 38.1347 | wps 552.4 | wpb 3065.4 | bsz 62.5 | num_updates 50226 | best_bleu 38.3988 (progress_bar.py:269, print())
[2021-11-13 15:01:20]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 78 @ 50226 updates, score 38.134698) (writing took 8.171056 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:01:40]    INFO >> AMP: overflow detected, setting scale to to 128.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 15:03:04]    INFO >> epoch 079:    274 / 644 loss=2.669, nll_loss=0.6, ppl=1.52, wps=1420.2, ups=1.97, wpb=721.2, bsz=16, num_updates=50500, lr=4.8e-05, gnorm=2.063, clip=0, loss_scale=128, train_wall=171, gb_free=28.7, wall=29524 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:05:17]    INFO >> epoch 079 | loss 2.699 | nll_loss 0.632 | ppl 1.55 | wps 1607.7 | ups 2.18 | wpb 736.8 | bsz 16 | num_updates 50870 | lr 4.8e-05 | gnorm 2.096 | clip 0 | loss_scale 128 | train_wall 212 | gb_free 27.7 | wall 29657 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:06:08]    INFO >> epoch 079 | valid on 'valid' subset | loss 4.436 | nll_loss 2.539 | ppl 5.81 | bleu 38.4703 | wps 551.6 | wpb 3065.4 | bsz 62.5 | num_updates 50870 | best_bleu 38.4703 (progress_bar.py:269, print())
[2021-11-13 15:06:22]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 79 @ 50870 updates, score 38.47032) (writing took 14.803120 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:07:17]    INFO >> epoch 080:    130 / 644 loss=2.7, nll_loss=0.632, ppl=1.55, wps=1452, ups=1.97, wpb=736.3, bsz=16, num_updates=51000, lr=4.8e-05, gnorm=2.101, clip=0, loss_scale=128, train_wall=164, gb_free=28.7, wall=29778 (progress_bar.py:260, log())
[2021-11-13 15:10:05]    INFO >> epoch 080:    630 / 644 loss=2.704, nll_loss=0.637, ppl=1.56, wps=2237.8, ups=2.99, wpb=749.4, bsz=16, num_updates=51500, lr=4.7e-05, gnorm=2.063, clip=0, loss_scale=128, train_wall=166, gb_free=28.7, wall=29945 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:10:22]    INFO >> epoch 080 | loss 2.688 | nll_loss 0.622 | ppl 1.54 | wps 1555.5 | ups 2.11 | wpb 736.8 | bsz 16 | num_updates 51514 | lr 4.7e-05 | gnorm 2.047 | clip 0 | loss_scale 128 | train_wall 215 | gb_free 28.4 | wall 29962 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:11:19]    INFO >> epoch 080 | valid on 'valid' subset | loss 4.428 | nll_loss 2.537 | ppl 5.8 | bleu 38.4031 | wps 464.7 | wpb 3065.4 | bsz 62.5 | num_updates 51514 | best_bleu 38.4703 (progress_bar.py:269, print())
[2021-11-13 15:11:27]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 80 @ 51514 updates, score 38.403083) (writing took 7.586262 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:13:02]    INFO >> AMP: overflow detected, setting scale to to 64.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 15:13:02]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
[2021-11-13 15:14:19]    INFO >> epoch 081:    487 / 644 loss=2.688, nll_loss=0.621, ppl=1.54, wps=1445.6, ups=1.97, wpb=735.6, bsz=16, num_updates=52000, lr=4.7e-05, gnorm=2.077, clip=0, loss_scale=64, train_wall=164, gb_free=28.7, wall=30200 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:15:27]    INFO >> epoch 081 | loss 2.695 | nll_loss 0.629 | ppl 1.55 | wps 1549.7 | ups 2.11 | wpb 734.8 | bsz 16 | num_updates 52157 | lr 4.7e-05 | gnorm 2.093 | clip 0 | loss_scale 64 | train_wall 214 | gb_free 28.7 | wall 30267 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:16:40]    INFO >> epoch 081 | valid on 'valid' subset | loss 4.467 | nll_loss 2.544 | ppl 5.83 | bleu 37.811 | wps 352.8 | wpb 3065.4 | bsz 62.5 | num_updates 52157 | best_bleu 38.4703 (progress_bar.py:269, print())
[2021-11-13 15:16:50]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 81 @ 52157 updates, score 37.811001) (writing took 10.764273 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:18:55]    INFO >> epoch 082:    343 / 644 loss=2.699, nll_loss=0.633, ppl=1.55, wps=1324.3, ups=1.81, wpb=732.2, bsz=16, num_updates=52500, lr=4.7e-05, gnorm=2.149, clip=0, loss_scale=64, train_wall=169, gb_free=28.7, wall=30476 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:20:43]    INFO >> epoch 082 | loss 2.706 | nll_loss 0.64 | ppl 1.56 | wps 1498.2 | ups 2.03 | wpb 736.8 | bsz 16 | num_updates 52801 | lr 4.7e-05 | gnorm 2.163 | clip 0 | loss_scale 64 | train_wall 208 | gb_free 28.7 | wall 30584 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:21:41]    INFO >> epoch 082 | valid on 'valid' subset | loss 4.44 | nll_loss 2.564 | ppl 5.91 | bleu 36.9604 | wps 465 | wpb 3065.4 | bsz 62.5 | num_updates 52801 | best_bleu 38.4703 (progress_bar.py:269, print())
[2021-11-13 15:21:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 82 @ 52801 updates, score 36.960363) (writing took 10.350728 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:23:07]    INFO >> epoch 083:    199 / 644 loss=2.707, nll_loss=0.643, ppl=1.56, wps=1470.7, ups=1.99, wpb=738.8, bsz=16, num_updates=53000, lr=4.7e-05, gnorm=2.14, clip=0, loss_scale=64, train_wall=159, gb_free=28.7, wall=30727 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:25:49]    INFO >> epoch 083 | loss 2.701 | nll_loss 0.636 | ppl 1.55 | wps 1552.4 | ups 2.11 | wpb 736.8 | bsz 16 | num_updates 53445 | lr 4.7e-05 | gnorm 2.156 | clip 0 | loss_scale 64 | train_wall 213 | gb_free 28.6 | wall 30890 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:26:44]    INFO >> epoch 083 | valid on 'valid' subset | loss 4.442 | nll_loss 2.566 | ppl 5.92 | bleu 37.9066 | wps 501.3 | wpb 3065.4 | bsz 62.5 | num_updates 53445 | best_bleu 38.4703 (progress_bar.py:269, print())
[2021-11-13 15:26:54]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 83 @ 53445 updates, score 37.90659) (writing took 10.890721 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:27:20]    INFO >> epoch 084:     55 / 644 loss=2.714, nll_loss=0.65, ppl=1.57, wps=1466.6, ups=1.97, wpb=744, bsz=16, num_updates=53500, lr=4.7e-05, gnorm=2.182, clip=0, loss_scale=64, train_wall=164, gb_free=28.6, wall=30981 (progress_bar.py:260, log())
[2021-11-13 15:30:14]    INFO >> epoch 084:    555 / 644 loss=2.675, nll_loss=0.61, ppl=1.53, wps=2106.5, ups=2.87, wpb=733.8, bsz=16, num_updates=54000, lr=4.7e-05, gnorm=2.071, clip=0, loss_scale=128, train_wall=173, gb_free=28.7, wall=31155 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:30:54]    INFO >> epoch 084 | loss 2.675 | nll_loss 0.61 | ppl 1.53 | wps 1554.1 | ups 2.11 | wpb 736.8 | bsz 16 | num_updates 54089 | lr 4.7e-05 | gnorm 2.063 | clip 0 | loss_scale 128 | train_wall 215 | gb_free 28.7 | wall 31195 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:31:51]    INFO >> epoch 084 | valid on 'valid' subset | loss 4.423 | nll_loss 2.531 | ppl 5.78 | bleu 38.6085 | wps 463.6 | wpb 3065.4 | bsz 62.5 | num_updates 54089 | best_bleu 38.6085 (progress_bar.py:269, print())
[2021-11-13 15:32:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 84 @ 54089 updates, score 38.608493) (writing took 12.764895 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:34:33]    INFO >> epoch 085:    411 / 644 loss=2.632, nll_loss=0.567, ppl=1.48, wps=1413.3, ups=1.93, wpb=731.7, bsz=16, num_updates=54500, lr=4.7e-05, gnorm=1.932, clip=0, loss_scale=128, train_wall=165, gb_free=28.7, wall=31414 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:35:59]    INFO >> epoch 085 | loss 2.645 | nll_loss 0.581 | ppl 1.5 | wps 1559.3 | ups 2.12 | wpb 736.8 | bsz 16 | num_updates 54733 | lr 4.7e-05 | gnorm 1.947 | clip 0 | loss_scale 128 | train_wall 210 | gb_free 28.7 | wall 31499 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:36:48]    INFO >> epoch 085 | valid on 'valid' subset | loss 4.395 | nll_loss 2.522 | ppl 5.74 | bleu 39.2826 | wps 575.7 | wpb 3065.4 | bsz 62.5 | num_updates 54733 | best_bleu 39.2826 (progress_bar.py:269, print())
[2021-11-13 15:37:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 85 @ 54733 updates, score 39.282599) (writing took 12.684191 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:38:38]    INFO >> epoch 086:    267 / 644 loss=2.651, nll_loss=0.59, ppl=1.51, wps=1502.7, ups=2.04, wpb=736.5, bsz=16, num_updates=55000, lr=4.7e-05, gnorm=1.923, clip=0, loss_scale=128, train_wall=159, gb_free=28.7, wall=31659 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:40:53]    INFO >> epoch 086 | loss 2.63 | nll_loss 0.567 | ppl 1.48 | wps 1611.3 | ups 2.19 | wpb 736.8 | bsz 16 | num_updates 55377 | lr 4.7e-05 | gnorm 1.897 | clip 0 | loss_scale 128 | train_wall 208 | gb_free 28.7 | wall 31794 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:41:48]    INFO >> epoch 086 | valid on 'valid' subset | loss 4.415 | nll_loss 2.524 | ppl 5.75 | bleu 39.396 | wps 487.6 | wpb 3065.4 | bsz 62.5 | num_updates 55377 | best_bleu 39.396 (progress_bar.py:269, print())
[2021-11-13 15:42:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 86 @ 55377 updates, score 39.39596) (writing took 16.223215 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:42:53]    INFO >> epoch 087:    123 / 644 loss=2.641, nll_loss=0.577, ppl=1.49, wps=1476, ups=1.96, wpb=751.6, bsz=16, num_updates=55500, lr=4.7e-05, gnorm=1.916, clip=0, loss_scale=128, train_wall=159, gb_free=28.7, wall=31914 (progress_bar.py:260, log())
[2021-11-13 15:45:10]    INFO >> AMP: overflow detected, setting scale to to 128.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 15:45:32]    INFO >> epoch 087:    623 / 644 loss=2.601, nll_loss=0.538, ppl=1.45, wps=2276.8, ups=3.15, wpb=723.4, bsz=16, num_updates=56000, lr=4.7e-05, gnorm=1.847, clip=0, loss_scale=128, train_wall=157, gb_free=28.7, wall=32072 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:45:50]    INFO >> epoch 087 | loss 2.621 | nll_loss 0.559 | ppl 1.47 | wps 1599.1 | ups 2.17 | wpb 736.8 | bsz 16 | num_updates 56021 | lr 4.7e-05 | gnorm 1.862 | clip 0 | loss_scale 128 | train_wall 201 | gb_free 28.7 | wall 32090 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:46:42]    INFO >> epoch 087 | valid on 'valid' subset | loss 4.382 | nll_loss 2.521 | ppl 5.74 | bleu 38.8862 | wps 517.3 | wpb 3065.4 | bsz 62.5 | num_updates 56021 | best_bleu 39.396 (progress_bar.py:269, print())
[2021-11-13 15:46:50]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 87 @ 56021 updates, score 38.886249) (writing took 7.917167 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:49:41]    INFO >> epoch 088:    479 / 644 loss=2.601, nll_loss=0.54, ppl=1.45, wps=1458.4, ups=2, wpb=728, bsz=16, num_updates=56500, lr=4.7e-05, gnorm=1.83, clip=0, loss_scale=128, train_wall=165, gb_free=28.7, wall=32322 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:50:46]    INFO >> epoch 088 | loss 2.614 | nll_loss 0.553 | ppl 1.47 | wps 1604.8 | ups 2.18 | wpb 736.8 | bsz 16 | num_updates 56665 | lr 4.7e-05 | gnorm 1.85 | clip 0 | loss_scale 128 | train_wall 211 | gb_free 28.7 | wall 32386 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:51:40]    INFO >> epoch 088 | valid on 'valid' subset | loss 4.395 | nll_loss 2.514 | ppl 5.71 | bleu 39.6834 | wps 512.3 | wpb 3065.4 | bsz 62.5 | num_updates 56665 | best_bleu 39.6834 (progress_bar.py:269, print())
[2021-11-13 15:51:54]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 88 @ 56665 updates, score 39.683357) (writing took 14.446187 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:53:59]    INFO >> epoch 089:    335 / 644 loss=2.626, nll_loss=0.564, ppl=1.48, wps=1449.6, ups=1.94, wpb=747.6, bsz=16, num_updates=57000, lr=4.7e-05, gnorm=1.883, clip=0, loss_scale=128, train_wall=165, gb_free=28.7, wall=32580 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:55:54]    INFO >> epoch 089 | loss 2.61 | nll_loss 0.549 | ppl 1.46 | wps 1538.7 | ups 2.09 | wpb 736.8 | bsz 16 | num_updates 57309 | lr 4.7e-05 | gnorm 1.862 | clip 0 | loss_scale 128 | train_wall 215 | gb_free 28.7 | wall 32695 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 15:56:52]    INFO >> epoch 089 | valid on 'valid' subset | loss 4.404 | nll_loss 2.517 | ppl 5.72 | bleu 39.5227 | wps 455.3 | wpb 3065.4 | bsz 62.5 | num_updates 57309 | best_bleu 39.6834 (progress_bar.py:269, print())
[2021-11-13 15:57:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 89 @ 57309 updates, score 39.522703) (writing took 9.810486 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 15:58:13]    INFO >> epoch 090:    191 / 644 loss=2.6, nll_loss=0.54, ppl=1.45, wps=1445.5, ups=1.97, wpb=733.2, bsz=16, num_updates=57500, lr=4.7e-05, gnorm=1.853, clip=0, loss_scale=128, train_wall=162, gb_free=28.7, wall=32834 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:00:54]    INFO >> epoch 090 | loss 2.6 | nll_loss 0.54 | ppl 1.45 | wps 1580.1 | ups 2.14 | wpb 736.8 | bsz 16 | num_updates 57953 | lr 4.7e-05 | gnorm 1.833 | clip 0 | loss_scale 256 | train_wall 208 | gb_free 28.7 | wall 32995 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:01:54]    INFO >> epoch 090 | valid on 'valid' subset | loss 4.396 | nll_loss 2.523 | ppl 5.75 | bleu 39.5603 | wps 442.7 | wpb 3065.4 | bsz 62.5 | num_updates 57953 | best_bleu 39.6834 (progress_bar.py:269, print())
[2021-11-13 16:02:02]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 90 @ 57953 updates, score 39.560338) (writing took 7.584927 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:02:26]    INFO >> epoch 091:     47 / 644 loss=2.603, nll_loss=0.543, ppl=1.46, wps=1459.6, ups=1.98, wpb=738.9, bsz=16, num_updates=58000, lr=4.7e-05, gnorm=1.813, clip=0, loss_scale=256, train_wall=161, gb_free=28.7, wall=33087 (progress_bar.py:260, log())
[2021-11-13 16:05:16]    INFO >> epoch 091:    547 / 644 loss=2.574, nll_loss=0.517, ppl=1.43, wps=2163.7, ups=2.95, wpb=733.4, bsz=16, num_updates=58500, lr=4.7e-05, gnorm=1.716, clip=0, loss_scale=256, train_wall=168, gb_free=28.7, wall=33256 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:05:52]    INFO >> epoch 091 | loss 2.572 | nll_loss 0.514 | ppl 1.43 | wps 1591.3 | ups 2.16 | wpb 736.8 | bsz 16 | num_updates 58597 | lr 4.7e-05 | gnorm 1.713 | clip 0 | loss_scale 256 | train_wall 206 | gb_free 28.7 | wall 33293 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:06:42]    INFO >> epoch 091 | valid on 'valid' subset | loss 4.365 | nll_loss 2.495 | ppl 5.64 | bleu 39.0554 | wps 545.6 | wpb 3065.4 | bsz 62.5 | num_updates 58597 | best_bleu 39.6834 (progress_bar.py:269, print())
[2021-11-13 16:06:50]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 91 @ 58597 updates, score 39.0554) (writing took 8.275953 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:09:15]    INFO >> epoch 092:    403 / 644 loss=2.547, nll_loss=0.489, ppl=1.4, wps=1542.1, ups=2.09, wpb=738.5, bsz=16, num_updates=59000, lr=4.7e-05, gnorm=1.633, clip=0, loss_scale=256, train_wall=157, gb_free=28.7, wall=33496 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:10:48]    INFO >> epoch 092 | loss 2.552 | nll_loss 0.494 | ppl 1.41 | wps 1603.3 | ups 2.18 | wpb 736.8 | bsz 16 | num_updates 59241 | lr 4.7e-05 | gnorm 1.633 | clip 0 | loss_scale 256 | train_wall 213 | gb_free 28.7 | wall 33589 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:11:43]    INFO >> epoch 092 | valid on 'valid' subset | loss 4.369 | nll_loss 2.499 | ppl 5.65 | bleu 40.0552 | wps 495.1 | wpb 3065.4 | bsz 62.5 | num_updates 59241 | best_bleu 40.0552 (progress_bar.py:269, print())
[2021-11-13 16:11:57]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 92 @ 59241 updates, score 40.055232) (writing took 14.150693 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:13:35]    INFO >> epoch 093:    259 / 644 loss=2.558, nll_loss=0.5, ppl=1.41, wps=1418.8, ups=1.92, wpb=737.9, bsz=16, num_updates=59500, lr=4.7e-05, gnorm=1.629, clip=0, loss_scale=256, train_wall=167, gb_free=28.7, wall=33756 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:15:52]    INFO >> epoch 093 | loss 2.545 | nll_loss 0.487 | ppl 1.4 | wps 1564.4 | ups 2.12 | wpb 736.8 | bsz 16 | num_updates 59885 | lr 4.7e-05 | gnorm 1.615 | clip 0 | loss_scale 256 | train_wall 210 | gb_free 28.7 | wall 33892 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:16:48]    INFO >> epoch 093 | valid on 'valid' subset | loss 4.387 | nll_loss 2.512 | ppl 5.7 | bleu 40.3564 | wps 475.4 | wpb 3065.4 | bsz 62.5 | num_updates 59885 | best_bleu 40.3564 (progress_bar.py:269, print())
[2021-11-13 16:17:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 93 @ 59885 updates, score 40.356411) (writing took 12.837551 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:17:22]    INFO >> AMP: overflow detected, setting scale to to 256.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 16:17:47]    INFO >> epoch 094:    115 / 644 loss=2.533, nll_loss=0.474, ppl=1.39, wps=1459.1, ups=1.99, wpb=734.5, bsz=16, num_updates=60000, lr=4.7e-05, gnorm=1.61, clip=0, loss_scale=256, train_wall=159, gb_free=28.7, wall=34007 (progress_bar.py:260, log())
[2021-11-13 16:20:29]    INFO >> epoch 094:    615 / 644 loss=2.541, nll_loss=0.485, ppl=1.4, wps=2259.3, ups=3.07, wpb=734.8, bsz=16, num_updates=60500, lr=4.7e-05, gnorm=1.602, clip=0, loss_scale=256, train_wall=161, gb_free=28.7, wall=34170 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:20:49]    INFO >> epoch 094 | loss 2.539 | nll_loss 0.482 | ppl 1.4 | wps 1597.1 | ups 2.17 | wpb 736.8 | bsz 16 | num_updates 60529 | lr 4.7e-05 | gnorm 1.599 | clip 0 | loss_scale 256 | train_wall 204 | gb_free 28.7 | wall 34189 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:21:44]    INFO >> epoch 094 | valid on 'valid' subset | loss 4.354 | nll_loss 2.5 | ppl 5.65 | bleu 40.6692 | wps 484.9 | wpb 3065.4 | bsz 62.5 | num_updates 60529 | best_bleu 40.6692 (progress_bar.py:269, print())
[2021-11-13 16:21:56]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 94 @ 60529 updates, score 40.669181) (writing took 12.449513 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:24:42]    INFO >> epoch 095:    471 / 644 loss=2.545, nll_loss=0.489, ppl=1.4, wps=1490.1, ups=1.98, wpb=752.8, bsz=16, num_updates=61000, lr=4.7e-05, gnorm=1.599, clip=0, loss_scale=256, train_wall=161, gb_free=28.7, wall=34423 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:25:44]    INFO >> epoch 095 | loss 2.534 | nll_loss 0.478 | ppl 1.39 | wps 1610.6 | ups 2.19 | wpb 736.8 | bsz 16 | num_updates 61173 | lr 4.7e-05 | gnorm 1.588 | clip 0 | loss_scale 256 | train_wall 203 | gb_free 28.7 | wall 34484 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:26:32]    INFO >> epoch 095 | valid on 'valid' subset | loss 4.376 | nll_loss 2.492 | ppl 5.63 | bleu 39.8571 | wps 572.8 | wpb 3065.4 | bsz 62.5 | num_updates 61173 | best_bleu 40.6692 (progress_bar.py:269, print())
[2021-11-13 16:26:40]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 95 @ 61173 updates, score 39.857079) (writing took 8.055953 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:28:37]    INFO >> epoch 096:    327 / 644 loss=2.523, nll_loss=0.468, ppl=1.38, wps=1539.6, ups=2.13, wpb=724, bsz=16, num_updates=61500, lr=4.7e-05, gnorm=1.587, clip=0, loss_scale=256, train_wall=155, gb_free=28.7, wall=34658 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:30:32]    INFO >> epoch 096 | loss 2.53 | nll_loss 0.475 | ppl 1.39 | wps 1642.1 | ups 2.23 | wpb 736.8 | bsz 16 | num_updates 61817 | lr 4.7e-05 | gnorm 1.592 | clip 0 | loss_scale 256 | train_wall 208 | gb_free 28.7 | wall 34773 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:31:33]    INFO >> epoch 096 | valid on 'valid' subset | loss 4.369 | nll_loss 2.505 | ppl 5.68 | bleu 40.9645 | wps 430.3 | wpb 3065.4 | bsz 62.5 | num_updates 61817 | best_bleu 40.9645 (progress_bar.py:269, print())
[2021-11-13 16:31:48]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_best.pt (epoch 96 @ 61817 updates, score 40.964461) (writing took 14.244639 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:32:40]    INFO >> AMP: overflow detected, setting scale to to 256.0 (amp_optimizer.py:66, clip_grad_norm())
[2021-11-13 16:32:40]    INFO >> AMP: skipping this batch. (ncc_trainers.py:470, train_step())
[2021-11-13 16:32:59]    INFO >> epoch 097:    184 / 644 loss=2.518, nll_loss=0.463, ppl=1.38, wps=1392.3, ups=1.91, wpb=728.1, bsz=16, num_updates=62000, lr=4.7e-05, gnorm=1.576, clip=0, loss_scale=256, train_wall=162, gb_free=28.6, wall=34919 (progress_bar.py:260, log())
[2021-11-13 16:33:51]    INFO >> AMP: overflow detected, setting scale to to 128.0 (amp_optimizer.py:66, clip_grad_norm())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:35:49]    INFO >> epoch 097 | loss 2.534 | nll_loss 0.479 | ppl 1.39 | wps 1496.9 | ups 2.03 | wpb 735.7 | bsz 16 | num_updates 62460 | lr 4.7e-05 | gnorm 1.624 | clip 0 | loss_scale 128 | train_wall 216 | gb_free 28.7 | wall 35089 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:36:54]    INFO >> epoch 097 | valid on 'valid' subset | loss 4.405 | nll_loss 2.544 | ppl 5.83 | bleu 39.9744 | wps 413.3 | wpb 3065.4 | bsz 62.5 | num_updates 62460 | best_bleu 40.9645 (progress_bar.py:269, print())
[2021-11-13 16:37:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 97 @ 62460 updates, score 39.974388) (writing took 7.847657 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:37:23]    INFO >> epoch 098:     40 / 644 loss=2.546, nll_loss=0.491, ppl=1.41, wps=1407.6, ups=1.89, wpb=744.8, bsz=16, num_updates=62500, lr=4.7e-05, gnorm=1.65, clip=0, loss_scale=128, train_wall=167, gb_free=28.7, wall=35184 (progress_bar.py:260, log())
[2021-11-13 16:40:13]    INFO >> epoch 098:    540 / 644 loss=2.556, nll_loss=0.499, ppl=1.41, wps=2162.3, ups=2.94, wpb=734.9, bsz=16, num_updates=63000, lr=4.7e-05, gnorm=1.762, clip=0, loss_scale=128, train_wall=169, gb_free=27.4, wall=35354 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:40:58]    INFO >> epoch 098 | loss 2.554 | nll_loss 0.498 | ppl 1.41 | wps 1535.7 | ups 2.08 | wpb 736.8 | bsz 16 | num_updates 63104 | lr 4.7e-05 | gnorm 1.744 | clip 0 | loss_scale 128 | train_wall 212 | gb_free 28.7 | wall 35398 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:41:54]    INFO >> epoch 098 | valid on 'valid' subset | loss 4.402 | nll_loss 2.531 | ppl 5.78 | bleu 39.5205 | wps 475.3 | wpb 3065.4 | bsz 62.5 | num_updates 63104 | best_bleu 40.9645 (progress_bar.py:269, print())
[2021-11-13 16:42:01]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 98 @ 63104 updates, score 39.520531) (writing took 7.314331 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:44:23]    INFO >> epoch 099:    396 / 644 loss=2.553, nll_loss=0.499, ppl=1.41, wps=1479.2, ups=2, wpb=738.8, bsz=16, num_updates=63500, lr=4.7e-05, gnorm=1.751, clip=0, loss_scale=128, train_wall=161, gb_free=28.7, wall=35603 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:46:01]    INFO >> epoch 099 | loss 2.557 | nll_loss 0.503 | ppl 1.42 | wps 1563 | ups 2.12 | wpb 736.8 | bsz 16 | num_updates 63748 | lr 4.7e-05 | gnorm 1.747 | clip 0 | loss_scale 128 | train_wall 215 | gb_free 28.7 | wall 35702 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-11-13 16:47:06]    INFO >> epoch 099 | valid on 'valid' subset | loss 4.4 | nll_loss 2.528 | ppl 5.77 | bleu 38.8142 | wps 398 | wpb 3065.4 | bsz 62.5 | num_updates 63748 | best_bleu 40.9645 (progress_bar.py:269, print())
[2021-11-13 16:47:15]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_code/translation/vanilla/data-mmap/transformer/csharp-java/checkpoints/checkpoint_last.pt (epoch 99 @ 63748 updates, score 38.814221) (writing took 9.339191 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-11-13 16:48:45]    INFO >> epoch 100:    252 / 644 loss=2.556, nll_loss=0.502, ppl=1.42, wps=1402.5, ups=1.91, wpb=736.2, bsz=16, num_updates=64000, lr=4.7e-05, gnorm=1.737, clip=0, loss_scale=128, train_wall=164, gb_free=28.7, wall=35866 (progress_bar.py:260, log())
/home/wanyao/anaconda3/envs/py38-1.8/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 76 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
