nohup: ignoring input
[2021-05-31 16:39:05]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-dev/run/completion/gpt2/config/csn_feng/ruby.yml (train.py:291, cli_main())
[2021-05-31 16:39:05]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 32, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby', 'target_lang': 'code_tokens', 'max_target_positions': 256, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 256, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 3, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}, 'kd': {'gen_topk': 5, 'distill_topk': 3}} (train.py:293, cli_main())
[2021-05-31 16:39:05]    INFO >> single GPU training... (train.py:322, cli_main())
[2021-05-31 16:39:05]    INFO >> {'criterion': 'completion_cross_entropy', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'completion', 'seed': 666, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': 100000.0, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 32, 'curriculum': 5, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'truncate_target': 1}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1}, 'task': {'data': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby', 'target_lang': 'code_tokens', 'max_target_positions': 256, 'add_bos_token': 0, 'eval_bleu': 0, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0, 'eval_mrr': 1}, 'model': {'arch': 'completion_gpt2', 'dropout': 0.5, 'decoder_embed_dim': 300, 'decoder_hidden_size': 300, 'decoder_layers': 6, 'decoder_attention_heads': 6, 'max_target_positions': 256, 'activation_fn': 'gelu', 'decoder_ffn_embed_dim': 1200}, 'optimization': {'max_epoch': 100, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': None, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': None, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'save_dir': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints', 'restore_file': 'checkpoint_best.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 3, 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt', 'model_overrides': '{}', 'checkpoint_suffix': '', 'max_sentences_eval': 64}, 'kd': {'gen_topk': 5, 'distill_topk': 3}} (train.py:201, single_main())
[2021-05-31 16:39:05]    INFO >> [code_tokens] dictionary: 50000 types (completion.py:103, setup_task())
[2021-05-31 16:39:05]    INFO >> Truncate dataset into max length: 256 (completion.py:42, load_token_dataset())
[2021-05-31 16:39:05]    INFO >> loaded 1400 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/valid.code_tokens (completion.py:43, load_token_dataset())
[2021-05-31 16:39:05]    INFO >> GPT2(
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(50000, 300, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (1): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (2): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (3): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (4): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
      (5): TransformerDecoderLayer(
        (in_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (attention): MultiheadAttention(
          (k_proj): Linear(in_features=300, out_features=300, bias=True)
          (v_proj): Linear(in_features=300, out_features=300, bias=True)
          (q_proj): Linear(in_features=300, out_features=300, bias=True)
          (out_proj): Linear(in_features=300, out_features=300, bias=True)
        )
        (ff_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=300, out_features=1200, bias=True)
        (fc2): Linear(in_features=1200, out_features=300, bias=True)
      )
    )
    (out_layer_norm): LayerNorm((300,), eps=1e-08, elementwise_affine=True)
  )
) (train.py:212, single_main())
[2021-05-31 16:39:05]    INFO >> model completion_gpt2, criterion CompletionCrossEntropyCriterion (train.py:213, single_main())
[2021-05-31 16:39:05]    INFO >> num. model params: 21894150 (num. trained: 21894150) (train.py:214, single_main())
[2021-05-31 16:39:16]    INFO >> training on 1 GPUs (train.py:221, single_main())
[2021-05-31 16:39:16]    INFO >> max tokens per GPU = 100000.0 and max sentences per GPU = 32 (train.py:222, single_main())
[2021-05-31 16:39:16]    INFO >> no existing checkpoint found checkpoint_best.pt (ncc_trainers.py:270, load_checkpoint())
[2021-05-31 16:39:16]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-05-31 16:39:16]    INFO >> Truncate dataset into max length: 256 (completion.py:42, load_token_dataset())
[2021-05-31 16:39:16]    INFO >> loaded 24927 examples from: /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/train.code_tokens (completion.py:43, load_token_dataset())
[2021-05-31 16:39:16]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/wanyao/yang/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2021-05-31 16:41:51]    INFO >> epoch 001:    500 / 779 loss=5.616, accuracy=0, mrr=0, ppl=49.03, wps=6685.3, ups=3.38, wpb=1977.3, bsz=32, num_updates=500, lr=0.001, gnorm=1.059, clip=0, train_wall=147, wall=155 (progress_bar.py:260, log())
[2021-05-31 16:42:07]    INFO >> epoch 001 | valid on 'valid' subset | loss 4.919 | accuracy 0.381425 | mrr 0.501904 | ppl 30.25 | wps 10496.9 | wpb 1984.1 | bsz 31.8 | num_updates 500 (progress_bar.py:269, print())
[2021-05-31 16:42:08]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 0.501904) (writing took 1.191442 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:43:29]    INFO >> epoch 001 | loss 5.268 | accuracy 0 | mrr 0 | ppl 38.54 | wps 6284.8 | ups 3.17 | wpb 1981 | bsz 32 | num_updates 779 | lr 0.001 | gnorm 1.013 | clip 0 | train_wall 227 | wall 253 (progress_bar.py:269, print())
[2021-05-31 16:43:45]    INFO >> epoch 001 | valid on 'valid' subset | loss 4.593 | accuracy 0.407702 | mrr 0.530375 | ppl 24.13 | wps 10210.6 | wpb 1984.1 | bsz 31.8 | num_updates 779 | best_mrr 0.530375 (progress_bar.py:269, print())
[2021-05-31 16:44:10]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 1 @ 779 updates, score 0.530375) (writing took 24.576174 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:45:22]    INFO >> epoch 002:    221 / 779 loss=4.484, accuracy=0, mrr=0, ppl=22.38, wps=4713.9, ups=2.37, wpb=1988.5, bsz=32, num_updates=1000, lr=0.001, gnorm=0.904, clip=0, train_wall=145, wall=366 (progress_bar.py:260, log())
[2021-05-31 16:45:38]    INFO >> epoch 002 | valid on 'valid' subset | loss 4.394 | accuracy 0.424633 | mrr 0.54788 | ppl 21.02 | wps 10385.2 | wpb 1984.1 | bsz 31.8 | num_updates 1000 | best_mrr 0.54788 (progress_bar.py:269, print())
[2021-05-31 16:45:51]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_2_1000.pt (epoch 2 @ 1000 updates, score 0.54788) (writing took 13.432414 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:48:23]    INFO >> epoch 002:    721 / 779 loss=3.946, accuracy=0, mrr=0, ppl=15.41, wps=5467.4, ups=2.77, wpb=1976.1, bsz=32, num_updates=1500, lr=0.001, gnorm=0.875, clip=0, train_wall=150, wall=547 (progress_bar.py:260, log())
[2021-05-31 16:48:39]    INFO >> epoch 002 | valid on 'valid' subset | loss 4.127 | accuracy 0.44445 | mrr 0.568877 | ppl 17.47 | wps 10182.8 | wpb 1984.1 | bsz 31.8 | num_updates 1500 | best_mrr 0.568877 (progress_bar.py:269, print())
[2021-05-31 16:48:58]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_2_1500.pt (epoch 2 @ 1500 updates, score 0.568877) (writing took 19.275927 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:49:16]    INFO >> epoch 002 | loss 4.023 | accuracy 0 | mrr 0 | ppl 16.26 | wps 4445.3 | ups 2.24 | wpb 1981 | bsz 32 | num_updates 1558 | lr 0.001 | gnorm 0.874 | clip 0 | train_wall 233 | wall 600 (progress_bar.py:269, print())
[2021-05-31 16:49:32]    INFO >> epoch 002 | valid on 'valid' subset | loss 4.084 | accuracy 0.448046 | mrr 0.572803 | ppl 16.96 | wps 10506 | wpb 1984.1 | bsz 31.8 | num_updates 1558 | best_mrr 0.572803 (progress_bar.py:269, print())
[2021-05-31 16:49:47]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 2 @ 1558 updates, score 0.572803) (writing took 15.161912 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:52:06]    INFO >> epoch 003:    442 / 779 loss=3.551, accuracy=0, mrr=0, ppl=11.72, wps=4453.4, ups=2.25, wpb=1981.1, bsz=32, num_updates=2000, lr=0.001, gnorm=0.846, clip=0, train_wall=148, wall=769 (progress_bar.py:260, log())
[2021-05-31 16:52:21]    INFO >> epoch 003 | valid on 'valid' subset | loss 3.972 | accuracy 0.461494 | mrr 0.585199 | ppl 15.69 | wps 10193.6 | wpb 1984.1 | bsz 31.8 | num_updates 2000 | best_mrr 0.585199 (progress_bar.py:269, print())
[2021-05-31 16:52:48]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_3_2000.pt (epoch 3 @ 2000 updates, score 0.585199) (writing took 26.835460 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:54:28]    INFO >> epoch 003 | loss 3.43 | accuracy 0 | mrr 0 | ppl 10.78 | wps 4951 | ups 2.5 | wpb 1981 | bsz 32 | num_updates 2337 | lr 0.001 | gnorm 0.847 | clip 0 | train_wall 229 | wall 912 (progress_bar.py:269, print())
[2021-05-31 16:54:44]    INFO >> epoch 003 | valid on 'valid' subset | loss 3.915 | accuracy 0.468436 | mrr 0.591677 | ppl 15.09 | wps 10427.7 | wpb 1984.1 | bsz 31.8 | num_updates 2337 | best_mrr 0.591677 (progress_bar.py:269, print())
[2021-05-31 16:55:06]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 3 @ 2337 updates, score 0.591677) (writing took 22.143319 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:56:02]    INFO >> epoch 004:    163 / 779 loss=3.25, accuracy=0, mrr=0, ppl=9.51, wps=4199.1, ups=2.12, wpb=1982, bsz=32, num_updates=2500, lr=0.001, gnorm=0.848, clip=0, train_wall=147, wall=1005 (progress_bar.py:260, log())
[2021-05-31 16:56:17]    INFO >> epoch 004 | valid on 'valid' subset | loss 3.899 | accuracy 0.467898 | mrr 0.592188 | ppl 14.92 | wps 10187.7 | wpb 1984.1 | bsz 31.8 | num_updates 2500 | best_mrr 0.592188 (progress_bar.py:269, print())
[2021-05-31 16:56:33]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_4_2500.pt (epoch 4 @ 2500 updates, score 0.592188) (writing took 16.135892 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 16:59:02]    INFO >> epoch 004:    663 / 779 loss=3.045, accuracy=0, mrr=0, ppl=8.25, wps=5466.6, ups=2.76, wpb=1977.2, bsz=32, num_updates=3000, lr=0.001, gnorm=0.844, clip=0, train_wall=148, wall=1186 (progress_bar.py:260, log())
[2021-05-31 16:59:18]    INFO >> epoch 004 | valid on 'valid' subset | loss 3.889 | accuracy 0.471999 | mrr 0.594293 | ppl 14.81 | wps 10073.1 | wpb 1984.1 | bsz 31.8 | num_updates 3000 | best_mrr 0.594293 (progress_bar.py:269, print())
[2021-05-31 16:59:31]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_4_3000.pt (epoch 4 @ 3000 updates, score 0.594293) (writing took 13.155441 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:00:08]    INFO >> epoch 004 | loss 3.046 | accuracy 0 | mrr 0 | ppl 8.26 | wps 4544.3 | ups 2.29 | wpb 1981 | bsz 32 | num_updates 3116 | lr 0.001 | gnorm 0.84 | clip 0 | train_wall 232 | wall 1251 (progress_bar.py:269, print())
[2021-05-31 17:00:23]    INFO >> epoch 004 | valid on 'valid' subset | loss 3.844 | accuracy 0.473178 | mrr 0.597233 | ppl 14.36 | wps 10217.5 | wpb 1984.1 | bsz 31.8 | num_updates 3116 | best_mrr 0.597233 (progress_bar.py:269, print())
[2021-05-31 17:00:48]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 4 @ 3116 updates, score 0.597233) (writing took 25.255085 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:02:50]    INFO >> epoch 005:    384 / 779 loss=2.848, accuracy=0, mrr=0, ppl=7.2, wps=4368.8, ups=2.2, wpb=1988.2, bsz=32, num_updates=3500, lr=0.001, gnorm=0.834, clip=0, train_wall=149, wall=1414 (progress_bar.py:260, log())
[2021-05-31 17:03:06]    INFO >> epoch 005 | valid on 'valid' subset | loss 3.89 | accuracy 0.472915 | mrr 0.595281 | ppl 14.83 | wps 10343.8 | wpb 1984.1 | bsz 31.8 | num_updates 3500 | best_mrr 0.597233 (progress_bar.py:269, print())
[2021-05-31 17:03:12]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_5_3500.pt (epoch 5 @ 3500 updates, score 0.595281) (writing took 6.871400 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:05:11]    INFO >> epoch 005 | loss 2.778 | accuracy 0 | mrr 0 | ppl 6.86 | wps 5078.3 | ups 2.56 | wpb 1981 | bsz 32 | num_updates 3895 | lr 0.001 | gnorm 0.844 | clip 0 | train_wall 231 | wall 1555 (progress_bar.py:269, print())
[2021-05-31 17:05:27]    INFO >> epoch 005 | valid on 'valid' subset | loss 3.878 | accuracy 0.478333 | mrr 0.600554 | ppl 14.7 | wps 10295.4 | wpb 1984.1 | bsz 31.8 | num_updates 3895 | best_mrr 0.600554 (progress_bar.py:269, print())
[2021-05-31 17:05:40]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 5 @ 3895 updates, score 0.600554) (writing took 12.826935 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:06:18]    INFO >> epoch 006:    105 / 779 loss=2.701, accuracy=0, mrr=0, ppl=6.5, wps=4741.7, ups=2.4, wpb=1974.3, bsz=32, num_updates=4000, lr=0.001, gnorm=0.844, clip=0, train_wall=149, wall=1622 (progress_bar.py:260, log())
[2021-05-31 17:06:34]    INFO >> epoch 006 | valid on 'valid' subset | loss 3.839 | accuracy 0.480968 | mrr 0.6025 | ppl 14.31 | wps 10354.8 | wpb 1984.1 | bsz 31.8 | num_updates 4000 | best_mrr 0.6025 (progress_bar.py:269, print())
[2021-05-31 17:06:47]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_6_4000.pt (epoch 6 @ 4000 updates, score 0.6025) (writing took 13.382535 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:09:12]    INFO >> epoch 006:    605 / 779 loss=2.619, accuracy=0, mrr=0, ppl=6.14, wps=5669.7, ups=2.87, wpb=1975.5, bsz=32, num_updates=4500, lr=0.001, gnorm=0.818, clip=0, train_wall=144, wall=1796 (progress_bar.py:260, log())
[2021-05-31 17:09:28]    INFO >> epoch 006 | valid on 'valid' subset | loss 3.804 | accuracy 0.4865 | mrr 0.607586 | ppl 13.97 | wps 10582.5 | wpb 1984.1 | bsz 31.8 | num_updates 4500 | best_mrr 0.607586 (progress_bar.py:269, print())
[2021-05-31 17:09:41]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_6_4500.pt (epoch 6 @ 4500 updates, score 0.607586) (writing took 13.300370 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:10:34]    INFO >> epoch 006 | loss 2.624 | accuracy 0 | mrr 0 | ppl 6.17 | wps 4787.1 | ups 2.42 | wpb 1981 | bsz 32 | num_updates 4674 | lr 0.001 | gnorm 0.812 | clip 0 | train_wall 227 | wall 1878 (progress_bar.py:269, print())
[2021-05-31 17:10:49]    INFO >> epoch 006 | valid on 'valid' subset | loss 3.762 | accuracy 0.488104 | mrr 0.609513 | ppl 13.57 | wps 10178.3 | wpb 1984.1 | bsz 31.8 | num_updates 4674 | best_mrr 0.609513 (progress_bar.py:269, print())
[2021-05-31 17:11:07]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 6 @ 4674 updates, score 0.609513) (writing took 17.246919 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:12:46]    INFO >> epoch 007:    326 / 779 loss=2.467, accuracy=0, mrr=0, ppl=5.53, wps=4664.3, ups=2.34, wpb=1990.8, bsz=32, num_updates=5000, lr=0.001, gnorm=0.797, clip=0, train_wall=143, wall=2010 (progress_bar.py:260, log())
[2021-05-31 17:13:01]    INFO >> epoch 007 | valid on 'valid' subset | loss 3.884 | accuracy 0.485011 | mrr 0.605366 | ppl 14.76 | wps 10425.9 | wpb 1984.1 | bsz 31.8 | num_updates 5000 | best_mrr 0.609513 (progress_bar.py:269, print())
[2021-05-31 17:13:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_7_5000.pt (epoch 7 @ 5000 updates, score 0.605366) (writing took 13.022762 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:15:31]    INFO >> epoch 007 | loss 2.411 | accuracy 0 | mrr 0 | ppl 5.32 | wps 5198.1 | ups 2.62 | wpb 1981 | bsz 32 | num_updates 5453 | lr 0.001 | gnorm 0.799 | clip 0 | train_wall 226 | wall 2175 (progress_bar.py:269, print())
[2021-05-31 17:15:46]    INFO >> epoch 007 | valid on 'valid' subset | loss 3.803 | accuracy 0.492766 | mrr 0.611525 | ppl 13.96 | wps 10228 | wpb 1984.1 | bsz 31.8 | num_updates 5453 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:16:04]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_best.pt (epoch 7 @ 5453 updates, score 0.611525) (writing took 17.917336 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:16:25]    INFO >> epoch 008:     47 / 779 loss=2.418, accuracy=0, mrr=0, ppl=5.34, wps=4523.9, ups=2.28, wpb=1982.6, bsz=32, num_updates=5500, lr=0.001, gnorm=0.797, clip=0, train_wall=149, wall=2229 (progress_bar.py:260, log())
[2021-05-31 17:16:40]    INFO >> epoch 008 | valid on 'valid' subset | loss 3.923 | accuracy 0.486936 | mrr 0.60568 | ppl 15.17 | wps 10353.5 | wpb 1984.1 | bsz 31.8 | num_updates 5500 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:16:47]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_8_5500.pt (epoch 8 @ 5500 updates, score 0.60568) (writing took 6.683766 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:19:18]    INFO >> epoch 008:    547 / 779 loss=2.227, accuracy=0, mrr=0, ppl=4.68, wps=5735.7, ups=2.9, wpb=1980.2, bsz=32, num_updates=6000, lr=0.001, gnorm=0.827, clip=0, train_wall=149, wall=2401 (progress_bar.py:260, log())
[2021-05-31 17:19:33]    INFO >> epoch 008 | valid on 'valid' subset | loss 3.907 | accuracy 0.485401 | mrr 0.605683 | ppl 15 | wps 10210.1 | wpb 1984.1 | bsz 31.8 | num_updates 6000 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:19:41]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_8_6000.pt (epoch 8 @ 6000 updates, score 0.605683) (writing took 7.657478 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:20:51]    INFO >> epoch 008 | loss 2.246 | accuracy 0 | mrr 0 | ppl 4.74 | wps 4815 | ups 2.43 | wpb 1981 | bsz 32 | num_updates 6232 | lr 0.001 | gnorm 0.819 | clip 0 | train_wall 232 | wall 2495 (progress_bar.py:269, print())
[2021-05-31 17:21:07]    INFO >> epoch 008 | valid on 'valid' subset | loss 3.898 | accuracy 0.48799 | mrr 0.607797 | ppl 14.91 | wps 10031 | wpb 1984.1 | bsz 31.8 | num_updates 6232 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:21:14]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_last.pt (epoch 8 @ 6232 updates, score 0.607797) (writing took 6.582865 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:22:41]    INFO >> epoch 009:    268 / 779 loss=2.146, accuracy=0, mrr=0, ppl=4.43, wps=4851.2, ups=2.46, wpb=1973.5, bsz=32, num_updates=6500, lr=0.001, gnorm=0.824, clip=0, train_wall=149, wall=2605 (progress_bar.py:260, log())
[2021-05-31 17:22:56]    INFO >> epoch 009 | valid on 'valid' subset | loss 4.02 | accuracy 0.482285 | mrr 0.6015 | ppl 16.22 | wps 10307.6 | wpb 1984.1 | bsz 31.8 | num_updates 6500 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:23:09]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_9_6500.pt (epoch 9 @ 6500 updates, score 0.6015) (writing took 12.238605 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:25:39]    INFO >> epoch 009:    768 / 779 loss=2.121, accuracy=0, mrr=0, ppl=4.35, wps=5588.4, ups=2.81, wpb=1989.3, bsz=32, num_updates=7000, lr=0.001, gnorm=0.829, clip=0, train_wall=149, wall=2783 (progress_bar.py:260, log())
[2021-05-31 17:25:55]    INFO >> epoch 009 | valid on 'valid' subset | loss 4.005 | accuracy 0.486363 | mrr 0.604896 | ppl 16.06 | wps 10127.9 | wpb 1984.1 | bsz 31.8 | num_updates 7000 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:26:02]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_9_7000.pt (epoch 9 @ 7000 updates, score 0.604896) (writing took 7.158589 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:26:05]    INFO >> epoch 009 | loss 2.082 | accuracy 0 | mrr 0 | ppl 4.23 | wps 4911.9 | ups 2.48 | wpb 1981 | bsz 32 | num_updates 7011 | lr 0.001 | gnorm 0.831 | clip 0 | train_wall 232 | wall 2809 (progress_bar.py:269, print())
[2021-05-31 17:26:21]    INFO >> epoch 009 | valid on 'valid' subset | loss 4.009 | accuracy 0.484003 | mrr 0.603424 | ppl 16.09 | wps 10122.7 | wpb 1984.1 | bsz 31.8 | num_updates 7011 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:26:34]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_last.pt (epoch 9 @ 7011 updates, score 0.603424) (writing took 12.704984 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:29:08]    INFO >> epoch 010:    489 / 779 loss=1.91, accuracy=0, mrr=0, ppl=3.76, wps=4743.7, ups=2.39, wpb=1985, bsz=32, num_updates=7500, lr=0.001, gnorm=0.848, clip=0, train_wall=149, wall=2992 (progress_bar.py:260, log())
[2021-05-31 17:29:24]    INFO >> epoch 010 | valid on 'valid' subset | loss 4.137 | accuracy 0.482136 | mrr 0.60037 | ppl 17.59 | wps 10420.7 | wpb 1984.1 | bsz 31.8 | num_updates 7500 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:29:38]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_10_7500.pt (epoch 10 @ 7500 updates, score 0.60037) (writing took 13.799782 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:31:04]    INFO >> epoch 010 | loss 1.934 | accuracy 0 | mrr 0 | ppl 3.82 | wps 5166.8 | ups 2.61 | wpb 1981 | bsz 32 | num_updates 7790 | lr 0.001 | gnorm 0.849 | clip 0 | train_wall 231 | wall 3108 (progress_bar.py:269, print())
[2021-05-31 17:31:20]    INFO >> epoch 010 | valid on 'valid' subset | loss 4.116 | accuracy 0.483694 | mrr 0.601611 | ppl 17.34 | wps 10282.2 | wpb 1984.1 | bsz 31.8 | num_updates 7790 | best_mrr 0.611525 (progress_bar.py:269, print())
[2021-05-31 17:31:27]    INFO >> saved checkpoint /mnt/wanyao/ncc_data/codexglue/code_to_text/completion/data-mmap/ruby/gpt2/checkpoints/checkpoint_last.pt (epoch 10 @ 7790 updates, score 0.601611) (writing took 6.982595 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-05-31 17:31:27]    INFO >> early stop since valid performance hasn't improved for last 3 runs (train.py:176, should_stop_early())
[2021-05-31 17:31:27]    INFO >> early stop since valid performance hasn't improved for last 3 runs (train.py:259, single_main())
[2021-05-31 17:31:27]    INFO >> done training in 3130.5 seconds (train.py:271, single_main())
