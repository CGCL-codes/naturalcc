nohup: 忽略输入
[2021-04-20 23:17:58]    INFO >> Load arguments in /home/yanghe/Documents/naturalcc-dev/run/retrieval/selfattn/config/csn_feng/all.yml (train.py:302, cli_main())
[2021-04-20 23:17:58]    INFO >> {'criterion': 'retrieval_softmax', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 1000, 'log_format': 'simple', 'tensorboard_logdir': '', 'seed': 0, 'cpu': 0, 'fp16': 0, 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'task': 'hybrid_retrieval'}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': None, 'max_sentences': 450, 'code_max_tokens': 200, 'query_max_tokens': 30, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': None, 'max_tokens_valid': None, 'max_sentences_valid': 1000, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'joined_dictionary': 0, 'langs': ['go', 'java', 'javascript', 'ruby', 'python', 'php']}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': 0, 'mask_whole_words': 0, 'pooler_activation_fn': 'tanh', 'source_lang': 'code_tokens', 'target_lang': 'docstring_tokens', 'source_aux_lang': 'code_tokens.wo_func', 'target_aux_lang': 'func_name', 'fraction_using_func_name': 0.3, 'load_alignments': 0, 'left_pad_source': 1, 'left_pad_target': 0, 'upsample_primary': 1, 'truncate_source': 0, 'eval_mrr': 1}, 'model': {'arch': 'self_attn', 'code_embed_dim': 128, 'code_token_types': 1, 'code_max_tokens': 200, 'code_position_encoding': 'learned', 'code_dropout': 0.1, 'code_pooling': 'weighted_mean', 'query_embed_dim': 128, 'query_token_types': 1, 'query_max_tokens': 30, 'query_self_attn_layers': 3, 'query_pooling': 'weighted_mean', 'query_position_encoding': 'learned', 'query_dropout': 0.1, 'self_attn_layers': 3, 'attention_heads': 8, 'ffn_embed_dim': 512, 'activation_fn': 'gelu'}, 'optimization': {'max_epoch': 300, 'max_update': 0, 'clip_norm': 1, 'sentence_avg': 0, 'update_freq': [1], 'lrs': [0.0005], 'min_lr': -1, 'use_bmuf': 0, 'lr_shrink': 1.0, 'force_anneal': 0, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0, 'use_old_adam': 1}, 'margin': 1, 'clip_norm_version': 'tf_clip_by_global_norm'}, 'checkpoint': {'save_dir': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/self_attn/checkpoints', 'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 10}, 'eval': {'path': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/self_attn/checkpoints/checkpoint_best.pt', 'quiet': 1, 'max_sentences': 450, 'model_overrides': '{}', 'eval_size': -1}} (train.py:304, cli_main())
[2021-04-20 23:17:58]    INFO >> single GPU training... (train.py:333, cli_main())
[2021-04-20 23:17:58]    INFO >> loaded 44689 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.go.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.java.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.javascript.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.ruby.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.python.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.php.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-04-20 23:17:58]    INFO >> loaded 44689 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.go.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.java.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.javascript.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.ruby.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.python.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.php.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-04-20 23:17:59]    INFO >> SelfAttn(
  (src_encoders): ModuleDict(
    (go): SelfAttnEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (type_embed): Embedding(1, 128)
      (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
      )
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (java): SelfAttnEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (type_embed): Embedding(1, 128)
      (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
      )
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (javascript): SelfAttnEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (type_embed): Embedding(1, 128)
      (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
      )
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (ruby): SelfAttnEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (type_embed): Embedding(1, 128)
      (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
      )
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (python): SelfAttnEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (type_embed): Embedding(1, 128)
      (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
      )
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (php): SelfAttnEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (type_embed): Embedding(1, 128)
      (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=128, out_features=128, bias=True)
            (v_proj): Linear(in_features=128, out_features=128, bias=True)
            (q_proj): Linear(in_features=128, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        )
      )
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
  )
  (tgt_encoders): SelfAttnEncoder(
    (embed): Embedding(10000, 128, padding_idx=0)
    (type_embed): Embedding(1, 128)
    (embed_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=512, bias=True)
        (fc2): Linear(in_features=512, out_features=128, bias=True)
        (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=512, bias=True)
        (fc2): Linear(in_features=512, out_features=128, bias=True)
        (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=128, out_features=128, bias=True)
          (v_proj): Linear(in_features=128, out_features=128, bias=True)
          (q_proj): Linear(in_features=128, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=128, out_features=512, bias=True)
        (fc2): Linear(in_features=512, out_features=128, bias=True)
        (ff_layer_norm): LayerNorm((128,), eps=1e-08, elementwise_affine=True)
      )
    )
    (weight_layer): Linear(in_features=128, out_features=1, bias=False)
  )
) (train.py:223, single_main())
[2021-04-20 23:17:59]    INFO >> model self_attn, criterion SearchSoftmaxCriterion (train.py:224, single_main())
[2021-04-20 23:17:59]    INFO >> num. model params: 13284736 (num. trained: 13284736) (train.py:227, single_main())
[2021-04-20 23:18:02]    INFO >> training on 1 GPUs (train.py:233, single_main())
[2021-04-20 23:18:02]    INFO >> max tokens per GPU = None and max sentences per GPU = 450 (train.py:236, single_main())
[2021-04-20 23:18:02]    INFO >> no existing checkpoint found /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/self_attn/checkpoints/checkpoint_last.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-20 23:18:02]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-04-20 23:18:02]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-04-20 23:18:02]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-04-20 23:18:02]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.code_tokens.wo_func'] (hybrid_retrieval.py:67, load_tokens_dataset())
[2021-04-20 23:18:02]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.func_name'] (hybrid_retrieval.py:81, load_tokens_dataset())
[2021-04-20 23:18:03]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
[2021-04-20 23:24:23]    INFO >> epoch 001:   1000 / 2019 loss=2.782, mrr=245.578, sample_size=450, wps=1209.6, ups=2.69, wpb=450, bsz=450, num_updates=1000, lr=0.0005, gnorm=10.763, clip=100, train_wall=360, wall=382 (progress_bar.py:262, log())
[2021-04-20 23:30:35]    INFO >> epoch 001:   2001 / 2019 loss=1.223, mrr=356.265, sample_size=450, wps=1210.1, ups=2.69, wpb=450, bsz=450, num_updates=2000, lr=0.0005, gnorm=6.825, clip=100, train_wall=360, wall=753 (progress_bar.py:262, log())
[2021-04-20 23:30:42]    INFO >> epoch 001 | loss 1.994 | mrr 0.670093 | sample_size 450 | wps 1209.2 | ups 2.69 | wpb 450 | bsz 450 | num_updates 2018 | lr 0.0005 | gnorm 8.769 | clip 100 | train_wall 727 | wall 761 (progress_bar.py:269, print())
[2021-04-20 23:30:59]    INFO >> epoch 001 | valid on 'valid' subset | loss 2.375 | mrr 0.602632 | sample_size 1000 | wps 4695.7 | wpb 1000 | bsz 1000 | num_updates 2018 (progress_bar.py:269, print())
[2021-04-20 23:31:01]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/self_attn/checkpoints/checkpoint_best.pt (epoch 1 @ 2018 updates, score 0.602632) (writing took 1.873282 seconds) (checkpoint_utils.py:81, save_checkpoint())
