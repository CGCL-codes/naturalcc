nohup: 忽略输入
[2021-04-20 04:15:04]    INFO >> Load arguments in /home/yanghe/Documents/naturalcc-dev/run/retrieval/nbow/config/csn_feng/python.yml (train.py:302, cli_main())
[2021-04-20 04:15:04]    INFO >> {'criterion': 'retrieval_cosine', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'seed': 666, 'cpu': 0, 'fp16': 0, 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'task': 'hybrid_retrieval'}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': None, 'max_sentences': 1000, 'code_max_tokens': 200, 'query_max_tokens': 30, 'required_batch_size_multiple': 8, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': None, 'max_tokens_valid': None, 'max_sentences_valid': 1000, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'joined_dictionary': 0, 'langs': ['python']}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': 0, 'mask_whole_words': 0, 'pooler_activation_fn': 'tanh', 'source_lang': 'code_tokens', 'target_lang': 'docstring_tokens', 'source_aux_lang': 'code_tokens.wo_func', 'target_aux_lang': 'func_name', 'fraction_using_func_name': 0.3, 'load_alignments': 0, 'left_pad_source': 1, 'left_pad_target': 0, 'upsample_primary': 1, 'truncate_source': 0, 'eval_mrr': 1}, 'model': {'arch': 'nbow', 'code_embed_dim': 128, 'code_dropout': 0.1, 'code_pooling': 'weighted_mean', 'query_embed_dim': 128, 'query_dropout': 0.1, 'query_pooling': 'weighted_mean'}, 'optimization': {'max_epoch': 300, 'max_update': 0, 'clip_norm': 1, 'sentence_avg': 0, 'update_freq': [1], 'lrs': [0.01], 'min_lr': -1, 'use_bmuf': 0, 'lr_shrink': 1.0, 'force_anneal': 0, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0, 'use_old_adam': 1}, 'margin': 1}, 'checkpoint': {'save_dir': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints', 'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 10}, 'eval': {'path': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt', 'quiet': 1, 'max_sentences': 1000, 'model_overrides': '{}', 'eval_size': -1}} (train.py:304, cli_main())
[2021-04-20 04:15:04]    INFO >> single GPU training... (train.py:333, cli_main())
[2021-04-20 04:15:05]    INFO >> loaded 13914 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.python.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-04-20 04:15:05]    INFO >> loaded 13914 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.python.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-04-20 04:15:05]    INFO >> NBOW(
  (src_encoders): ModuleDict(
    (python): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
  )
  (tgt_encoders): NBOWEncoder(
    (embed): Embedding(10000, 128, padding_idx=0)
    (weight_layer): Linear(in_features=128, out_features=1, bias=False)
  )
) (train.py:223, single_main())
[2021-04-20 04:15:05]    INFO >> model nbow, criterion SearchCosineCriterion (train.py:224, single_main())
[2021-04-20 04:15:05]    INFO >> num. model params: 2560256 (num. trained: 2560256) (train.py:227, single_main())
[2021-04-20 04:15:07]    INFO >> training on 1 GPUs (train.py:233, single_main())
[2021-04-20 04:15:07]    INFO >> max tokens per GPU = None and max sentences per GPU = 1000 (train.py:236, single_main())
[2021-04-20 04:15:07]    INFO >> no existing checkpoint found /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-20 04:15:07]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-04-20 04:15:08]    INFO >> loaded 251820 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-04-20 04:15:08]    INFO >> loaded 251820 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-04-20 04:15:08]    INFO >> loaded 251820 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.code_tokens.wo_func'] (hybrid_retrieval.py:67, load_tokens_dataset())
[2021-04-20 04:15:08]    INFO >> loaded 251820 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.func_name'] (hybrid_retrieval.py:81, load_tokens_dataset())
[2021-04-20 04:15:08]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/yanghe/Documents/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:57: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
[2021-04-20 04:15:25]    INFO >> epoch 001 | loss 1.006 | mrr 0.191111 | sample_size 1000 | wps 17311.4 | ups 17.31 | wpb 1000 | bsz 1000 | num_updates 251 | lr 0.01 | gnorm 0.015 | clip 0 | train_wall 12 | wall 18 (progress_bar.py:269, print())
[2021-04-20 04:15:28]    INFO >> epoch 001 | valid on 'valid' subset | loss 1.001 | mrr 0.346118 | sample_size 1000 | wps 13041.8 | wpb 1000 | bsz 1000 | num_updates 251 (progress_bar.py:269, print())
[2021-04-20 04:15:28]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 1 @ 251 updates, score 0.346118) (writing took 0.216857 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:15:47]    INFO >> epoch 002:    250 / 252 loss=1.004, mrr=324.818, sample_size=1000, wps=13574.1, ups=13.57, wpb=1000, bsz=1000, num_updates=500, lr=0.01, gnorm=0.009, clip=0, train_wall=27, wall=40 (progress_bar.py:262, log())
[2021-04-20 04:15:48]    INFO >> epoch 002 | loss 1.001 | mrr 0.4602 | sample_size 1000 | wps 11047.4 | ups 11.05 | wpb 1000 | bsz 1000 | num_updates 502 | lr 0.01 | gnorm 0.003 | clip 0 | train_wall 15 | wall 40 (progress_bar.py:269, print())
[2021-04-20 04:15:51]    INFO >> epoch 002 | valid on 'valid' subset | loss 1.003 | mrr 0.42389 | sample_size 1000 | wps 13227.6 | wpb 1000 | bsz 1000 | num_updates 502 | best_mrr 423.89 (progress_bar.py:269, print())
[2021-04-20 04:15:51]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 2 @ 502 updates, score 0.42389) (writing took 0.228151 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:16:10]    INFO >> epoch 003 | loss 0.996 | mrr 0.589532 | sample_size 1000 | wps 11184 | ups 11.18 | wpb 1000 | bsz 1000 | num_updates 753 | lr 0.01 | gnorm 0.012 | clip 0 | train_wall 15 | wall 63 (progress_bar.py:269, print())
[2021-04-20 04:16:13]    INFO >> epoch 003 | valid on 'valid' subset | loss 1.039 | mrr 0.460456 | sample_size 1000 | wps 14093 | wpb 1000 | bsz 1000 | num_updates 753 | best_mrr 460.456 (progress_bar.py:269, print())
[2021-04-20 04:16:14]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 3 @ 753 updates, score 0.460456) (writing took 0.227750 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:16:32]    INFO >> epoch 004:    248 / 252 loss=0.976, mrr=645.493, sample_size=1000, wps=11133.9, ups=11.13, wpb=1000, bsz=1000, num_updates=1000, lr=0.01, gnorm=0.017, clip=0, train_wall=29, wall=85 (progress_bar.py:262, log())
[2021-04-20 04:16:33]    INFO >> epoch 004 | loss 0.955 | mrr 0.703631 | sample_size 1000 | wps 11078.6 | ups 11.08 | wpb 1000 | bsz 1000 | num_updates 1004 | lr 0.01 | gnorm 0.022 | clip 0 | train_wall 15 | wall 85 (progress_bar.py:269, print())
[2021-04-20 04:16:36]    INFO >> epoch 004 | valid on 'valid' subset | loss 1.046 | mrr 0.509769 | sample_size 1000 | wps 14312.6 | wpb 1000 | bsz 1000 | num_updates 1004 | best_mrr 509.769 (progress_bar.py:269, print())
[2021-04-20 04:16:36]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 4 @ 1004 updates, score 0.509769) (writing took 0.223947 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:16:56]    INFO >> epoch 005 | loss 0.914 | mrr 0.784099 | sample_size 1000 | wps 10870.6 | ups 10.87 | wpb 1000 | bsz 1000 | num_updates 1255 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 15 | wall 109 (progress_bar.py:269, print())
[2021-04-20 04:16:59]    INFO >> epoch 005 | valid on 'valid' subset | loss 1.044 | mrr 0.519274 | sample_size 1000 | wps 14049.3 | wpb 1000 | bsz 1000 | num_updates 1255 | best_mrr 519.274 (progress_bar.py:269, print())
[2021-04-20 04:16:59]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 5 @ 1255 updates, score 0.519274) (writing took 0.231881 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:17:18]    INFO >> epoch 006:    246 / 252 loss=0.905, mrr=798.371, sample_size=1000, wps=10944, ups=10.94, wpb=1000, bsz=1000, num_updates=1500, lr=0.01, gnorm=0.021, clip=0, train_wall=30, wall=130 (progress_bar.py:262, log())
[2021-04-20 04:17:19]    INFO >> epoch 006 | loss 0.896 | mrr 0.813789 | sample_size 1000 | wps 11084.6 | ups 11.08 | wpb 1000 | bsz 1000 | num_updates 1506 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 15 | wall 131 (progress_bar.py:269, print())
[2021-04-20 04:17:22]    INFO >> epoch 006 | valid on 'valid' subset | loss 1.044 | mrr 0.521325 | sample_size 1000 | wps 13266.8 | wpb 1000 | bsz 1000 | num_updates 1506 | best_mrr 521.325 (progress_bar.py:269, print())
[2021-04-20 04:17:22]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 6 @ 1506 updates, score 0.521325) (writing took 0.251921 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:17:42]    INFO >> epoch 007 | loss 0.885 | mrr 0.830473 | sample_size 1000 | wps 10711.3 | ups 10.71 | wpb 1000 | bsz 1000 | num_updates 1757 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 15 | wall 155 (progress_bar.py:269, print())
[2021-04-20 04:17:45]    INFO >> epoch 007 | valid on 'valid' subset | loss 1.043 | mrr 0.520262 | sample_size 1000 | wps 14179.1 | wpb 1000 | bsz 1000 | num_updates 1757 | best_mrr 520.262 (progress_bar.py:269, print())
[2021-04-20 04:17:46]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 7 @ 1757 updates, score 0.520262) (writing took 0.133392 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:18:04]    INFO >> epoch 008:    244 / 252 loss=0.881, mrr=835.136, sample_size=1000, wps=10806.4, ups=10.81, wpb=1000, bsz=1000, num_updates=2000, lr=0.01, gnorm=0.021, clip=0, train_wall=30, wall=177 (progress_bar.py:262, log())
[2021-04-20 04:18:05]    INFO >> epoch 008 | loss 0.877 | mrr 0.840459 | sample_size 1000 | wps 10963.9 | ups 10.96 | wpb 1000 | bsz 1000 | num_updates 2008 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 15 | wall 177 (progress_bar.py:269, print())
[2021-04-20 04:18:08]    INFO >> epoch 008 | valid on 'valid' subset | loss 1.043 | mrr 0.524737 | sample_size 1000 | wps 12245.8 | wpb 1000 | bsz 1000 | num_updates 2008 | best_mrr 524.737 (progress_bar.py:269, print())
[2021-04-20 04:18:08]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_best.pt (epoch 8 @ 2008 updates, score 0.524737) (writing took 0.247053 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:18:28]    INFO >> epoch 009 | loss 0.872 | mrr 0.847588 | sample_size 1000 | wps 11057 | ups 11.06 | wpb 1000 | bsz 1000 | num_updates 2259 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 15 | wall 200 (progress_bar.py:269, print())
[2021-04-20 04:18:31]    INFO >> epoch 009 | valid on 'valid' subset | loss 1.044 | mrr 0.522141 | sample_size 1000 | wps 12967.1 | wpb 1000 | bsz 1000 | num_updates 2259 | best_mrr 522.141 (progress_bar.py:269, print())
[2021-04-20 04:18:31]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 9 @ 2259 updates, score 0.522141) (writing took 0.218210 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:18:50]    INFO >> epoch 010:    242 / 252 loss=0.87, mrr=850.386, sample_size=1000, wps=11030.4, ups=11.03, wpb=1000, bsz=1000, num_updates=2500, lr=0.01, gnorm=0.021, clip=0, train_wall=29, wall=222 (progress_bar.py:262, log())
[2021-04-20 04:18:50]    INFO >> epoch 010 | loss 0.868 | mrr 0.853487 | sample_size 1000 | wps 11049.7 | ups 11.05 | wpb 1000 | bsz 1000 | num_updates 2510 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 15 | wall 223 (progress_bar.py:269, print())
[2021-04-20 04:18:54]    INFO >> epoch 010 | valid on 'valid' subset | loss 1.044 | mrr 0.524512 | sample_size 1000 | wps 13806.7 | wpb 1000 | bsz 1000 | num_updates 2510 | best_mrr 524.512 (progress_bar.py:269, print())
[2021-04-20 04:18:54]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 10 @ 2510 updates, score 0.524512) (writing took 0.153141 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:19:12]    INFO >> epoch 011 | loss 0.865 | mrr 0.856767 | sample_size 1000 | wps 11712.3 | ups 11.71 | wpb 1000 | bsz 1000 | num_updates 2761 | lr 0.01 | gnorm 0.022 | clip 0 | train_wall 13 | wall 244 (progress_bar.py:269, print())
[2021-04-20 04:19:15]    INFO >> epoch 011 | valid on 'valid' subset | loss 1.044 | mrr 0.522344 | sample_size 1000 | wps 13682.8 | wpb 1000 | bsz 1000 | num_updates 2761 | best_mrr 522.344 (progress_bar.py:269, print())
[2021-04-20 04:19:15]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 11 @ 2761 updates, score 0.522344) (writing took 0.127812 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:19:33]    INFO >> epoch 012:    240 / 252 loss=0.864, mrr=858.548, sample_size=1000, wps=11609.3, ups=11.61, wpb=1000, bsz=1000, num_updates=3000, lr=0.01, gnorm=0.022, clip=0, train_wall=27, wall=265 (progress_bar.py:262, log())
[2021-04-20 04:19:34]    INFO >> epoch 012 | loss 0.862 | mrr 0.860528 | sample_size 1000 | wps 11447.1 | ups 11.45 | wpb 1000 | bsz 1000 | num_updates 3012 | lr 0.01 | gnorm 0.022 | clip 0 | train_wall 14 | wall 266 (progress_bar.py:269, print())
[2021-04-20 04:19:37]    INFO >> epoch 012 | valid on 'valid' subset | loss 1.044 | mrr 0.522445 | sample_size 1000 | wps 12669.3 | wpb 1000 | bsz 1000 | num_updates 3012 | best_mrr 522.445 (progress_bar.py:269, print())
[2021-04-20 04:19:37]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 12 @ 3012 updates, score 0.522445) (writing took 0.173159 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:19:56]    INFO >> epoch 013 | loss 0.86 | mrr 0.863303 | sample_size 1000 | wps 11468 | ups 11.47 | wpb 1000 | bsz 1000 | num_updates 3263 | lr 0.01 | gnorm 0.022 | clip 0 | train_wall 14 | wall 288 (progress_bar.py:269, print())
[2021-04-20 04:19:59]    INFO >> epoch 013 | valid on 'valid' subset | loss 1.044 | mrr 0.524236 | sample_size 1000 | wps 13231.8 | wpb 1000 | bsz 1000 | num_updates 3263 | best_mrr 524.236 (progress_bar.py:269, print())
[2021-04-20 04:19:59]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 13 @ 3263 updates, score 0.524236) (writing took 0.121901 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:20:16]    INFO >> epoch 014:    238 / 252 loss=0.859, mrr=864.534, sample_size=1000, wps=11566.4, ups=11.57, wpb=1000, bsz=1000, num_updates=3500, lr=0.01, gnorm=0.022, clip=0, train_wall=27, wall=308 (progress_bar.py:262, log())
[2021-04-20 04:20:17]    INFO >> epoch 014 | loss 0.858 | mrr 0.866032 | sample_size 1000 | wps 11762 | ups 11.76 | wpb 1000 | bsz 1000 | num_updates 3514 | lr 0.01 | gnorm 0.022 | clip 0 | train_wall 13 | wall 310 (progress_bar.py:269, print())
[2021-04-20 04:20:20]    INFO >> epoch 014 | valid on 'valid' subset | loss 1.044 | mrr 0.523135 | sample_size 1000 | wps 13482.4 | wpb 1000 | bsz 1000 | num_updates 3514 | best_mrr 523.135 (progress_bar.py:269, print())
[2021-04-20 04:20:20]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 14 @ 3514 updates, score 0.523135) (writing took 0.126291 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:20:38]    INFO >> epoch 015 | loss 0.857 | mrr 0.867246 | sample_size 1000 | wps 11923.1 | ups 11.92 | wpb 1000 | bsz 1000 | num_updates 3765 | lr 0.01 | gnorm 0.023 | clip 0 | train_wall 13 | wall 331 (progress_bar.py:269, print())
[2021-04-20 04:20:41]    INFO >> epoch 015 | valid on 'valid' subset | loss 1.045 | mrr 0.521256 | sample_size 1000 | wps 12307 | wpb 1000 | bsz 1000 | num_updates 3765 | best_mrr 521.256 (progress_bar.py:269, print())
[2021-04-20 04:20:41]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 15 @ 3765 updates, score 0.521256) (writing took 0.115600 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:20:57]    INFO >> epoch 016:    236 / 252 loss=0.856, mrr=868.493, sample_size=1000, wps=12105.4, ups=12.11, wpb=1000, bsz=1000, num_updates=4000, lr=0.01, gnorm=0.023, clip=0, train_wall=25, wall=350 (progress_bar.py:262, log())
[2021-04-20 04:20:58]    INFO >> epoch 016 | loss 0.855 | mrr 0.869829 | sample_size 1000 | wps 12436.2 | ups 12.44 | wpb 1000 | bsz 1000 | num_updates 4016 | lr 0.01 | gnorm 0.023 | clip 0 | train_wall 12 | wall 351 (progress_bar.py:269, print())
[2021-04-20 04:21:01]    INFO >> epoch 016 | valid on 'valid' subset | loss 1.044 | mrr 0.520879 | sample_size 1000 | wps 12197.9 | wpb 1000 | bsz 1000 | num_updates 4016 | best_mrr 520.879 (progress_bar.py:269, print())
[2021-04-20 04:21:02]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 16 @ 4016 updates, score 0.520879) (writing took 0.134535 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:21:18]    INFO >> epoch 017 | loss 0.854 | mrr 0.871127 | sample_size 1000 | wps 12706.1 | ups 12.71 | wpb 1000 | bsz 1000 | num_updates 4267 | lr 0.01 | gnorm 0.023 | clip 0 | train_wall 11 | wall 371 (progress_bar.py:269, print())
[2021-04-20 04:21:21]    INFO >> epoch 017 | valid on 'valid' subset | loss 1.044 | mrr 0.520878 | sample_size 1000 | wps 14041.5 | wpb 1000 | bsz 1000 | num_updates 4267 | best_mrr 520.878 (progress_bar.py:269, print())
[2021-04-20 04:21:21]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 17 @ 4267 updates, score 0.520878) (writing took 0.121343 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:21:36]    INFO >> epoch 018:    234 / 252 loss=0.853, mrr=871.676, sample_size=1000, wps=12990.1, ups=12.99, wpb=1000, bsz=1000, num_updates=4500, lr=0.01, gnorm=0.023, clip=0, train_wall=21, wall=388 (progress_bar.py:262, log())
[2021-04-20 04:21:37]    INFO >> epoch 018 | loss 0.852 | mrr 0.87271 | sample_size 1000 | wps 13324.9 | ups 13.32 | wpb 1000 | bsz 1000 | num_updates 4518 | lr 0.01 | gnorm 0.024 | clip 0 | train_wall 10 | wall 389 (progress_bar.py:269, print())
[2021-04-20 04:21:40]    INFO >> epoch 018 | valid on 'valid' subset | loss 1.045 | mrr 0.519756 | sample_size 1000 | wps 13690.6 | wpb 1000 | bsz 1000 | num_updates 4518 | best_mrr 519.756 (progress_bar.py:269, print())
[2021-04-20 04:21:40]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/python/nbow/checkpoints/checkpoint_last.pt (epoch 18 @ 4518 updates, score 0.519756) (writing took 0.122141 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 04:21:40]    INFO >> early stop since valid performance hasn't improved for last 10 runs (train.py:191, should_stop_early())
[2021-04-20 04:21:40]    INFO >> early stop since valid performance hasn't improved for last 10 runs (train.py:272, single_main())
[2021-04-20 04:21:40]    INFO >> done training in 392.1 seconds (train.py:283, single_main())
