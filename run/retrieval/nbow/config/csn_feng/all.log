nohup: 忽略输入
[2021-04-20 03:37:08]    INFO >> Load arguments in /home/yanghe/Documents/naturalcc-dev/run/retrieval/nbow/config/csn_feng/all.yml (train.py:302, cli_main())
[2021-04-20 03:37:08]    INFO >> {'criterion': 'retrieval_cosine', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'seed': 666, 'cpu': 0, 'fp16': 0, 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'task': 'hybrid_retrieval'}, 'dataset': {'num_workers': 1, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': None, 'max_sentences': 1000, 'code_max_tokens': 200, 'query_max_tokens': 30, 'required_batch_size_multiple': 8, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': None, 'max_tokens_valid': None, 'max_sentences_valid': 1000, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'joined_dictionary': 0, 'langs': ['go', 'java', 'javascript', 'ruby', 'python', 'php']}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': 0, 'mask_whole_words': 0, 'pooler_activation_fn': 'tanh', 'source_lang': 'code_tokens', 'target_lang': 'docstring_tokens', 'source_aux_lang': 'code_tokens.wo_func', 'target_aux_lang': 'func_name', 'fraction_using_func_name': 0.3, 'load_alignments': 0, 'left_pad_source': 1, 'left_pad_target': 0, 'upsample_primary': 1, 'truncate_source': 0, 'eval_mrr': 1}, 'model': {'arch': 'nbow', 'code_embed_dim': 128, 'code_dropout': 0.1, 'code_pooling': 'weighted_mean', 'query_embed_dim': 128, 'query_dropout': 0.1, 'query_pooling': 'weighted_mean'}, 'optimization': {'max_epoch': 300, 'max_update': 0, 'clip_norm': 1, 'sentence_avg': 0, 'update_freq': [1], 'lrs': [0.01], 'min_lr': -1, 'use_bmuf': 0, 'lr_shrink': 1.0, 'force_anneal': 0, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0, 'use_old_adam': 1}, 'margin': 1}, 'checkpoint': {'save_dir': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints', 'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 10}, 'eval': {'path': '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt', 'quiet': 1, 'max_sentences': 1000, 'model_overrides': '{}', 'eval_size': 1000}} (train.py:304, cli_main())
[2021-04-20 03:37:08]    INFO >> single GPU training... (train.py:333, cli_main())
[2021-04-20 03:37:08]    INFO >> loaded 44689 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.go.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.java.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.javascript.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.ruby.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.python.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.php.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-04-20 03:37:08]    INFO >> loaded 44689 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.go.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.java.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.javascript.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.ruby.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.python.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/valid.php.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-04-20 03:37:08]    INFO >> NBOW(
  (src_encoders): ModuleDict(
    (go): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (java): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (javascript): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (ruby): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (python): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (php): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
  )
  (tgt_encoders): NBOWEncoder(
    (embed): Embedding(10000, 128, padding_idx=0)
    (weight_layer): Linear(in_features=128, out_features=1, bias=False)
  )
) (train.py:223, single_main())
[2021-04-20 03:37:08]    INFO >> model nbow, criterion SearchCosineCriterion (train.py:224, single_main())
[2021-04-20 03:37:08]    INFO >> num. model params: 8960896 (num. trained: 8960896) (train.py:227, single_main())
[2021-04-20 03:37:10]    INFO >> training on 1 GPUs (train.py:233, single_main())
[2021-04-20 03:37:10]    INFO >> max tokens per GPU = None and max sentences per GPU = 1000 (train.py:236, single_main())
[2021-04-20 03:37:10]    INFO >> no existing checkpoint found /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (ncc_trainers.py:270, load_checkpoint())
[2021-04-20 03:37:10]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-04-20 03:37:11]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.code_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-04-20 03:37:11]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.docstring_tokens', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-04-20 03:37:11]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.code_tokens.wo_func', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.code_tokens.wo_func'] (hybrid_retrieval.py:67, load_tokens_dataset())
[2021-04-20 03:37:11]    INFO >> loaded 908224 examples from: ['/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.go.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.java.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.javascript.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.ruby.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.python.func_name', '/data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/train.php.func_name'] (hybrid_retrieval.py:81, load_tokens_dataset())
[2021-04-20 03:37:12]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
/home/yanghe/Documents/naturalcc-dev/ncc/utils/gradient_clip/fairseq_clip.py:57: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
[2021-04-20 03:37:44]    INFO >> epoch 001:    501 / 909 loss=1.014, mrr=216.102, sample_size=1000, wps=16873.1, ups=16.87, wpb=1000, bsz=1000, num_updates=500, lr=0.01, gnorm=0.019, clip=0, train_wall=9, wall=34 (progress_bar.py:262, log())
[2021-04-20 03:38:09]    INFO >> epoch 001 | loss 1.007 | mrr 0.325202 | sample_size 1000 | wps 16738.8 | ups 16.74 | wpb 1000 | bsz 1000 | num_updates 908 | lr 0.01 | gnorm 0.013 | clip 0 | train_wall 16 | wall 59 (progress_bar.py:269, print())
[2021-04-20 03:38:14]    INFO >> epoch 001 | valid on 'valid' subset | loss 1.009 | mrr 0.413643 | sample_size 1000 | wps 17417.9 | wpb 1000 | bsz 1000 | num_updates 908 (progress_bar.py:269, print())
[2021-04-20 03:38:15]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 1 @ 908 updates, score 0.413643) (writing took 0.752080 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:38:23]    INFO >> epoch 002:     92 / 909 loss=0.996, mrr=481.838, sample_size=1000, wps=12826.2, ups=12.83, wpb=1000, bsz=1000, num_updates=1000, lr=0.01, gnorm=0.008, clip=0, train_wall=9, wall=73 (progress_bar.py:262, log())
[2021-04-20 03:38:53]    INFO >> epoch 002:    593 / 909 loss=0.97, mrr=644.161, sample_size=1000, wps=16732.7, ups=16.73, wpb=1000, bsz=1000, num_updates=1500, lr=0.01, gnorm=0.018, clip=0, train_wall=8, wall=103 (progress_bar.py:262, log())
[2021-04-20 03:39:12]    INFO >> epoch 002 | loss 0.963 | mrr 0.661267 | sample_size 1000 | wps 14333.6 | ups 14.33 | wpb 1000 | bsz 1000 | num_updates 1816 | lr 0.01 | gnorm 0.018 | clip 0 | train_wall 15 | wall 122 (progress_bar.py:269, print())
[2021-04-20 03:39:18]    INFO >> epoch 002 | valid on 'valid' subset | loss 1.028 | mrr 0.557338 | sample_size 1000 | wps 17419.3 | wpb 1000 | bsz 1000 | num_updates 1816 | best_mrr 557.338 (progress_bar.py:269, print())
[2021-04-20 03:39:19]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 2 @ 1816 updates, score 0.557338) (writing took 0.796951 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:39:32]    INFO >> epoch 003:    184 / 909 loss=0.931, mrr=739.073, sample_size=1000, wps=12737.9, ups=12.74, wpb=1000, bsz=1000, num_updates=2000, lr=0.01, gnorm=0.019, clip=0, train_wall=9, wall=142 (progress_bar.py:262, log())
[2021-04-20 03:40:11]    INFO >> epoch 003:    684 / 909 loss=0.908, mrr=783.648, sample_size=1000, wps=12938.1, ups=12.94, wpb=1000, bsz=1000, num_updates=2500, lr=0.01, gnorm=0.02, clip=0, train_wall=32, wall=181 (progress_bar.py:262, log())
[2021-04-20 03:40:29]    INFO >> epoch 003 | loss 0.908 | mrr 0.783989 | sample_size 1000 | wps 11800.4 | ups 11.8 | wpb 1000 | bsz 1000 | num_updates 2724 | lr 0.01 | gnorm 0.02 | clip 0 | train_wall 49 | wall 199 (progress_bar.py:269, print())
[2021-04-20 03:40:35]    INFO >> epoch 003 | valid on 'valid' subset | loss 1.024 | mrr 0.578425 | sample_size 1000 | wps 17227.9 | wpb 1000 | bsz 1000 | num_updates 2724 | best_mrr 578.425 (progress_bar.py:269, print())
[2021-04-20 03:40:36]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 3 @ 2724 updates, score 0.578425) (writing took 0.793978 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:41:00]    INFO >> epoch 004:    276 / 909 loss=0.893, mrr=806.641, sample_size=1000, wps=10254.7, ups=10.25, wpb=1000, bsz=1000, num_updates=3000, lr=0.01, gnorm=0.02, clip=0, train_wall=32, wall=230 (progress_bar.py:262, log())
[2021-04-20 03:41:39]    INFO >> epoch 004:    777 / 909 loss=0.887, mrr=816.261, sample_size=1000, wps=12678, ups=12.68, wpb=1000, bsz=1000, num_updates=3500, lr=0.01, gnorm=0.021, clip=0, train_wall=32, wall=269 (progress_bar.py:262, log())
[2021-04-20 03:41:50]    INFO >> epoch 004 | loss 0.886 | mrr 0.818571 | sample_size 1000 | wps 11227.8 | ups 11.23 | wpb 1000 | bsz 1000 | num_updates 3632 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 58 | wall 280 (progress_bar.py:269, print())
[2021-04-20 03:41:56]    INFO >> epoch 004 | valid on 'valid' subset | loss 1.022 | mrr 0.582528 | sample_size 1000 | wps 17230.8 | wpb 1000 | bsz 1000 | num_updates 3632 | best_mrr 582.528 (progress_bar.py:269, print())
[2021-04-20 03:41:57]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 4 @ 3632 updates, score 0.582528) (writing took 0.848040 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:42:28]    INFO >> epoch 005:    368 / 909 loss=0.875, mrr=833.811, sample_size=1000, wps=10212.3, ups=10.21, wpb=1000, bsz=1000, num_updates=4000, lr=0.01, gnorm=0.022, clip=0, train_wall=32, wall=318 (progress_bar.py:262, log())
[2021-04-20 03:43:07]    INFO >> epoch 005:    869 / 909 loss=0.878, mrr=829.432, sample_size=1000, wps=12773.1, ups=12.77, wpb=1000, bsz=1000, num_updates=4500, lr=0.01, gnorm=0.023, clip=0, train_wall=32, wall=357 (progress_bar.py:262, log())
[2021-04-20 03:43:11]    INFO >> epoch 005 | loss 0.875 | mrr 0.834313 | sample_size 1000 | wps 11249 | ups 11.25 | wpb 1000 | bsz 1000 | num_updates 4540 | lr 0.01 | gnorm 0.022 | clip 0 | train_wall 58 | wall 360 (progress_bar.py:269, print())
[2021-04-20 03:43:17]    INFO >> epoch 005 | valid on 'valid' subset | loss 1.022 | mrr 0.584705 | sample_size 1000 | wps 17457.7 | wpb 1000 | bsz 1000 | num_updates 4540 | best_mrr 584.705 (progress_bar.py:269, print())
[2021-04-20 03:43:17]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 5 @ 4540 updates, score 0.584705) (writing took 0.827569 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:43:56]    INFO >> epoch 006:    460 / 909 loss=0.865, mrr=847.602, sample_size=1000, wps=10234.5, ups=10.23, wpb=1000, bsz=1000, num_updates=5000, lr=0.01, gnorm=0.023, clip=0, train_wall=32, wall=406 (progress_bar.py:262, log())
[2021-04-20 03:44:32]    INFO >> epoch 006 | loss 0.868 | mrr 0.843513 | sample_size 1000 | wps 11190.8 | ups 11.19 | wpb 1000 | bsz 1000 | num_updates 5448 | lr 0.01 | gnorm 0.024 | clip 0 | train_wall 58 | wall 442 (progress_bar.py:269, print())
[2021-04-20 03:44:38]    INFO >> epoch 006 | valid on 'valid' subset | loss 1.022 | mrr 0.586574 | sample_size 1000 | wps 17733.7 | wpb 1000 | bsz 1000 | num_updates 5448 | best_mrr 586.574 (progress_bar.py:269, print())
[2021-04-20 03:44:39]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 6 @ 5448 updates, score 0.586574) (writing took 0.811330 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:44:45]    INFO >> epoch 007:     52 / 909 loss=0.87, mrr=840.117, sample_size=1000, wps=10178.5, ups=10.18, wpb=1000, bsz=1000, num_updates=5500, lr=0.01, gnorm=0.024, clip=0, train_wall=32, wall=455 (progress_bar.py:262, log())
[2021-04-20 03:45:24]    INFO >> epoch 007:    552 / 909 loss=0.86, mrr=853.599, sample_size=1000, wps=12792.2, ups=12.79, wpb=1000, bsz=1000, num_updates=6000, lr=0.01, gnorm=0.025, clip=0, train_wall=32, wall=494 (progress_bar.py:262, log())
[2021-04-20 03:45:53]    INFO >> epoch 007 | loss 0.863 | mrr 0.849807 | sample_size 1000 | wps 11219.1 | ups 11.22 | wpb 1000 | bsz 1000 | num_updates 6356 | lr 0.01 | gnorm 0.025 | clip 0 | train_wall 58 | wall 523 (progress_bar.py:269, print())
[2021-04-20 03:45:59]    INFO >> epoch 007 | valid on 'valid' subset | loss 1.021 | mrr 0.58796 | sample_size 1000 | wps 17199.8 | wpb 1000 | bsz 1000 | num_updates 6356 | best_mrr 587.96 (progress_bar.py:269, print())
[2021-04-20 03:46:00]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 7 @ 6356 updates, score 0.58796) (writing took 0.995009 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:46:14]    INFO >> epoch 008:    144 / 909 loss=0.863, mrr=849.284, sample_size=1000, wps=10173, ups=10.17, wpb=1000, bsz=1000, num_updates=6500, lr=0.01, gnorm=0.026, clip=0, train_wall=32, wall=543 (progress_bar.py:262, log())
[2021-04-20 03:46:53]    INFO >> epoch 008:    644 / 909 loss=0.859, mrr=855.164, sample_size=1000, wps=12756.2, ups=12.76, wpb=1000, bsz=1000, num_updates=7000, lr=0.01, gnorm=0.027, clip=0, train_wall=32, wall=582 (progress_bar.py:262, log())
[2021-04-20 03:47:14]    INFO >> epoch 008 | loss 0.859 | mrr 0.854528 | sample_size 1000 | wps 11211.5 | ups 11.21 | wpb 1000 | bsz 1000 | num_updates 7264 | lr 0.01 | gnorm 0.027 | clip 0 | train_wall 58 | wall 604 (progress_bar.py:269, print())
[2021-04-20 03:47:20]    INFO >> epoch 008 | valid on 'valid' subset | loss 1.022 | mrr 0.586831 | sample_size 1000 | wps 17624.2 | wpb 1000 | bsz 1000 | num_updates 7264 | best_mrr 586.831 (progress_bar.py:269, print())
[2021-04-20 03:47:20]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 8 @ 7264 updates, score 0.586831) (writing took 0.461176 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:47:41]    INFO >> epoch 009:    237 / 909 loss=0.857, mrr=856.656, sample_size=1000, wps=10282.1, ups=10.28, wpb=1000, bsz=1000, num_updates=7500, lr=0.01, gnorm=0.028, clip=0, train_wall=32, wall=631 (progress_bar.py:262, log())
[2021-04-20 03:48:18]    INFO >> epoch 009:    737 / 909 loss=0.857, mrr=857.021, sample_size=1000, wps=13851, ups=13.85, wpb=1000, bsz=1000, num_updates=8000, lr=0.01, gnorm=0.029, clip=0, train_wall=26, wall=667 (progress_bar.py:262, log())
[2021-04-20 03:48:31]    INFO >> epoch 009 | loss 0.856 | mrr 0.858212 | sample_size 1000 | wps 11731 | ups 11.73 | wpb 1000 | bsz 1000 | num_updates 8172 | lr 0.01 | gnorm 0.029 | clip 0 | train_wall 52 | wall 681 (progress_bar.py:269, print())
[2021-04-20 03:48:37]    INFO >> epoch 009 | valid on 'valid' subset | loss 1.022 | mrr 0.585894 | sample_size 1000 | wps 17413.6 | wpb 1000 | bsz 1000 | num_updates 8172 | best_mrr 585.894 (progress_bar.py:269, print())
[2021-04-20 03:48:37]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 9 @ 8172 updates, score 0.585894) (writing took 0.492890 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:49:06]    INFO >> epoch 010:    328 / 909 loss=0.852, mrr=862.488, sample_size=1000, wps=10363.6, ups=10.36, wpb=1000, bsz=1000, num_updates=8500, lr=0.01, gnorm=0.029, clip=0, train_wall=32, wall=715 (progress_bar.py:262, log())
[2021-04-20 03:49:45]    INFO >> epoch 010:    829 / 909 loss=0.856, mrr=857.739, sample_size=1000, wps=12733.4, ups=12.73, wpb=1000, bsz=1000, num_updates=9000, lr=0.01, gnorm=0.03, clip=0, train_wall=32, wall=755 (progress_bar.py:262, log())
[2021-04-20 03:49:52]    INFO >> epoch 010 | loss 0.853 | mrr 0.86159 | sample_size 1000 | wps 11306.4 | ups 11.31 | wpb 1000 | bsz 1000 | num_updates 9080 | lr 0.01 | gnorm 0.03 | clip 0 | train_wall 58 | wall 761 (progress_bar.py:269, print())
[2021-04-20 03:49:57]    INFO >> epoch 010 | valid on 'valid' subset | loss 1.022 | mrr 0.585952 | sample_size 1000 | wps 17987.4 | wpb 1000 | bsz 1000 | num_updates 9080 | best_mrr 585.952 (progress_bar.py:269, print())
[2021-04-20 03:49:58]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 10 @ 9080 updates, score 0.585952) (writing took 0.444794 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:50:33]    INFO >> epoch 011:    421 / 909 loss=0.848, mrr=867.215, sample_size=1000, wps=10427.4, ups=10.43, wpb=1000, bsz=1000, num_updates=9500, lr=0.01, gnorm=0.031, clip=0, train_wall=32, wall=803 (progress_bar.py:262, log())
[2021-04-20 03:51:11]    INFO >> epoch 011 | loss 0.851 | mrr 0.863626 | sample_size 1000 | wps 11458.4 | ups 11.46 | wpb 1000 | bsz 1000 | num_updates 9988 | lr 0.01 | gnorm 0.032 | clip 0 | train_wall 58 | wall 841 (progress_bar.py:269, print())
[2021-04-20 03:51:17]    INFO >> epoch 011 | valid on 'valid' subset | loss 1.021 | mrr 0.586765 | sample_size 1000 | wps 17257.1 | wpb 1000 | bsz 1000 | num_updates 9988 | best_mrr 586.765 (progress_bar.py:269, print())
[2021-04-20 03:51:17]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 11 @ 9988 updates, score 0.586765) (writing took 0.540820 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:51:21]    INFO >> epoch 012:     12 / 909 loss=0.855, mrr=858.366, sample_size=1000, wps=10490, ups=10.49, wpb=1000, bsz=1000, num_updates=10000, lr=0.01, gnorm=0.032, clip=0, train_wall=32, wall=850 (progress_bar.py:262, log())
[2021-04-20 03:52:00]    INFO >> epoch 012:    512 / 909 loss=0.846, mrr=870.623, sample_size=1000, wps=12627.6, ups=12.63, wpb=1000, bsz=1000, num_updates=10500, lr=0.01, gnorm=0.033, clip=0, train_wall=32, wall=890 (progress_bar.py:262, log())
[2021-04-20 03:52:32]    INFO >> epoch 012 | loss 0.849 | mrr 0.865979 | sample_size 1000 | wps 11197.3 | ups 11.2 | wpb 1000 | bsz 1000 | num_updates 10896 | lr 0.01 | gnorm 0.033 | clip 0 | train_wall 58 | wall 922 (progress_bar.py:269, print())
[2021-04-20 03:52:38]    INFO >> epoch 012 | valid on 'valid' subset | loss 1.022 | mrr 0.585943 | sample_size 1000 | wps 17605.5 | wpb 1000 | bsz 1000 | num_updates 10896 | best_mrr 585.943 (progress_bar.py:269, print())
[2021-04-20 03:52:38]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 12 @ 10896 updates, score 0.585943) (writing took 0.448193 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:52:49]    INFO >> epoch 013:    104 / 909 loss=0.851, mrr=863.605, sample_size=1000, wps=10272.2, ups=10.27, wpb=1000, bsz=1000, num_updates=11000, lr=0.01, gnorm=0.033, clip=0, train_wall=32, wall=939 (progress_bar.py:262, log())
[2021-04-20 03:53:28]    INFO >> epoch 013:    604 / 909 loss=0.846, mrr=870.079, sample_size=1000, wps=12794.9, ups=12.79, wpb=1000, bsz=1000, num_updates=11500, lr=0.01, gnorm=0.034, clip=0, train_wall=32, wall=978 (progress_bar.py:262, log())
[2021-04-20 03:53:52]    INFO >> epoch 013 | loss 0.847 | mrr 0.867694 | sample_size 1000 | wps 11375.9 | ups 11.38 | wpb 1000 | bsz 1000 | num_updates 11804 | lr 0.01 | gnorm 0.034 | clip 0 | train_wall 58 | wall 1001 (progress_bar.py:269, print())
[2021-04-20 03:53:57]    INFO >> epoch 013 | valid on 'valid' subset | loss 1.022 | mrr 0.585463 | sample_size 1000 | wps 17358.8 | wpb 1000 | bsz 1000 | num_updates 11804 | best_mrr 585.463 (progress_bar.py:269, print())
[2021-04-20 03:53:58]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 13 @ 11804 updates, score 0.585463) (writing took 0.520377 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:54:16]    INFO >> epoch 014:    196 / 909 loss=0.847, mrr=867.183, sample_size=1000, wps=10395.2, ups=10.4, wpb=1000, bsz=1000, num_updates=12000, lr=0.01, gnorm=0.035, clip=0, train_wall=32, wall=1026 (progress_bar.py:262, log())
[2021-04-20 03:54:55]    INFO >> epoch 014:    696 / 909 loss=0.846, mrr=869.647, sample_size=1000, wps=12843.9, ups=12.84, wpb=1000, bsz=1000, num_updates=12500, lr=0.01, gnorm=0.036, clip=0, train_wall=32, wall=1065 (progress_bar.py:262, log())
[2021-04-20 03:55:12]    INFO >> epoch 014 | loss 0.846 | mrr 0.869419 | sample_size 1000 | wps 11315.6 | ups 11.32 | wpb 1000 | bsz 1000 | num_updates 12712 | lr 0.01 | gnorm 0.036 | clip 0 | train_wall 58 | wall 1082 (progress_bar.py:269, print())
[2021-04-20 03:55:18]    INFO >> epoch 014 | valid on 'valid' subset | loss 1.022 | mrr 0.586041 | sample_size 1000 | wps 17383 | wpb 1000 | bsz 1000 | num_updates 12712 | best_mrr 586.041 (progress_bar.py:269, print())
[2021-04-20 03:55:18]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 14 @ 12712 updates, score 0.586041) (writing took 0.536626 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:55:43]    INFO >> epoch 015:    289 / 909 loss=0.844, mrr=871.171, sample_size=1000, wps=10366.1, ups=10.37, wpb=1000, bsz=1000, num_updates=13000, lr=0.01, gnorm=0.036, clip=0, train_wall=32, wall=1113 (progress_bar.py:262, log())
[2021-04-20 03:56:22]    INFO >> epoch 015:    789 / 909 loss=0.847, mrr=868.029, sample_size=1000, wps=12889.7, ups=12.89, wpb=1000, bsz=1000, num_updates=13500, lr=0.01, gnorm=0.037, clip=0, train_wall=32, wall=1152 (progress_bar.py:262, log())
[2021-04-20 03:56:30]    INFO >> epoch 015 | loss 0.845 | mrr 0.870701 | sample_size 1000 | wps 11594.3 | ups 11.59 | wpb 1000 | bsz 1000 | num_updates 13620 | lr 0.01 | gnorm 0.037 | clip 0 | train_wall 55 | wall 1160 (progress_bar.py:269, print())
[2021-04-20 03:56:35]    INFO >> epoch 015 | valid on 'valid' subset | loss 1.022 | mrr 0.585232 | sample_size 1000 | wps 17196.7 | wpb 1000 | bsz 1000 | num_updates 13620 | best_mrr 585.232 (progress_bar.py:269, print())
[2021-04-20 03:56:36]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 15 @ 13620 updates, score 0.585232) (writing took 0.626502 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:57:08]    INFO >> epoch 016:    381 / 909 loss=0.842, mrr=874.454, sample_size=1000, wps=10812.2, ups=10.81, wpb=1000, bsz=1000, num_updates=14000, lr=0.01, gnorm=0.038, clip=0, train_wall=29, wall=1198 (progress_bar.py:262, log())
[2021-04-20 03:57:48]    INFO >> epoch 016:    881 / 909 loss=0.847, mrr=867.814, sample_size=1000, wps=12647.3, ups=12.65, wpb=1000, bsz=1000, num_updates=14500, lr=0.01, gnorm=0.038, clip=0, train_wall=32, wall=1238 (progress_bar.py:262, log())
[2021-04-20 03:57:50]    INFO >> epoch 016 | loss 0.843 | mrr 0.871963 | sample_size 1000 | wps 11345.9 | ups 11.35 | wpb 1000 | bsz 1000 | num_updates 14528 | lr 0.01 | gnorm 0.038 | clip 0 | train_wall 58 | wall 1240 (progress_bar.py:269, print())
[2021-04-20 03:57:56]    INFO >> epoch 016 | valid on 'valid' subset | loss 1.022 | mrr 0.585074 | sample_size 1000 | wps 17631 | wpb 1000 | bsz 1000 | num_updates 14528 | best_mrr 585.074 (progress_bar.py:269, print())
[2021-04-20 03:57:56]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 16 @ 14528 updates, score 0.585074) (writing took 0.494955 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:58:36]    INFO >> epoch 017:    473 / 909 loss=0.839, mrr=876.793, sample_size=1000, wps=10320.9, ups=10.32, wpb=1000, bsz=1000, num_updates=15000, lr=0.01, gnorm=0.039, clip=0, train_wall=32, wall=1286 (progress_bar.py:262, log())
[2021-04-20 03:59:11]    INFO >> epoch 017 | loss 0.842 | mrr 0.873097 | sample_size 1000 | wps 11303.7 | ups 11.3 | wpb 1000 | bsz 1000 | num_updates 15436 | lr 0.01 | gnorm 0.039 | clip 0 | train_wall 58 | wall 1320 (progress_bar.py:269, print())
[2021-04-20 03:59:16]    INFO >> epoch 017 | valid on 'valid' subset | loss 1.022 | mrr 0.584468 | sample_size 1000 | wps 17906.4 | wpb 1000 | bsz 1000 | num_updates 15436 | best_mrr 584.468 (progress_bar.py:269, print())
[2021-04-20 03:59:17]    INFO >> saved checkpoint /data/yanghe/ncc_data/codexglue/code_to_text/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 17 @ 15436 updates, score 0.584468) (writing took 0.470084 seconds) (checkpoint_utils.py:81, save_checkpoint())
[2021-04-20 03:59:17]    INFO >> early stop since valid performance hasn't improved for last 10 runs (train.py:191, should_stop_early())
[2021-04-20 03:59:17]    INFO >> early stop since valid performance hasn't improved for last 10 runs (train.py:272, single_main())
[2021-04-20 03:59:17]    INFO >> done training in 1325.0 seconds (train.py:283, single_main())
