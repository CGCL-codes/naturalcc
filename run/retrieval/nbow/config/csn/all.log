nohup: ignoring input
Using backend: pytorch
[2021-09-26 16:28:08]    INFO >> Load arguments in /home/wanyao/yang/naturalcc-master/run/retrieval/nbow/config/csn/all.yml (train.py:302, cli_main())
[2021-09-26 16:28:08]    INFO >> {'criterion': 'retrieval_cosine', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'seed': 666, 'cpu': 0, 'fp16': 0, 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'task': 'hybrid_retrieval'}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 0, 'max_tokens': None, 'max_sentences': 1000, 'code_max_tokens': 200, 'query_max_tokens': 30, 'required_batch_size_multiple': 8, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': None, 'max_tokens_valid': None, 'max_sentences_valid': 1000, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'joined_dictionary': 0, 'langs': ['go', 'java', 'javascript', 'ruby', 'python', 'php']}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': 0, 'mask_whole_words': 0, 'pooler_activation_fn': 'tanh', 'source_lang': 'code_tokens', 'target_lang': 'docstring_tokens', 'source_aux_lang': 'code_tokens.wo_func', 'target_aux_lang': 'func_name', 'fraction_using_func_name': 0.1, 'load_alignments': 0, 'left_pad_source': 1, 'left_pad_target': 0, 'upsample_primary': 1, 'truncate_source': 0, 'eval_mrr': 1}, 'model': {'arch': 'nbow', 'code_embed_dim': 128, 'code_dropout': 0.1, 'code_pooling': 'weighted_mean', 'query_embed_dim': 128, 'query_dropout': 0.1, 'query_pooling': 'weighted_mean'}, 'optimization': {'max_epoch': 300, 'max_update': 0, 'clip_norm_version': 'tf_clip_by_global_norm', 'clip_norm': 1, 'sentence_avg': 0, 'update_freq': [1], 'lrs': [0.01], 'min_lr': -1, 'use_bmuf': 0, 'lr_shrink': 1.0, 'force_anneal': 0, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0, 'use_old_adam': 1}, 'margin': 1}, 'checkpoint': {'save_dir': '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints', 'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'mrr', 'maximize_best_checkpoint_metric': 1, 'patience': 5}, 'eval': {'path': '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt', 'quiet': 1, 'max_sentences': 1000, 'model_overrides': '{}', 'eval_size': -1}} (train.py:304, cli_main())
[2021-09-26 16:28:08]    INFO >> single GPU training... (train.py:333, cli_main())
[2021-09-26 16:28:08]    INFO >> loaded 89154 examples from: ['/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.go.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.java.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.javascript.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.ruby.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.python.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.php.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-09-26 16:28:08]    INFO >> loaded 89154 examples from: ['/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.go.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.java.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.javascript.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.ruby.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.python.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/valid.php.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-09-26 16:28:08]    INFO >> NBOW(
  (src_encoders): ModuleDict(
    (go): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (java): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (javascript): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (ruby): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (python): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
    (php): NBOWEncoder(
      (embed): Embedding(10000, 128, padding_idx=0)
      (weight_layer): Linear(in_features=128, out_features=1, bias=False)
    )
  )
  (tgt_encoders): NBOWEncoder(
    (embed): Embedding(10000, 128, padding_idx=0)
    (weight_layer): Linear(in_features=128, out_features=1, bias=False)
  )
) (train.py:223, single_main())
[2021-09-26 16:28:08]    INFO >> model nbow, criterion SearchCosineCriterion (train.py:224, single_main())
[2021-09-26 16:28:08]    INFO >> num. model params: 8960896 (num. trained: 8960896) (train.py:225, single_main())
[2021-09-26 16:28:14]    INFO >> training on 1 GPUs (train.py:233, single_main())
[2021-09-26 16:28:14]    INFO >> max tokens per GPU = None and max sentences per GPU = 1000 (train.py:234, single_main())
[2021-09-26 16:28:14]    INFO >> no existing checkpoint found /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (ncc_trainers.py:270, load_checkpoint())
[2021-09-26 16:28:14]    INFO >> loading train data for epoch 1 (ncc_trainers.py:285, get_train_iterator())
[2021-09-26 16:28:15]    INFO >> loaded 1880853 examples from: ['/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.go.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.java.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.javascript.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.ruby.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.python.code_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.php.code_tokens'] (hybrid_retrieval.py:54, load_tokens_dataset())
[2021-09-26 16:28:15]    INFO >> loaded 1880853 examples from: ['/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.go.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.java.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.javascript.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.ruby.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.python.docstring_tokens', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.php.docstring_tokens'] (hybrid_retrieval.py:55, load_tokens_dataset())
[2021-09-26 16:28:16]    INFO >> loaded 1880853 examples from: ['/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.go.code_tokens.wo_func', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.java.code_tokens.wo_func', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.javascript.code_tokens.wo_func', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.ruby.code_tokens.wo_func', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.python.code_tokens.wo_func', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.php.code_tokens.wo_func'] (hybrid_retrieval.py:67, load_tokens_dataset())
[2021-09-26 16:28:16]    INFO >> loaded 1880853 examples from: ['/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.go.func_name', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.java.func_name', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.javascript.func_name', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.ruby.func_name', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.python.func_name', '/home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/train.php.func_name'] (hybrid_retrieval.py:81, load_tokens_dataset())
[2021-09-26 16:28:18]    INFO >> NOTE: your device may support faster training with fp16 (ncc_trainers.py:155, _setup_optimizer())
[2021-09-26 16:28:48]    INFO >> epoch 001:    500 / 1881 loss=1.011, mrr=195.81, sample_size=1000, wps=27147.9, ups=27.15, wpb=1000, bsz=1000, num_updates=500, lr=0.01, gnorm=0.017, clip=0, train_wall=12, wall=34 (progress_bar.py:260, log())
[2021-09-26 16:29:07]    INFO >> epoch 001:   1000 / 1881 loss=0.992, mrr=418.093, sample_size=1000, wps=27091.9, ups=27.09, wpb=1000, bsz=1000, num_updates=1000, lr=0.01, gnorm=0.009, clip=0, train_wall=12, wall=53 (progress_bar.py:260, log())
[2021-09-26 16:29:26]    INFO >> epoch 001:   1501 / 1881 loss=0.977, mrr=562.273, sample_size=1000, wps=26165.8, ups=26.17, wpb=1000, bsz=1000, num_updates=1500, lr=0.01, gnorm=0.013, clip=0, train_wall=12, wall=72 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:29:40]    INFO >> epoch 001 | loss 0.987 | mrr 0.440118 | sample_size 1000 | wps 26764.4 | ups 26.76 | wpb 1000 | bsz 1000 | num_updates 1880 | lr 0.01 | gnorm 0.014 | clip 0 | train_wall 44 | wall 86 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:29:51]    INFO >> epoch 001 | valid on 'valid' subset | loss 0.99 | mrr 0.592341 | sample_size 1000 | wps 26217 | wpb 1000 | bsz 1000 | num_updates 1880 (progress_bar.py:269, print())
[2021-09-26 16:29:51]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 1 @ 1880 updates, score 0.592341) (writing took 0.369453 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:30:08]    INFO >> epoch 002:    120 / 1881 loss=0.958, mrr=644.467, sample_size=1000, wps=11963.6, ups=11.96, wpb=1000, bsz=1000, num_updates=2000, lr=0.01, gnorm=0.017, clip=0, train_wall=11, wall=114 (progress_bar.py:260, log())
[2021-09-26 16:30:26]    INFO >> epoch 002:    621 / 1881 loss=0.937, mrr=697.623, sample_size=1000, wps=27289.8, ups=27.29, wpb=1000, bsz=1000, num_updates=2500, lr=0.01, gnorm=0.019, clip=0, train_wall=11, wall=132 (progress_bar.py:260, log())
[2021-09-26 16:30:45]    INFO >> epoch 002:   1121 / 1881 loss=0.929, mrr=711.312, sample_size=1000, wps=25932.6, ups=25.93, wpb=1000, bsz=1000, num_updates=3000, lr=0.01, gnorm=0.019, clip=0, train_wall=12, wall=151 (progress_bar.py:260, log())
[2021-09-26 16:31:04]    INFO >> epoch 002:   1621 / 1881 loss=0.924, mrr=719.103, sample_size=1000, wps=26157.7, ups=26.16, wpb=1000, bsz=1000, num_updates=3500, lr=0.01, gnorm=0.02, clip=0, train_wall=12, wall=171 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:31:15]    INFO >> epoch 002 | loss 0.929 | mrr 0.710316 | sample_size 1000 | wps 19834.4 | ups 19.83 | wpb 1000 | bsz 1000 | num_updates 3760 | lr 0.01 | gnorm 0.019 | clip 0 | train_wall 44 | wall 181 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:31:26]    INFO >> epoch 002 | valid on 'valid' subset | loss 0.966 | mrr 0.650375 | sample_size 1000 | wps 25720.6 | wpb 1000 | bsz 1000 | num_updates 3760 | best_mrr 650.375 (progress_bar.py:269, print())
[2021-09-26 16:31:26]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 2 @ 3760 updates, score 0.650375) (writing took 0.491468 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:31:47]    INFO >> epoch 003:    240 / 1881 loss=0.909, mrr=745.089, sample_size=1000, wps=11732.5, ups=11.73, wpb=1000, bsz=1000, num_updates=4000, lr=0.01, gnorm=0.02, clip=0, train_wall=12, wall=213 (progress_bar.py:260, log())
[2021-09-26 16:32:06]    INFO >> epoch 003:    741 / 1881 loss=0.901, mrr=758.195, sample_size=1000, wps=27086, ups=27.09, wpb=1000, bsz=1000, num_updates=4500, lr=0.01, gnorm=0.021, clip=0, train_wall=12, wall=232 (progress_bar.py:260, log())
[2021-09-26 16:32:24]    INFO >> epoch 003:   1241 / 1881 loss=0.904, mrr=754.229, sample_size=1000, wps=27196.1, ups=27.2, wpb=1000, bsz=1000, num_updates=5000, lr=0.01, gnorm=0.022, clip=0, train_wall=12, wall=250 (progress_bar.py:260, log())
[2021-09-26 16:32:43]    INFO >> epoch 003:   1741 / 1881 loss=0.904, mrr=752.252, sample_size=1000, wps=26481.3, ups=26.48, wpb=1000, bsz=1000, num_updates=5500, lr=0.01, gnorm=0.022, clip=0, train_wall=12, wall=269 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:32:49]    INFO >> epoch 003 | loss 0.902 | mrr 0.756178 | sample_size 1000 | wps 20088.9 | ups 20.09 | wpb 1000 | bsz 1000 | num_updates 5640 | lr 0.01 | gnorm 0.021 | clip 0 | train_wall 44 | wall 275 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:32:59]    INFO >> epoch 003 | valid on 'valid' subset | loss 0.96 | mrr 0.656474 | sample_size 1000 | wps 26059.8 | wpb 1000 | bsz 1000 | num_updates 5640 | best_mrr 656.474 (progress_bar.py:269, print())
[2021-09-26 16:33:00]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 3 @ 5640 updates, score 0.656474) (writing took 0.504964 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:33:25]    INFO >> epoch 004:    360 / 1881 loss=0.891, mrr=773.202, sample_size=1000, wps=11926.6, ups=11.93, wpb=1000, bsz=1000, num_updates=6000, lr=0.01, gnorm=0.023, clip=0, train_wall=12, wall=311 (progress_bar.py:260, log())
[2021-09-26 16:33:41]    INFO >> epoch 004:    860 / 1881 loss=0.89, mrr=774.758, sample_size=1000, wps=29825.8, ups=29.83, wpb=1000, bsz=1000, num_updates=6500, lr=0.01, gnorm=0.024, clip=0, train_wall=10, wall=328 (progress_bar.py:260, log())
[2021-09-26 16:34:00]    INFO >> epoch 004:   1361 / 1881 loss=0.893, mrr=768.552, sample_size=1000, wps=27555, ups=27.55, wpb=1000, bsz=1000, num_updates=7000, lr=0.01, gnorm=0.024, clip=0, train_wall=12, wall=346 (progress_bar.py:260, log())
[2021-09-26 16:34:17]    INFO >> epoch 004:   1861 / 1881 loss=0.895, mrr=764.771, sample_size=1000, wps=29159.9, ups=29.16, wpb=1000, bsz=1000, num_updates=7500, lr=0.01, gnorm=0.025, clip=0, train_wall=11, wall=363 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:34:18]    INFO >> epoch 004 | loss 0.891 | mrr 0.771669 | sample_size 1000 | wps 20990.3 | ups 20.99 | wpb 1000 | bsz 1000 | num_updates 7520 | lr 0.01 | gnorm 0.024 | clip 0 | train_wall 41 | wall 364 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:34:29]    INFO >> epoch 004 | valid on 'valid' subset | loss 0.958 | mrr 0.660401 | sample_size 1000 | wps 23419.4 | wpb 1000 | bsz 1000 | num_updates 7520 | best_mrr 660.401 (progress_bar.py:269, print())
[2021-09-26 16:34:30]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 4 @ 7520 updates, score 0.660401) (writing took 0.495778 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:34:59]    INFO >> epoch 005:    480 / 1881 loss=0.88, mrr=788.989, sample_size=1000, wps=11753.8, ups=11.75, wpb=1000, bsz=1000, num_updates=8000, lr=0.01, gnorm=0.026, clip=0, train_wall=12, wall=405 (progress_bar.py:260, log())
[2021-09-26 16:35:17]    INFO >> epoch 005:    981 / 1881 loss=0.885, mrr=781.028, sample_size=1000, wps=27535.6, ups=27.54, wpb=1000, bsz=1000, num_updates=8500, lr=0.01, gnorm=0.026, clip=0, train_wall=12, wall=424 (progress_bar.py:260, log())
[2021-09-26 16:35:36]    INFO >> epoch 005:   1481 / 1881 loss=0.887, mrr=776.594, sample_size=1000, wps=26706.6, ups=26.71, wpb=1000, bsz=1000, num_updates=9000, lr=0.01, gnorm=0.027, clip=0, train_wall=12, wall=442 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:35:52]    INFO >> epoch 005 | loss 0.885 | mrr 0.780093 | sample_size 1000 | wps 20080.3 | ups 20.08 | wpb 1000 | bsz 1000 | num_updates 9400 | lr 0.01 | gnorm 0.027 | clip 0 | train_wall 44 | wall 458 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:36:02]    INFO >> epoch 005 | valid on 'valid' subset | loss 0.957 | mrr 0.661542 | sample_size 1000 | wps 28095.2 | wpb 1000 | bsz 1000 | num_updates 9400 | best_mrr 661.542 (progress_bar.py:269, print())
[2021-09-26 16:36:03]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 5 @ 9400 updates, score 0.661542) (writing took 0.499622 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:36:18]    INFO >> epoch 006:    101 / 1881 loss=0.887, mrr=776.636, sample_size=1000, wps=11841.9, ups=11.84, wpb=1000, bsz=1000, num_updates=9500, lr=0.01, gnorm=0.028, clip=0, train_wall=12, wall=485 (progress_bar.py:260, log())
[2021-09-26 16:36:38]    INFO >> epoch 006:    601 / 1881 loss=0.876, mrr=793.149, sample_size=1000, wps=26208.2, ups=26.21, wpb=1000, bsz=1000, num_updates=10000, lr=0.01, gnorm=0.029, clip=0, train_wall=12, wall=504 (progress_bar.py:260, log())
[2021-09-26 16:36:56]    INFO >> epoch 006:   1101 / 1881 loss=0.882, mrr=784.849, sample_size=1000, wps=26593.5, ups=26.59, wpb=1000, bsz=1000, num_updates=10500, lr=0.01, gnorm=0.029, clip=0, train_wall=12, wall=522 (progress_bar.py:260, log())
[2021-09-26 16:37:15]    INFO >> epoch 006:   1601 / 1881 loss=0.884, mrr=781.296, sample_size=1000, wps=26882.2, ups=26.88, wpb=1000, bsz=1000, num_updates=11000, lr=0.01, gnorm=0.03, clip=0, train_wall=12, wall=541 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:37:26]    INFO >> epoch 006 | loss 0.881 | mrr 0.785683 | sample_size 1000 | wps 20043.5 | ups 20.04 | wpb 1000 | bsz 1000 | num_updates 11280 | lr 0.01 | gnorm 0.029 | clip 0 | train_wall 45 | wall 552 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:37:37]    INFO >> epoch 006 | valid on 'valid' subset | loss 0.956 | mrr 0.661833 | sample_size 1000 | wps 25477.9 | wpb 1000 | bsz 1000 | num_updates 11280 | best_mrr 661.833 (progress_bar.py:269, print())
[2021-09-26 16:37:37]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 6 @ 11280 updates, score 0.661833) (writing took 0.556817 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:37:57]    INFO >> epoch 007:    220 / 1881 loss=0.879, mrr=788.648, sample_size=1000, wps=11773.5, ups=11.77, wpb=1000, bsz=1000, num_updates=11500, lr=0.01, gnorm=0.03, clip=0, train_wall=12, wall=583 (progress_bar.py:260, log())
[2021-09-26 16:38:16]    INFO >> epoch 007:    720 / 1881 loss=0.875, mrr=793.857, sample_size=1000, wps=26579.6, ups=26.58, wpb=1000, bsz=1000, num_updates=12000, lr=0.01, gnorm=0.031, clip=0, train_wall=12, wall=602 (progress_bar.py:260, log())
[2021-09-26 16:38:35]    INFO >> epoch 007:   1220 / 1881 loss=0.879, mrr=788.211, sample_size=1000, wps=26740.1, ups=26.74, wpb=1000, bsz=1000, num_updates=12500, lr=0.01, gnorm=0.031, clip=0, train_wall=12, wall=621 (progress_bar.py:260, log())
[2021-09-26 16:38:53]    INFO >> epoch 007:   1721 / 1881 loss=0.881, mrr=783.941, sample_size=1000, wps=27379.8, ups=27.38, wpb=1000, bsz=1000, num_updates=13000, lr=0.01, gnorm=0.032, clip=0, train_wall=11, wall=639 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:39:00]    INFO >> epoch 007 | loss 0.878 | mrr 0.789818 | sample_size 1000 | wps 19937.8 | ups 19.94 | wpb 1000 | bsz 1000 | num_updates 13160 | lr 0.01 | gnorm 0.032 | clip 0 | train_wall 44 | wall 646 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:39:11]    INFO >> epoch 007 | valid on 'valid' subset | loss 0.955 | mrr 0.662081 | sample_size 1000 | wps 26312.2 | wpb 1000 | bsz 1000 | num_updates 13160 | best_mrr 662.081 (progress_bar.py:269, print())
[2021-09-26 16:39:11]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 7 @ 13160 updates, score 0.662081) (writing took 0.541274 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:39:36]    INFO >> epoch 008:    340 / 1881 loss=0.873, mrr=796.015, sample_size=1000, wps=11651.2, ups=11.65, wpb=1000, bsz=1000, num_updates=13500, lr=0.01, gnorm=0.033, clip=0, train_wall=12, wall=682 (progress_bar.py:260, log())
[2021-09-26 16:39:55]    INFO >> epoch 008:    841 / 1881 loss=0.873, mrr=796.058, sample_size=1000, wps=26153.2, ups=26.15, wpb=1000, bsz=1000, num_updates=14000, lr=0.01, gnorm=0.033, clip=0, train_wall=12, wall=701 (progress_bar.py:260, log())
[2021-09-26 16:40:14]    INFO >> epoch 008:   1341 / 1881 loss=0.877, mrr=789.74, sample_size=1000, wps=26851.7, ups=26.85, wpb=1000, bsz=1000, num_updates=14500, lr=0.01, gnorm=0.034, clip=0, train_wall=12, wall=720 (progress_bar.py:260, log())
[2021-09-26 16:40:33]    INFO >> epoch 008:   1841 / 1881 loss=0.879, mrr=786.624, sample_size=1000, wps=26680.8, ups=26.68, wpb=1000, bsz=1000, num_updates=15000, lr=0.01, gnorm=0.034, clip=0, train_wall=12, wall=739 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:40:35]    INFO >> epoch 008 | loss 0.875 | mrr 0.792725 | sample_size 1000 | wps 19835.2 | ups 19.84 | wpb 1000 | bsz 1000 | num_updates 15040 | lr 0.01 | gnorm 0.034 | clip 0 | train_wall 44 | wall 741 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:40:45]    INFO >> epoch 008 | valid on 'valid' subset | loss 0.955 | mrr 0.662784 | sample_size 1000 | wps 24964.7 | wpb 1000 | bsz 1000 | num_updates 15040 | best_mrr 662.784 (progress_bar.py:269, print())
[2021-09-26 16:40:46]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 8 @ 15040 updates, score 0.662784) (writing took 0.525004 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:41:16]    INFO >> epoch 009:    461 / 1881 loss=0.869, mrr=802.688, sample_size=1000, wps=11518.3, ups=11.52, wpb=1000, bsz=1000, num_updates=15500, lr=0.01, gnorm=0.035, clip=0, train_wall=12, wall=782 (progress_bar.py:260, log())
[2021-09-26 16:41:34]    INFO >> epoch 009:    961 / 1881 loss=0.872, mrr=796.772, sample_size=1000, wps=27223.7, ups=27.22, wpb=1000, bsz=1000, num_updates=16000, lr=0.01, gnorm=0.035, clip=0, train_wall=11, wall=800 (progress_bar.py:260, log())
[2021-09-26 16:41:53]    INFO >> epoch 009:   1461 / 1881 loss=0.876, mrr=791.551, sample_size=1000, wps=26690.5, ups=26.69, wpb=1000, bsz=1000, num_updates=16500, lr=0.01, gnorm=0.036, clip=0, train_wall=12, wall=819 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:42:10]    INFO >> epoch 009 | loss 0.873 | mrr 0.795407 | sample_size 1000 | wps 19763.2 | ups 19.76 | wpb 1000 | bsz 1000 | num_updates 16920 | lr 0.01 | gnorm 0.036 | clip 0 | train_wall 44 | wall 836 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:42:21]    INFO >> epoch 009 | valid on 'valid' subset | loss 0.955 | mrr 0.661588 | sample_size 1000 | wps 24325.2 | wpb 1000 | bsz 1000 | num_updates 16920 | best_mrr 661.588 (progress_bar.py:269, print())
[2021-09-26 16:42:21]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 9 @ 16920 updates, score 0.661588) (writing took 0.332615 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:42:36]    INFO >> epoch 010:     80 / 1881 loss=0.875, mrr=792.054, sample_size=1000, wps=11630.1, ups=11.63, wpb=1000, bsz=1000, num_updates=17000, lr=0.01, gnorm=0.037, clip=0, train_wall=12, wall=862 (progress_bar.py:260, log())
[2021-09-26 16:42:54]    INFO >> epoch 010:    580 / 1881 loss=0.867, mrr=804.086, sample_size=1000, wps=27935.2, ups=27.94, wpb=1000, bsz=1000, num_updates=17500, lr=0.01, gnorm=0.037, clip=0, train_wall=12, wall=880 (progress_bar.py:260, log())
[2021-09-26 16:43:13]    INFO >> epoch 010:   1081 / 1881 loss=0.871, mrr=797.717, sample_size=1000, wps=26570.4, ups=26.57, wpb=1000, bsz=1000, num_updates=18000, lr=0.01, gnorm=0.038, clip=0, train_wall=12, wall=899 (progress_bar.py:260, log())
[2021-09-26 16:43:32]    INFO >> epoch 010:   1581 / 1881 loss=0.874, mrr=792.102, sample_size=1000, wps=26279.4, ups=26.28, wpb=1000, bsz=1000, num_updates=18500, lr=0.01, gnorm=0.038, clip=0, train_wall=12, wall=918 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:43:44]    INFO >> epoch 010 | loss 0.871 | mrr 0.797244 | sample_size 1000 | wps 19960.3 | ups 19.96 | wpb 1000 | bsz 1000 | num_updates 18800 | lr 0.01 | gnorm 0.038 | clip 0 | train_wall 44 | wall 930 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:43:54]    INFO >> epoch 010 | valid on 'valid' subset | loss 0.954 | mrr 0.66216 | sample_size 1000 | wps 27661.1 | wpb 1000 | bsz 1000 | num_updates 18800 | best_mrr 662.16 (progress_bar.py:269, print())
[2021-09-26 16:43:55]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 10 @ 18800 updates, score 0.66216) (writing took 0.334278 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:44:14]    INFO >> epoch 011:    200 / 1881 loss=0.87, mrr=798.417, sample_size=1000, wps=11825.7, ups=11.83, wpb=1000, bsz=1000, num_updates=19000, lr=0.01, gnorm=0.038, clip=0, train_wall=12, wall=960 (progress_bar.py:260, log())
[2021-09-26 16:44:32]    INFO >> epoch 011:    700 / 1881 loss=0.867, mrr=804.21, sample_size=1000, wps=27377.4, ups=27.38, wpb=1000, bsz=1000, num_updates=19500, lr=0.01, gnorm=0.039, clip=0, train_wall=11, wall=978 (progress_bar.py:260, log())
[2021-09-26 16:44:51]    INFO >> epoch 011:   1201 / 1881 loss=0.871, mrr=797.592, sample_size=1000, wps=26454.9, ups=26.45, wpb=1000, bsz=1000, num_updates=20000, lr=0.01, gnorm=0.039, clip=0, train_wall=12, wall=997 (progress_bar.py:260, log())
[2021-09-26 16:45:10]    INFO >> epoch 011:   1701 / 1881 loss=0.873, mrr=793.171, sample_size=1000, wps=26193.1, ups=26.19, wpb=1000, bsz=1000, num_updates=20500, lr=0.01, gnorm=0.04, clip=0, train_wall=12, wall=1016 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:45:17]    INFO >> epoch 011 | loss 0.87 | mrr 0.799056 | sample_size 1000 | wps 20165.3 | ups 20.17 | wpb 1000 | bsz 1000 | num_updates 20680 | lr 0.01 | gnorm 0.039 | clip 0 | train_wall 44 | wall 1023 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:45:28]    INFO >> epoch 011 | valid on 'valid' subset | loss 0.953 | mrr 0.663595 | sample_size 1000 | wps 29167.3 | wpb 1000 | bsz 1000 | num_updates 20680 | best_mrr 663.595 (progress_bar.py:269, print())
[2021-09-26 16:45:28]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 11 @ 20680 updates, score 0.663595) (writing took 0.534394 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:45:52]    INFO >> epoch 012:    320 / 1881 loss=0.866, mrr=804.118, sample_size=1000, wps=11864.6, ups=11.86, wpb=1000, bsz=1000, num_updates=21000, lr=0.01, gnorm=0.04, clip=0, train_wall=12, wall=1059 (progress_bar.py:260, log())
[2021-09-26 16:46:11]    INFO >> epoch 012:    820 / 1881 loss=0.867, mrr=803.592, sample_size=1000, wps=26575.5, ups=26.58, wpb=1000, bsz=1000, num_updates=21500, lr=0.01, gnorm=0.041, clip=0, train_wall=12, wall=1077 (progress_bar.py:260, log())
[2021-09-26 16:46:30]    INFO >> epoch 012:   1320 / 1881 loss=0.87, mrr=798.063, sample_size=1000, wps=27074.7, ups=27.07, wpb=1000, bsz=1000, num_updates=22000, lr=0.01, gnorm=0.041, clip=0, train_wall=12, wall=1096 (progress_bar.py:260, log())
[2021-09-26 16:46:48]    INFO >> epoch 012:   1821 / 1881 loss=0.873, mrr=794.726, sample_size=1000, wps=27455.6, ups=27.46, wpb=1000, bsz=1000, num_updates=22500, lr=0.01, gnorm=0.041, clip=0, train_wall=12, wall=1114 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:46:51]    INFO >> epoch 012 | loss 0.869 | mrr 0.800624 | sample_size 1000 | wps 20125.2 | ups 20.13 | wpb 1000 | bsz 1000 | num_updates 22560 | lr 0.01 | gnorm 0.041 | clip 0 | train_wall 44 | wall 1117 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:47:02]    INFO >> epoch 012 | valid on 'valid' subset | loss 0.953 | mrr 0.66262 | sample_size 1000 | wps 22909.9 | wpb 1000 | bsz 1000 | num_updates 22560 | best_mrr 662.62 (progress_bar.py:269, print())
[2021-09-26 16:47:02]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 12 @ 22560 updates, score 0.66262) (writing took 0.327822 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:47:31]    INFO >> epoch 013:    440 / 1881 loss=0.863, mrr=807.757, sample_size=1000, wps=11750.7, ups=11.75, wpb=1000, bsz=1000, num_updates=23000, lr=0.01, gnorm=0.042, clip=0, train_wall=12, wall=1157 (progress_bar.py:260, log())
[2021-09-26 16:47:49]    INFO >> epoch 013:    940 / 1881 loss=0.866, mrr=804.541, sample_size=1000, wps=27702.6, ups=27.7, wpb=1000, bsz=1000, num_updates=23500, lr=0.01, gnorm=0.042, clip=0, train_wall=12, wall=1175 (progress_bar.py:260, log())
[2021-09-26 16:48:07]    INFO >> epoch 013:   1440 / 1881 loss=0.87, mrr=798.406, sample_size=1000, wps=27748.7, ups=27.75, wpb=1000, bsz=1000, num_updates=24000, lr=0.01, gnorm=0.043, clip=0, train_wall=11, wall=1193 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:48:24]    INFO >> epoch 013 | loss 0.868 | mrr 0.801853 | sample_size 1000 | wps 20236.8 | ups 20.24 | wpb 1000 | bsz 1000 | num_updates 24440 | lr 0.01 | gnorm 0.042 | clip 0 | train_wall 44 | wall 1210 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:48:35]    INFO >> epoch 013 | valid on 'valid' subset | loss 0.954 | mrr 0.662888 | sample_size 1000 | wps 23022.2 | wpb 1000 | bsz 1000 | num_updates 24440 | best_mrr 662.888 (progress_bar.py:269, print())
[2021-09-26 16:48:35]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 13 @ 24440 updates, score 0.662888) (writing took 0.294556 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:48:50]    INFO >> epoch 014:     60 / 1881 loss=0.871, mrr=796.86, sample_size=1000, wps=11620.9, ups=11.62, wpb=1000, bsz=1000, num_updates=24500, lr=0.01, gnorm=0.043, clip=0, train_wall=12, wall=1236 (progress_bar.py:260, log())
[2021-09-26 16:49:08]    INFO >> epoch 014:    560 / 1881 loss=0.862, mrr=809.803, sample_size=1000, wps=27148.3, ups=27.15, wpb=1000, bsz=1000, num_updates=25000, lr=0.01, gnorm=0.043, clip=0, train_wall=12, wall=1254 (progress_bar.py:260, log())
[2021-09-26 16:49:26]    INFO >> epoch 014:   1060 / 1881 loss=0.866, mrr=803.224, sample_size=1000, wps=28010.3, ups=28.01, wpb=1000, bsz=1000, num_updates=25500, lr=0.01, gnorm=0.044, clip=0, train_wall=11, wall=1272 (progress_bar.py:260, log())
[2021-09-26 16:49:44]    INFO >> epoch 014:   1560 / 1881 loss=0.869, mrr=799.285, sample_size=1000, wps=27740.8, ups=27.74, wpb=1000, bsz=1000, num_updates=26000, lr=0.01, gnorm=0.044, clip=0, train_wall=12, wall=1290 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:49:56]    INFO >> epoch 014 | loss 0.867 | mrr 0.803026 | sample_size 1000 | wps 20255.7 | ups 20.26 | wpb 1000 | bsz 1000 | num_updates 26320 | lr 0.01 | gnorm 0.044 | clip 0 | train_wall 43 | wall 1302 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:50:07]    INFO >> epoch 014 | valid on 'valid' subset | loss 0.953 | mrr 0.663693 | sample_size 1000 | wps 25190.8 | wpb 1000 | bsz 1000 | num_updates 26320 | best_mrr 663.693 (progress_bar.py:269, print())
[2021-09-26 16:50:08]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 14 @ 26320 updates, score 0.663693) (writing took 0.544638 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:50:26]    INFO >> epoch 015:    180 / 1881 loss=0.867, mrr=802.606, sample_size=1000, wps=11767.1, ups=11.77, wpb=1000, bsz=1000, num_updates=26500, lr=0.01, gnorm=0.044, clip=0, train_wall=12, wall=1332 (progress_bar.py:260, log())
[2021-09-26 16:50:45]    INFO >> epoch 015:    680 / 1881 loss=0.863, mrr=808.781, sample_size=1000, wps=27280.5, ups=27.28, wpb=1000, bsz=1000, num_updates=27000, lr=0.01, gnorm=0.045, clip=0, train_wall=12, wall=1351 (progress_bar.py:260, log())
[2021-09-26 16:51:03]    INFO >> epoch 015:   1181 / 1881 loss=0.866, mrr=803.64, sample_size=1000, wps=27080.3, ups=27.08, wpb=1000, bsz=1000, num_updates=27500, lr=0.01, gnorm=0.045, clip=0, train_wall=12, wall=1369 (progress_bar.py:260, log())
[2021-09-26 16:51:22]    INFO >> epoch 015:   1681 / 1881 loss=0.869, mrr=798.965, sample_size=1000, wps=26135.3, ups=26.14, wpb=1000, bsz=1000, num_updates=28000, lr=0.01, gnorm=0.045, clip=0, train_wall=12, wall=1388 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:51:30]    INFO >> epoch 015 | loss 0.866 | mrr 0.80393 | sample_size 1000 | wps 19966 | ups 19.97 | wpb 1000 | bsz 1000 | num_updates 28200 | lr 0.01 | gnorm 0.045 | clip 0 | train_wall 44 | wall 1397 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:51:41]    INFO >> epoch 015 | valid on 'valid' subset | loss 0.953 | mrr 0.66245 | sample_size 1000 | wps 26023.3 | wpb 1000 | bsz 1000 | num_updates 28200 | best_mrr 662.45 (progress_bar.py:269, print())
[2021-09-26 16:51:42]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 15 @ 28200 updates, score 0.66245) (writing took 0.332216 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:52:05]    INFO >> epoch 016:    300 / 1881 loss=0.864, mrr=806.192, sample_size=1000, wps=11803.4, ups=11.8, wpb=1000, bsz=1000, num_updates=28500, lr=0.01, gnorm=0.046, clip=0, train_wall=12, wall=1431 (progress_bar.py:260, log())
[2021-09-26 16:52:23]    INFO >> epoch 016:    800 / 1881 loss=0.863, mrr=807.899, sample_size=1000, wps=27513.9, ups=27.51, wpb=1000, bsz=1000, num_updates=29000, lr=0.01, gnorm=0.046, clip=0, train_wall=12, wall=1449 (progress_bar.py:260, log())
[2021-09-26 16:52:41]    INFO >> epoch 016:   1301 / 1881 loss=0.866, mrr=803.271, sample_size=1000, wps=27626.5, ups=27.63, wpb=1000, bsz=1000, num_updates=29500, lr=0.01, gnorm=0.046, clip=0, train_wall=12, wall=1467 (progress_bar.py:260, log())
[2021-09-26 16:52:59]    INFO >> epoch 016:   1801 / 1881 loss=0.868, mrr=799.754, sample_size=1000, wps=27209.6, ups=27.21, wpb=1000, bsz=1000, num_updates=30000, lr=0.01, gnorm=0.046, clip=0, train_wall=12, wall=1485 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:53:03]    INFO >> epoch 016 | loss 0.865 | mrr 0.804926 | sample_size 1000 | wps 20374.3 | ups 20.37 | wpb 1000 | bsz 1000 | num_updates 30080 | lr 0.01 | gnorm 0.046 | clip 0 | train_wall 44 | wall 1489 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:53:14]    INFO >> epoch 016 | valid on 'valid' subset | loss 0.953 | mrr 0.66352 | sample_size 1000 | wps 23829.7 | wpb 1000 | bsz 1000 | num_updates 30080 | best_mrr 663.52 (progress_bar.py:269, print())
[2021-09-26 16:53:14]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 16 @ 30080 updates, score 0.66352) (writing took 0.319756 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:53:43]    INFO >> epoch 017:    420 / 1881 loss=0.861, mrr=810.831, sample_size=1000, wps=11537.9, ups=11.54, wpb=1000, bsz=1000, num_updates=30500, lr=0.01, gnorm=0.047, clip=0, train_wall=12, wall=1529 (progress_bar.py:260, log())
[2021-09-26 16:54:01]    INFO >> epoch 017:    920 / 1881 loss=0.863, mrr=807.466, sample_size=1000, wps=26880.7, ups=26.88, wpb=1000, bsz=1000, num_updates=31000, lr=0.01, gnorm=0.047, clip=0, train_wall=12, wall=1547 (progress_bar.py:260, log())
[2021-09-26 16:54:20]    INFO >> epoch 017:   1421 / 1881 loss=0.866, mrr=802.667, sample_size=1000, wps=27295.5, ups=27.3, wpb=1000, bsz=1000, num_updates=31500, lr=0.01, gnorm=0.047, clip=0, train_wall=12, wall=1566 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:54:37]    INFO >> epoch 017 | loss 0.864 | mrr 0.805514 | sample_size 1000 | wps 19902.4 | ups 19.9 | wpb 1000 | bsz 1000 | num_updates 31960 | lr 0.01 | gnorm 0.047 | clip 0 | train_wall 44 | wall 1583 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:54:48]    INFO >> epoch 017 | valid on 'valid' subset | loss 0.952 | mrr 0.663754 | sample_size 1000 | wps 24549.6 | wpb 1000 | bsz 1000 | num_updates 31960 | best_mrr 663.754 (progress_bar.py:269, print())
[2021-09-26 16:54:49]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_best.pt (epoch 17 @ 31960 updates, score 0.663754) (writing took 0.573358 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:55:03]    INFO >> epoch 018:     40 / 1881 loss=0.867, mrr=800.805, sample_size=1000, wps=11643.4, ups=11.64, wpb=1000, bsz=1000, num_updates=32000, lr=0.01, gnorm=0.048, clip=0, train_wall=12, wall=1609 (progress_bar.py:260, log())
[2021-09-26 16:55:20]    INFO >> epoch 018:    540 / 1881 loss=0.859, mrr=812.682, sample_size=1000, wps=28786.3, ups=28.79, wpb=1000, bsz=1000, num_updates=32500, lr=0.01, gnorm=0.048, clip=0, train_wall=11, wall=1626 (progress_bar.py:260, log())
[2021-09-26 16:55:38]    INFO >> epoch 018:   1040 / 1881 loss=0.864, mrr=806.228, sample_size=1000, wps=27255.7, ups=27.26, wpb=1000, bsz=1000, num_updates=33000, lr=0.01, gnorm=0.048, clip=0, train_wall=12, wall=1644 (progress_bar.py:260, log())
[2021-09-26 16:55:57]    INFO >> epoch 018:   1541 / 1881 loss=0.866, mrr=803.475, sample_size=1000, wps=27131, ups=27.13, wpb=1000, bsz=1000, num_updates=33500, lr=0.01, gnorm=0.048, clip=0, train_wall=12, wall=1663 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:56:10]    INFO >> epoch 018 | loss 0.864 | mrr 0.806148 | sample_size 1000 | wps 20309.9 | ups 20.31 | wpb 1000 | bsz 1000 | num_updates 33840 | lr 0.01 | gnorm 0.048 | clip 0 | train_wall 43 | wall 1676 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:56:21]    INFO >> epoch 018 | valid on 'valid' subset | loss 0.952 | mrr 0.663177 | sample_size 1000 | wps 22755.1 | wpb 1000 | bsz 1000 | num_updates 33840 | best_mrr 663.177 (progress_bar.py:269, print())
[2021-09-26 16:56:21]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 18 @ 33840 updates, score 0.663177) (writing took 0.315937 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:56:40]    INFO >> epoch 019:    160 / 1881 loss=0.865, mrr=804.428, sample_size=1000, wps=11607.1, ups=11.61, wpb=1000, bsz=1000, num_updates=34000, lr=0.01, gnorm=0.049, clip=0, train_wall=12, wall=1706 (progress_bar.py:260, log())
[2021-09-26 16:56:58]    INFO >> epoch 019:    660 / 1881 loss=0.86, mrr=811.981, sample_size=1000, wps=27318.4, ups=27.32, wpb=1000, bsz=1000, num_updates=34500, lr=0.01, gnorm=0.049, clip=0, train_wall=12, wall=1724 (progress_bar.py:260, log())
[2021-09-26 16:57:17]    INFO >> epoch 019:   1161 / 1881 loss=0.864, mrr=806.026, sample_size=1000, wps=26824.7, ups=26.82, wpb=1000, bsz=1000, num_updates=35000, lr=0.01, gnorm=0.049, clip=0, train_wall=12, wall=1743 (progress_bar.py:260, log())
[2021-09-26 16:57:35]    INFO >> epoch 019:   1661 / 1881 loss=0.866, mrr=803.371, sample_size=1000, wps=27750.2, ups=27.75, wpb=1000, bsz=1000, num_updates=35500, lr=0.01, gnorm=0.05, clip=0, train_wall=11, wall=1761 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:57:43]    INFO >> epoch 019 | loss 0.863 | mrr 0.80707 | sample_size 1000 | wps 20091.5 | ups 20.09 | wpb 1000 | bsz 1000 | num_updates 35720 | lr 0.01 | gnorm 0.049 | clip 0 | train_wall 43 | wall 1769 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:57:54]    INFO >> epoch 019 | valid on 'valid' subset | loss 0.953 | mrr 0.662183 | sample_size 1000 | wps 25499.3 | wpb 1000 | bsz 1000 | num_updates 35720 | best_mrr 662.183 (progress_bar.py:269, print())
[2021-09-26 16:57:54]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 19 @ 35720 updates, score 0.662183) (writing took 0.317435 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:58:17]    INFO >> epoch 020:    281 / 1881 loss=0.861, mrr=809.676, sample_size=1000, wps=11919.1, ups=11.92, wpb=1000, bsz=1000, num_updates=36000, lr=0.01, gnorm=0.05, clip=0, train_wall=11, wall=1803 (progress_bar.py:260, log())
[2021-09-26 16:58:36]    INFO >> epoch 020:    781 / 1881 loss=0.86, mrr=811.376, sample_size=1000, wps=26571, ups=26.57, wpb=1000, bsz=1000, num_updates=36500, lr=0.01, gnorm=0.05, clip=0, train_wall=12, wall=1822 (progress_bar.py:260, log())
[2021-09-26 16:58:54]    INFO >> epoch 020:   1281 / 1881 loss=0.864, mrr=805.875, sample_size=1000, wps=26742.9, ups=26.74, wpb=1000, bsz=1000, num_updates=37000, lr=0.01, gnorm=0.05, clip=0, train_wall=11, wall=1840 (progress_bar.py:260, log())
[2021-09-26 16:59:13]    INFO >> epoch 020:   1781 / 1881 loss=0.866, mrr=802.041, sample_size=1000, wps=26505.1, ups=26.51, wpb=1000, bsz=1000, num_updates=37500, lr=0.01, gnorm=0.05, clip=0, train_wall=12, wall=1859 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:59:17]    INFO >> epoch 020 | loss 0.863 | mrr 0.807715 | sample_size 1000 | wps 20053 | ups 20.05 | wpb 1000 | bsz 1000 | num_updates 37600 | lr 0.01 | gnorm 0.05 | clip 0 | train_wall 43 | wall 1863 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 16:59:28]    INFO >> epoch 020 | valid on 'valid' subset | loss 0.953 | mrr 0.661953 | sample_size 1000 | wps 29556.1 | wpb 1000 | bsz 1000 | num_updates 37600 | best_mrr 661.953 (progress_bar.py:269, print())
[2021-09-26 16:59:28]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 20 @ 37600 updates, score 0.661953) (writing took 0.315751 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 16:59:55]    INFO >> epoch 021:    400 / 1881 loss=0.859, mrr=812.43, sample_size=1000, wps=11924.7, ups=11.92, wpb=1000, bsz=1000, num_updates=38000, lr=0.01, gnorm=0.051, clip=0, train_wall=12, wall=1901 (progress_bar.py:260, log())
[2021-09-26 17:00:13]    INFO >> epoch 021:    900 / 1881 loss=0.861, mrr=809.533, sample_size=1000, wps=27536.4, ups=27.54, wpb=1000, bsz=1000, num_updates=38500, lr=0.01, gnorm=0.051, clip=0, train_wall=11, wall=1919 (progress_bar.py:260, log())
[2021-09-26 17:00:32]    INFO >> epoch 021:   1401 / 1881 loss=0.863, mrr=806.72, sample_size=1000, wps=27008.8, ups=27.01, wpb=1000, bsz=1000, num_updates=39000, lr=0.01, gnorm=0.051, clip=0, train_wall=12, wall=1938 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 17:00:50]    INFO >> epoch 021 | loss 0.862 | mrr 0.808119 | sample_size 1000 | wps 20286.5 | ups 20.29 | wpb 1000 | bsz 1000 | num_updates 39480 | lr 0.01 | gnorm 0.051 | clip 0 | train_wall 44 | wall 1956 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 17:01:00]    INFO >> epoch 021 | valid on 'valid' subset | loss 0.952 | mrr 0.662276 | sample_size 1000 | wps 27297.3 | wpb 1000 | bsz 1000 | num_updates 39480 | best_mrr 662.276 (progress_bar.py:269, print())
[2021-09-26 17:01:01]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 21 @ 39480 updates, score 0.662276) (writing took 0.320643 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 17:01:14]    INFO >> epoch 022:     20 / 1881 loss=0.866, mrr=802.847, sample_size=1000, wps=11959, ups=11.96, wpb=1000, bsz=1000, num_updates=39500, lr=0.01, gnorm=0.051, clip=0, train_wall=11, wall=1980 (progress_bar.py:260, log())
[2021-09-26 17:01:32]    INFO >> epoch 022:    520 / 1881 loss=0.857, mrr=815.064, sample_size=1000, wps=27165.5, ups=27.17, wpb=1000, bsz=1000, num_updates=40000, lr=0.01, gnorm=0.052, clip=0, train_wall=12, wall=1998 (progress_bar.py:260, log())
[2021-09-26 17:01:50]    INFO >> epoch 022:   1020 / 1881 loss=0.861, mrr=809.346, sample_size=1000, wps=27028.7, ups=27.03, wpb=1000, bsz=1000, num_updates=40500, lr=0.01, gnorm=0.051, clip=0, train_wall=12, wall=2016 (progress_bar.py:260, log())
[2021-09-26 17:02:09]    INFO >> epoch 022:   1520 / 1881 loss=0.864, mrr=805.839, sample_size=1000, wps=26920.9, ups=26.92, wpb=1000, bsz=1000, num_updates=41000, lr=0.01, gnorm=0.052, clip=0, train_wall=12, wall=2035 (progress_bar.py:260, log())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 17:02:23]    INFO >> epoch 022 | loss 0.862 | mrr 0.80883 | sample_size 1000 | wps 20082.8 | ups 20.08 | wpb 1000 | bsz 1000 | num_updates 41360 | lr 0.01 | gnorm 0.052 | clip 0 | train_wall 44 | wall 2049 (progress_bar.py:269, print())
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
[2021-09-26 17:02:34]    INFO >> epoch 022 | valid on 'valid' subset | loss 0.953 | mrr 0.662412 | sample_size 1000 | wps 23829.7 | wpb 1000 | bsz 1000 | num_updates 41360 | best_mrr 662.412 (progress_bar.py:269, print())
[2021-09-26 17:02:35]    INFO >> saved checkpoint /home/wanyao/ncc_data/codesearchnet/retrieval/data-mmap/all/nbow/checkpoints/checkpoint_last.pt (epoch 22 @ 41360 updates, score 0.662412) (writing took 0.314055 seconds) (checkpoint_utils.py:79, save_checkpoint())
[2021-09-26 17:02:35]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:190, should_stop_early())
[2021-09-26 17:02:35]    INFO >> early stop since valid performance hasn't improved for last 5 runs (train.py:271, single_main())
[2021-09-26 17:02:35]    INFO >> done training in 2057.1 seconds (train.py:283, single_main())
