{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncc2.tasks.generation import GenerationTask\n",
    "\n",
    "ckpt_path = '/data/lz/models/CodeLlama-7b'\n",
    "dataset_path = '/data/lz/naturalcc2/examples/generation/dataset.json'\n",
    "output_path = './result.json'\n",
    "test_input = 'this is a test'\n",
    "\n",
    "task = GenerationTask(task_name=\"codellama_7b_code\",device=\"cuda:2\")\n",
    "task.from_pretrained(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.load_dataset(dataset_path)\n",
    "task.run(output_path=output_path,batch_size=1,max_length=50,temperature=0.5,top_p=0.99)\n",
    "# test_output = task.generate(test_input,max_length=30,top_k=20,top_p=0.99,penalty_weight=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. generation sample fix (add beam search,etc.) -\n",
    "# 2. task register fix √\n",
    "# 3. hf model adapter √\n",
    "# 4. code completion task lz & hyf\n",
    "# 5. evaluation tvc\n",
    "# 6. readme.md lz \n",
    "# 7. code summarization task runbang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/aigc/miniconda3/envs/ncc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from ncc2.tasks.summarization import SummarizationTask\n",
    "\n",
    "ckpt_path = '/data/lz/models/codet5p-6b'\n",
    "dataset_path = '/data/lz/naturalcc2/examples/generation/dataset.json'\n",
    "output_path = './result.json'\n",
    "test_input = 'this is a test'\n",
    "\n",
    "task = SummarizationTask(task_name=\"t5_code\",device=\"cuda:2\")\n",
    "task.from_pretrained(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/data/aigc/miniconda3/envs/ncc/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data/aigc/miniconda3/envs/ncc/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.99` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 17%|█▋        | 1/6 [00:08<00:44,  8.82s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 33%|███▎      | 2/6 [00:13<00:24,  6.17s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 50%|█████     | 3/6 [00:17<00:15,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 67%|██████▋   | 4/6 [00:21<00:09,  4.92s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 83%|████████▎ | 5/6 [00:26<00:04,  4.70s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████| 6/6 [00:30<00:00,  5.06s/it]\n"
     ]
    }
   ],
   "source": [
    "task.load_dataset(dataset_path)\n",
    "task.run(output_path=output_path,batch_size=1,max_length=50,temperature=0.5,top_p=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"\\n\\ntask.from_pretrained(ckpt_path)\\n\\ntask.to_cpu()\\n\\ntask.eval()\\n\\ntask.load_dataset(dataset_name)\\n\\ntask.load_dataloader()\\n\\ntask.load_model()\\n\\ntask.load_optimizer()\\n\\ntask.load_scheduler()\\n\\ntask.load_loss()\\n\\ntask.load_metric()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.generate(\"\"\"task = GenerationTask(task_name=\"codellama_7b_code\",device=\"cuda:2\")\n",
    "task.from_pretrained(ckpt_path)\n",
    "return summarization of the code: \"\"\",max_length=100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncc2.tasks.summarization import codet5_SummarizationTask\n",
    "ckpt_path = '\"Salesforce/codet5-large\"'\n",
    "dataset_path = './dataset.json'\n",
    "output_path = './result.json'\n",
    "test_input = 'this is a test'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rkwv-runner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
