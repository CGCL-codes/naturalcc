preprocess:
  task: summarization # task', metavar='TASK', default="translation", choices=TASK_REGISTRY.keys(), help='task'
  source_lang:
    - code_tokens
    - docstring_tokens
#    - path
#    - path.terminals
#    - sbt
    - traversal
  # ~ path for dataset default. e.g.  for code_search_net, ~/filter = ~/code_search_net/filter
  trainpref: ~/code_search_net/filter/go/train #", metavar="FP", default=None, help="train file prefix"
  validpref: ~/code_search_net/filter/go/valid #", metavar="FP", default=None, help="comma separated, valid file prefixes"
  testpref:  ~/code_search_net/filter/go/test  #", metavar="FP", default=None, help="comma separated, test file prefixes"

  align_suffix: ~ # ", metavar="FP", default=None, help="alignment file suffix"
#  destdir: ~/code_search_net/summarization/data-raw/go/ #", metavar="DIR", default="data-bin", help="destination dir"
  destdir: ~/code_search_net/summarization/data-mmap/go #", metavar="DIR", default="data-bin", help="destination dir"
  thresholdsrc: 0 #", metavar="N", default=0, type=int, help="map words appearing less than threshold times to unknown"
  srcdict: ~
  #  nwordssrc: -1 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  nwordssrc: 50000 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  alignfile: ~ #", metavar="ALIGN", default=None, help="an alignment file (optional)"
#  dataset_impl: raw #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  dataset_impl: mmap #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  joined_dictionary: 0 # ", action="store_true", help="Generate joined dictionary"
  padding_factor: 8 #", metavar="N", default=8, type=int, help="Pad dictionary size to be multiple of N"
  workers: 24 # ", metavar="N", default=1, type=int, help="number of parallel workers"