preprocess:
  task: path_summarization # task', metavar='TASK', default="translation", choices=TASK_REGISTRY.keys(), help='task'
  source_lang: method_path
  trainpref: ~/py150/attributes/train #", metavar="FP", default=None, help="train file prefix"
  validpref: ~/py150/attributes/valid #", metavar="FP", default=None, help="comma separated, valid file prefixes"
  testpref:  ~/py150/attributes/test  #", metavar="FP", default=None, help="comma separated, test file prefixes"
  only_source: 0
  only_train: 1

  train_path_num: 1000
  eval_path_num: 200

  # bin dataset
  dataset_impl: mmap #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  destdir: ~/py150/method_prediction/data-mmap #", metavar="DIR", default="data-bin", help="destination dir"

#  align_suffix: ~ # ", metavar="FP", default=None, help="alignment file suffix"
  threshold: 0 #", metavar="N", default=0, type=int, help="map words appearing less than threshold times to unknown"
  subtokendict: ~
  typedict: ~
  methoddict: ~
#  subtokendict: ~/py150/method_prediction/data-mmap/subtoken.dict.jsonl
#  typedict: ~/py150/method_prediction/data-mmap/type.dict.jsonl
#  methoddict: ~/py150/method_prediction/data-mmap/method.dict.jsonl
  nwordssubtoken: 186277 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  nwordstype: 999999999 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  nwordsmethod: 26347 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  alignfile: ~ #", metavar="ALIGN", default=None, help="an alignment file (optional)"
  padding_factor: 1 #", metavar="N", default=8, type=int, help="Pad dictionary size to be multiple of N"
  workers: 40 # ", metavar="N", default=1, type=int, help="number of parallel workers"