preprocess:
  task: typilus # task', metavar='TASK', default="translation", choices=TASK_REGISTRY.keys(), help='task'
  langs:
    - nodes
    - edges
    - supernodes.annotation
  trainpref: ~/typilus/attributes/train #", metavar="FP", default=None, help="train file prefix"
  validpref: ~/typilus/attributes/valid #", metavar="FP", default=None, help="comma separated, valid file prefixes"
  testpref:  ~/typilus/attributes/test  #", metavar="FP", default=None, help="comma separated, test file prefixes"

  # raw dataset
#  dataset_impl: raw #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  # bin dataset
  dataset_impl: mmap #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  destdir: ~/typilus/type_inference/data-mmap #", metavar="DIR", default="data-bin", help="destination dir"

  only_train: 1 # if set false, generate dictionaries with additional validation datasets. e.g. neural-transformer
  edge_backward: 1

#  align_suffix: ~ # ", metavar="FP", default=None, help="alignment file suffix"
  thresholds: #", metavar="N", default=0, type=int, help="map words appearing less than threshold times to unknown"
    - 5
    - 5
    - 5
  dicts:
    - ~
    - ~
    - ~
#    - ~/typilus/type_inference/data-mmap/nodes.dict.json
#    - ~/typilus/type_inference/data-mmap/edges.dict.json
#    - ~/typilus/type_inference/data-mmap/supernodes.annotation.dict.json
  nwords:  #", metavar="N", default=-1, type=int, help="number of source words to retain"
    - 9999 # 9999 for node subtokens, 4 for bos/eos/unk/pad, 3 for TokenEmbedder.STRING_LITERAL/FLOAT_LITERAL/INT_LITERAL
    - 99
    - 99 # 99 for annotation types, 4 for bos/eos/unk/pad
  padding_factor: 1 #", metavar="N", default=8, type=int, help="Pad dictionary size to be multiple of N"
  workers: 1 # ", metavar="N", default=1, type=int, help="number of parallel workers"