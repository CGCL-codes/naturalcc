preprocess:
  task: summarization # task', metavar='TASK', default="translation", choices=TASK_REGISTRY.keys(), help='task'
  source_lang: code_tokens # sbt, sbtao, path, bin_ast
  target_lang: docstring_tokens #", default=None, metavar="TARGET", help="target language"
  # ~ path for dataset default. e.g.  for CodeSearchNet, ~/flatten = ~/.ncc/CodeSearchNet/flatten
  trainpref: ~/.ncc/code_search_net/filter/ruby/train #", metavar="FP", default=None, help="train file prefix"
  validpref: ~/.ncc/code_search_net/filter/ruby/valid #", metavar="FP", default=None, help="comma separated, valid file prefixes"
  testpref:  ~/.ncc/code_search_net/filter/ruby/test  #", metavar="FP", default=None, help="comma separated, test file prefixes"

  align_suffix: ~ # ", metavar="FP", default=None, help="alignment file suffix"
#  destdir: ~/.ncc/CodeSearchNet/summarization/data-raw/ruby/ #", metavar="DIR", default="data-bin", help="destination dir"
  destdir: ~/.ncc/code_search_net/summarization/data-mmap/ruby #", metavar="DIR", default="data-bin", help="destination dir"
  thresholdtgt: 0 #", metavar="N", default=0, type=int, help="map words appearing less than threshold times to unknown"
  thresholdsrc: 0 #", metavar="N", default=0, type=int, help="map words appearing less than threshold times to unknown"
  srcdict: ~
  tgtdict: ~
  #  nwordstgt: -1 #", metavar="N", default=-1, type=int, help="number of target words to retain"
  #  nwordssrc: -1 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  nwordstgt: 50000 #", metavar="N", default=-1, type=int, help="number of target words to retain"
  nwordssrc: 50000 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  alignfile: ~ #", metavar="ALIGN", default=None, help="an alignment file (optional)"
#  dataset_impl: raw #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  dataset_impl: mmap #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  joined_dictionary: 0 # ", action="store_true", help="Generate joined dictionary"
  only_source: 0 # ", action="store_true", help="Only process the source language"
  padding_factor: 8 #", metavar="N", default=8, type=int, help="Pad dictionary size to be multiple of N"
  workers: 1 # ", metavar="N", default=1, type=int, help="number of parallel workers"
  inserted: 0