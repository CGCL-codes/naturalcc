preprocess:
  task: completion # task', metavar='TASK', default="translation", choices=TASK_REGISTRY.keys(), help='task'
  source_lang: code_tokens
  target_lang: code_types
  only_source: 0
  joined_dictionary: 0
  only_train: 1

  trainpref: ~/ncc_data/raw_py150/attributes/train #", metavar="FP", default=None, help="train file prefix"
  validpref: ~ #", metavar="FP", default=None, help="comma separated, valid file prefixes"
  testpref:  ~/ncc_data/raw_py150/attributes/test  #", metavar="FP", default=None, help="comma separated, test file prefixes"

  # bin dataset
  dataset_impl: mmap #', metavar='FORMAT', default='mmap', choices=get_available_dataset_impl(), help='output dataset implementation'
  destdir: ~/ncc_data/raw_py150/completion/data-mmap #", metavar="DIR", default="data-bin", help="destination dir"
  max_len: 500

#  align_suffix: ~ # ", metavar="FP", default=None, help="alignment file suffix"
  threshold: 0 #", metavar="N", default=0, type=int, help="map words appearing less than threshold times to unknown"
  srcdict: ~
  tgtdict: ~
  nwordssrc: 50000 #", metavar="N", default=-1, type=int, help="number of source words to retain"
  nwordstgt: 50000 #", metavar="N", default=-1, type=int, help="number of target words to retain"
  alignfile: ~ #", metavar="ALIGN", default=None, help="an alignment file (optional)"
  padding_factor: 1 #", metavar="N", default=8, type=int, help="Pad dictionary size to be multiple of N"
  workers: 40 # ", metavar="N", default=1, type=int, help="number of parallel workers"